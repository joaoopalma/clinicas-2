{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f80f8da",
   "metadata": {},
   "source": [
    "# Entrega 6 - C. dados aplicada ao direito II\n",
    "\n",
    "**Objetivo:** Extrair informações estruturadas dos casos e criar novas colunas de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "660192a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports básicos\n",
    "import re, unicodedata\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac4002a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão: (19800, 6)\n",
      "Colunas: ['cd_causa', 'cd_atendimento', 'ds_Acao_Judicial', 'ds_fatos', 'ds_Pedidos', 'ds_Qualificacao']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cd_causa            object\n",
       "cd_atendimento      object\n",
       "ds_Acao_Judicial    object\n",
       "ds_fatos            object\n",
       "ds_Pedidos          object\n",
       "ds_Qualificacao     object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cd_causa</th>\n",
       "      <th>cd_atendimento</th>\n",
       "      <th>ds_Acao_Judicial</th>\n",
       "      <th>ds_fatos</th>\n",
       "      <th>ds_Pedidos</th>\n",
       "      <th>ds_Qualificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CIB0500064</td>\n",
       "      <td>0825789-84.2025.8.18.0140</td>\n",
       "      <td>90 - ACAO DE REPARACAO DE DANOS</td>\n",
       "      <td>DOS FATOS A parte Autora, pessoa idosa e hipos...</td>\n",
       "      <td>DOS PEDIDOS Ante ao exposto, requer: a) Sejam ...</td>\n",
       "      <td>DOUTO JUÍZO DE DIREITO DA ___ VARA CÍVEL DA CO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CIB0505587</td>\n",
       "      <td>1004697-72.2025.8.26.0066</td>\n",
       "      <td>90 - ACAO DE REPARACAO DE DANOS</td>\n",
       "      <td>DOS FATOS 5. A parte autora é pessoa idosa, hi...</td>\n",
       "      <td>DOS PEDIDOS E REQUERIMENTOS 33. Diante do expo...</td>\n",
       "      <td>(17) 99779-9177 / EXCELENTÍSSIMO SENHOR DOUTOR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CIB0508201</td>\n",
       "      <td>0800423-07.2025.8.15.0761</td>\n",
       "      <td>90 - ACAO DE REPARACAO DE DANOS</td>\n",
       "      <td>DOS FATOS 1. SITUAÇÃO DE VULNERABILIDADE DO CO...</td>\n",
       "      <td>DOS PEDIDOS E REQUERIMENTOS Ex Positis, requer...</td>\n",
       "      <td>AO COLENDO JUÍZO DA VARA ÚNICA DA COMARCA DE G...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cd_causa             cd_atendimento                 ds_Acao_Judicial  \\\n",
       "0  CIB0500064  0825789-84.2025.8.18.0140  90 - ACAO DE REPARACAO DE DANOS   \n",
       "1  CIB0505587  1004697-72.2025.8.26.0066  90 - ACAO DE REPARACAO DE DANOS   \n",
       "2  CIB0508201  0800423-07.2025.8.15.0761  90 - ACAO DE REPARACAO DE DANOS   \n",
       "\n",
       "                                            ds_fatos  \\\n",
       "0  DOS FATOS A parte Autora, pessoa idosa e hipos...   \n",
       "1  DOS FATOS 5. A parte autora é pessoa idosa, hi...   \n",
       "2  DOS FATOS 1. SITUAÇÃO DE VULNERABILIDADE DO CO...   \n",
       "\n",
       "                                          ds_Pedidos  \\\n",
       "0  DOS PEDIDOS Ante ao exposto, requer: a) Sejam ...   \n",
       "1  DOS PEDIDOS E REQUERIMENTOS 33. Diante do expo...   \n",
       "2  DOS PEDIDOS E REQUERIMENTOS Ex Positis, requer...   \n",
       "\n",
       "                                     ds_Qualificacao  \n",
       "0  DOUTO JUÍZO DE DIREITO DA ___ VARA CÍVEL DA CO...  \n",
       "1  (17) 99779-9177 / EXCELENTÍSSIMO SENHOR DOUTOR...  \n",
       "2  AO COLENDO JUÍZO DA VARA ÚNICA DA COMARCA DE G...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) ENTENDIMENTO DE DADOS (EDA)\n",
    "\n",
    "# LINHA DE SELEÇÃO DO INPUT  ←←← (não remover esta linha!)\n",
    "INPUT_CSV = \"../data/dataset_clinica20252.csv\"   # ajuste se necessário\n",
    "\n",
    "# OBS: o CSV vem separado por \"|\"\n",
    "df = pd.read_csv(INPUT_CSV, sep=\"|\")\n",
    "\n",
    "print(\"Dimensão:\", df.shape)\n",
    "print(\"Colunas:\", list(df.columns))\n",
    "\n",
    "# Tipos e amostras\n",
    "display(df.dtypes)\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "712be6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup + utilidades\n",
    "\n",
    "def strip_accents(s: str) -> str:\n",
    "    if not isinstance(s, str): return \"\"\n",
    "    return \"\".join(c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\")\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = (s or \"\").replace(\"\\n\", \" \")\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "# Constantes\n",
    "UF_LIST = set(\"AC AL AP AM BA CE DF ES GO MA MT MS MG PA PB PR PE PI RJ RN RS RO RR SC SP SE TO\".split())\n",
    "MESES_PT = {\"janeiro\":1,\"fevereiro\":2,\"março\":3,\"marco\":3,\"abril\":4,\"maio\":5,\"junho\":6,\"julho\":7,\"agosto\":8,\"setembro\":9,\"outubro\":10,\"novembro\":11,\"dezembro\":12}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd8ec57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lê as colunas textuais, normaliza e filtra casos cujo texto contenha \"crédito consignado\"\n",
    "# salva output.xlsx com cd_atendimento\n",
    "\n",
    "def filtra_credito_consignado(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Procura 'crédito consignado' nas colunas textuais e salva output.xlsx\n",
    "    contendo apenas cd_atendimento.\n",
    "    \"\"\"\n",
    "    text_cols = [\"ds_Acao_Judicial\", \"ds_fatos\", \"ds_Pedidos\", \"ds_Qualificacao\"]\n",
    "    present = [c for c in text_cols if c in df.columns]\n",
    "    txt = df[present].astype(str).agg(\" \".join, axis=1).map(lambda x: strip_accents(x).lower())\n",
    "    mask = txt.str.contains(\"credito consignado\", na=False)\n",
    "\n",
    "    out = df.loc[mask, [\"cd_atendimento\"]].astype(str).copy()\n",
    "    out.to_excel(\"output/output.xlsx\", index=False)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9883b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções auxiliares para extração\n",
    "\n",
    "def extract_cnpjs(text: str) -> str:\n",
    "    text = clean_text(text)\n",
    "    raw = re.findall(r\"\\b\\d{2}\\.?\\d{3}\\.?\\d{3}/?\\d{4}-?\\d{2}\\b\", text)\n",
    "    nums = [re.sub(r\"\\D\", \"\", c) for c in raw if len(re.sub(r\"\\D\", \"\", c)) == 14]\n",
    "    nums = sorted(set(nums))\n",
    "    return \",\".join(nums) if nums else \"vazio\"\n",
    "\n",
    "def extract_valor_causa(text: str) -> float:\n",
    "    text = clean_text(text)\n",
    "    matches = re.findall(r\"(?:R\\$\\s*)?(\\d{1,3}(?:\\.\\d{3})*,\\d{2}|\\d+,\\d{2})\", text)\n",
    "    valores = [float(v.replace(\".\", \"\").replace(\",\", \".\")) for v in matches]\n",
    "    return max(valores) if valores else 0.0\n",
    "\n",
    "def extract_dt_distribuicao(text: str) -> str:\n",
    "    t = strip_accents(clean_text(text)).lower()\n",
    "    for pattern in [\n",
    "        r\"\\b(20\\d{2})-(0[1-9]|1[0-2])-(0[1-9]|[12]\\d|3[01])\\b\",   # ISO\n",
    "        r\"\\b(0?[1-9]|[12]\\d|3[01])[/\\-](0?[1-9]|1[0-2])[/\\-](20\\d{2})\\b\", # dd/mm/yyyy\n",
    "    ]:\n",
    "        m = re.search(pattern, t)\n",
    "        if m:\n",
    "            parts = m.groups()\n",
    "            if len(parts) == 3 and parts[0].startswith(\"20\"):\n",
    "                y, mm, dd = parts[0], parts[1], parts[2]\n",
    "            else:\n",
    "                dd, mm, y = parts[0], parts[1], parts[2]\n",
    "            return f\"{y}-{mm.zfill(2)}-{dd.zfill(2)}\"\n",
    "    return \"\"\n",
    "\n",
    "def classify_tipo_vara(text: str) -> str:\n",
    "    t = strip_accents(clean_text(text)).lower()\n",
    "    if \"juizado especial\" in t or \"jecc\" in t:\n",
    "        return \"JE\"\n",
    "    return \"G1\"\n",
    "\n",
    "def extract_uf(text: str) -> str:\n",
    "    tokens = re.findall(r\"\\b[A-Z]{2}\\b\", text.upper())\n",
    "    for tk in tokens:\n",
    "        if tk in UF_LIST:\n",
    "            return tk\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a8e0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair nome de empresas\n",
    "\n",
    "def extract_nome_empresa(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Captura nomes de empresas no polo passivo.\n",
    "    Ex: BANCO DO BRASIL S.A., BANCO SANTANDER S/A, BRADESCO, etc.\n",
    "    \"\"\"\n",
    "    t = clean_text(text).upper()\n",
    "    m = re.search(r\"(BANCO [A-Z ]{2,}(?:S\\.?A\\.?|S\\/A|LTDA|EIRELI|ME)?)\", t)\n",
    "    if m:\n",
    "        return m.group(1).strip(\" ,;\")\n",
    "    m = re.search(r\"([A-Z ]{2,}(?:S\\.?A\\.?|S\\/A|LTDA|EIRELI|ME))\", t)\n",
    "    if m:\n",
    "        return m.group(1).strip(\" ,;\")\n",
    "    return \"vazio\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4b04838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- CNPJ: validação e parsing ----------------\n",
    "def cnpj_is_valid(cnpj_digits: str) -> bool:\n",
    "    \"\"\"Valida dígitos verificadores do CNPJ (14 dígitos).\"\"\"\n",
    "    if len(cnpj_digits) != 14 or len(set(cnpj_digits)) == 1:\n",
    "        return False\n",
    "    nums = [int(x) for x in cnpj_digits]\n",
    "    for i in [12, 13]:\n",
    "        if i == 12: pesos = [5,4,3,2,9,8,7,6,5,4,3,2]\n",
    "        else:       pesos = [6,5,4,3,2,9,8,7,6,5,4,3,2]\n",
    "        soma = sum(a*b for a,b in zip(nums[:i], pesos))\n",
    "        dig = 11 - (soma % 11)\n",
    "        dig = 0 if dig >= 10 else dig\n",
    "        if nums[i] != dig: \n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def find_cnpjs_pos(text: str) -> List[Tuple[str,int]]:\n",
    "    \"\"\"Encontra CNPJs válidos e suas posições no texto.\"\"\"\n",
    "    out = []\n",
    "    for m in re.finditer(r\"\\b\\d{2}\\.?\\d{3}\\.?\\d{3}/?\\d{4}-?\\d{2}\\b\", text):\n",
    "        digits = re.sub(r\"\\D\", \"\", m.group(0))\n",
    "        if len(digits) == 14 and cnpj_is_valid(digits):\n",
    "            out.append((digits, m.start()))\n",
    "    return out\n",
    "\n",
    "# ---------------- Empresa: nome e span ----------------\n",
    "_COMPANY_SUFFIX = r\"(?:S\\.?A\\.?|S\\/A|LTDA|EIRELI|ME)\"\n",
    "def find_company_spans(text: str) -> List[Tuple[str,int,int]]:\n",
    "    \"\"\"\n",
    "    Retorna [(nome, start, end), ...] para empresas típicas no polo passivo.\n",
    "    Captura 'BANCO ...', ou qualquer bloco com sufixo societário.\n",
    "    \"\"\"\n",
    "    T = clean_text(text).upper()\n",
    "    spans = []\n",
    "    # 1) BANCO ...\n",
    "    for m in re.finditer(r\"(BANCO(?: [A-Z0-9&'\\.\\-]{2,}){1,8})\", T):\n",
    "        name = m.group(1).strip(\" ,;\")\n",
    "        spans.append((name, m.start(1), m.end(1)))\n",
    "    # 2) QUALQUER NOME COM SUFIXO SOCIETÁRIO\n",
    "    for m in re.finditer(rf\"([A-Z0-9][A-Z0-9 \\.&'\\-]{{2,}}{_COMPANY_SUFFIX})\", T):\n",
    "        name = m.group(1).strip(\" ,;\")\n",
    "        spans.append((name, m.start(1), m.end(1)))\n",
    "    # dedup por nome\n",
    "    seen, uniq = set(), []\n",
    "    for n,s,e in spans:\n",
    "        if n not in seen:\n",
    "            uniq.append((n,s,e))\n",
    "            seen.add(n)\n",
    "    return uniq\n",
    "\n",
    "def pick_company_and_cnpjs(text: str, win_after=200, win_before=100) -> Tuple[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Escolhe UM nome de empresa e os CNPJs que estão próximos a esse nome.\n",
    "    Regra: prioriza o primeiro span; se sem CNPJ no entorno, tenta o próximo; \n",
    "    se nada, usa primeiro CNPJ válido da qualificação.\n",
    "    \"\"\"\n",
    "    T = clean_text(text)\n",
    "    companies = find_company_spans(T)\n",
    "    cnpjs_pos = find_cnpjs_pos(T)\n",
    "\n",
    "    # helper: cnpjs próximos a um span\n",
    "    def cnpjs_near(start, end):\n",
    "        near = []\n",
    "        for cnpj, pos in cnpjs_pos:\n",
    "            if (start - win_before) <= pos <= (end + win_after):\n",
    "                near.append(cnpj)\n",
    "        return sorted(set(near))\n",
    "\n",
    "    # tenta associar por proximidade\n",
    "    for name, s, e in companies:\n",
    "        near = cnpjs_near(s, e)\n",
    "        if near:\n",
    "            return name, near\n",
    "\n",
    "    # fallback: sem nome confiável, usa primeiro CNPJ válido (se houver)\n",
    "    if cnpjs_pos:\n",
    "        return \"vazio\", [cnpjs_pos[0][0]]\n",
    "\n",
    "    return \"vazio\", []\n",
    "\n",
    "# ---------------- Outros campos (ajustes leves) ----------------\n",
    "def extract_valor_causa_priorizando_label(text: str) -> float:\n",
    "    \"\"\"\n",
    "    Procura primeiro números próximos a 'valor da causa' (janela curta).\n",
    "    Se não achar, cai no maior valor do texto.\n",
    "    \"\"\"\n",
    "    T = clean_text(text)\n",
    "    # janela +/- 80 chars ao redor de 'valor da causa'\n",
    "    for m in re.finditer(r\"valor (?:da|de) causa\", strip_accents(T).lower()):\n",
    "        a, b = max(0, m.start()-80), m.end()+80\n",
    "        trecho = T[a:b]\n",
    "        nums = re.findall(r\"(?:R\\$\\s*)?(\\d{1,3}(?:\\.\\d{3})*,\\d{2}|\\d+,\\d{2})\", trecho)\n",
    "        if nums:\n",
    "            vals = [float(v.replace(\".\",\"\").replace(\",\", \".\")) for v in nums]\n",
    "            return max(vals)\n",
    "    # fallback: maior do texto\n",
    "    nums = re.findall(r\"(?:R\\$\\s*)?(\\d{1,3}(?:\\.\\d{3})*,\\d{2}|\\d+,\\d{2})\", T)\n",
    "    vals = [float(v.replace(\".\",\"\").replace(\",\", \".\")) for v in nums]\n",
    "    return max(vals) if vals else 0.0\n",
    "\n",
    "def extract_dt_distribuicao(text: str) -> str:\n",
    "    t = strip_accents(clean_text(text)).lower()\n",
    "    m = re.search(r\"\\b(20\\d{2})-(0[1-9]|1[0-2])-(0[1-9]|[12]\\d|3[01])\\b\", t)\n",
    "    if m: return f\"{m.group(1)}-{m.group(2)}-{m.group(3)}\"\n",
    "    m = re.search(r\"\\b(0?[1-9]|[12]\\d|3[01])[/\\-](0?[1-9]|1[0-2])[/\\-](20\\d{2})\\b\", t)\n",
    "    if m:\n",
    "        dd, mm, y = int(m.group(1)), int(m.group(2)), int(m.group(3))\n",
    "        return f\"{y:04d}-{mm:02d}-{dd:02d}\"\n",
    "    return \"\"\n",
    "\n",
    "def classify_tipo_vara(text: str) -> str:\n",
    "    t = strip_accents(clean_text(text)).lower()\n",
    "    return \"JE\" if (\"juizado especial\" in t or \"jecc\" in t) else \"G1\"\n",
    "\n",
    "def extract_uf(text: str) -> str:\n",
    "    for tok in re.findall(r\"\\b[A-Z]{2}\\b\", clean_text(text).upper()):\n",
    "        if tok in UF_LIST:\n",
    "            return tok\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e3eea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_colunas(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Usa principalmente a 'ds_Qualificacao' (onde normalmente aparece o polo passivo),\n",
    "    mas consulta 'ds_fatos' e 'ds_Pedidos' para valor e data.\n",
    "    \"\"\"\n",
    "    qual = df.get(\"ds_Qualificacao\", \"\").astype(str)\n",
    "    fatos = df.get(\"ds_fatos\", \"\").astype(str)\n",
    "    pedidos = df.get(\"ds_Pedidos\", \"\").astype(str)\n",
    "\n",
    "    # nome + cnpjs amarrados por proximidade\n",
    "    pares = qual.map(lambda t: pick_company_and_cnpjs(t))\n",
    "    nome_empresa = pares.map(lambda x: x[0])\n",
    "    cnpjs = pares.map(lambda x: \",\".join(x[1]) if x[1] else \"vazio\")\n",
    "\n",
    "    texto_valor = (fatos + \" \" + pedidos).astype(str)\n",
    "    texto_data  = (pedidos + \" \" + qual).astype(str)\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"cd_atendimento\": df[\"cd_atendimento\"].astype(str),\n",
    "        \"nome_empresa\": nome_empresa,\n",
    "        \"cnpj\": cnpjs,\n",
    "        \"valor_causa\": texto_valor.map(extract_valor_causa_priorizando_label),\n",
    "        \"dt_distribuicao\": texto_data.map(extract_dt_distribuicao),\n",
    "        \"tipo_vara\": qual.map(classify_tipo_vara),\n",
    "        \"uf\": qual.map(extract_uf),\n",
    "    })\n",
    "\n",
    "    out.to_excel(\"output_colunas.xlsx\", index=False)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73e01ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cd_atendimento</th>\n",
       "      <th>nome_empresa</th>\n",
       "      <th>cnpj</th>\n",
       "      <th>valor_causa</th>\n",
       "      <th>dt_distribuicao</th>\n",
       "      <th>tipo_vara</th>\n",
       "      <th>uf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0825789-84.2025.8.18.0140</td>\n",
       "      <td>BANCO BRADESCO FINANCIAMENTOS</td>\n",
       "      <td>07207996000150</td>\n",
       "      <td>21906.64</td>\n",
       "      <td>2025-05-14</td>\n",
       "      <td>G1</td>\n",
       "      <td>PI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1004697-72.2025.8.26.0066</td>\n",
       "      <td>BANCO BRADESCO S.A</td>\n",
       "      <td>60746948000112</td>\n",
       "      <td>10000.00</td>\n",
       "      <td></td>\n",
       "      <td>G1</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0800423-07.2025.8.15.0761</td>\n",
       "      <td>BANCO DO BRADESCO S.A</td>\n",
       "      <td>60746948000112</td>\n",
       "      <td>11409.08</td>\n",
       "      <td>2025-05-22</td>\n",
       "      <td>G1</td>\n",
       "      <td>PB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004875-69.2025.8.26.0438</td>\n",
       "      <td>BANCO BRADESCO</td>\n",
       "      <td>60746948000112</td>\n",
       "      <td>11256.04</td>\n",
       "      <td></td>\n",
       "      <td>G1</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0010630-50.2025.8.27.2706</td>\n",
       "      <td>BANCO BRADESCO S.A.</td>\n",
       "      <td>60746948000112</td>\n",
       "      <td>15215.42</td>\n",
       "      <td></td>\n",
       "      <td>G1</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0092601-36.2025.8.05.0001</td>\n",
       "      <td>vazio</td>\n",
       "      <td>vazio</td>\n",
       "      <td>15000.00</td>\n",
       "      <td></td>\n",
       "      <td>G1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0801575-51.2025.8.18.0068</td>\n",
       "      <td>BANCO BRADESCO S.A.</td>\n",
       "      <td>60746948000112</td>\n",
       "      <td>5159.84</td>\n",
       "      <td>2025-06-02</td>\n",
       "      <td>G1</td>\n",
       "      <td>PI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0801452-38.2025.8.18.0073</td>\n",
       "      <td>E BRADESCO SEGUROS S/A</td>\n",
       "      <td>33055146004776</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2017-02-21</td>\n",
       "      <td>G1</td>\n",
       "      <td>PI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0800895-81.2025.8.10.0038</td>\n",
       "      <td>vazio</td>\n",
       "      <td>vazio</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2025-05-19</td>\n",
       "      <td>G1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0148716-17.2025.8.04.1000</td>\n",
       "      <td>BANCO BRADESCO S.A INSCRITO NO CNPJ 60.746.948</td>\n",
       "      <td>60746948000112</td>\n",
       "      <td>16804.00</td>\n",
       "      <td></td>\n",
       "      <td>G1</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cd_atendimento                                    nome_empresa  \\\n",
       "0  0825789-84.2025.8.18.0140                   BANCO BRADESCO FINANCIAMENTOS   \n",
       "1  1004697-72.2025.8.26.0066                              BANCO BRADESCO S.A   \n",
       "2  0800423-07.2025.8.15.0761                           BANCO DO BRADESCO S.A   \n",
       "3  1004875-69.2025.8.26.0438                                  BANCO BRADESCO   \n",
       "4  0010630-50.2025.8.27.2706                             BANCO BRADESCO S.A.   \n",
       "5  0092601-36.2025.8.05.0001                                           vazio   \n",
       "6  0801575-51.2025.8.18.0068                             BANCO BRADESCO S.A.   \n",
       "7  0801452-38.2025.8.18.0073                          E BRADESCO SEGUROS S/A   \n",
       "8  0800895-81.2025.8.10.0038                                           vazio   \n",
       "9  0148716-17.2025.8.04.1000  BANCO BRADESCO S.A INSCRITO NO CNPJ 60.746.948   \n",
       "\n",
       "             cnpj  valor_causa dt_distribuicao tipo_vara  uf  \n",
       "0  07207996000150     21906.64      2025-05-14        G1  PI  \n",
       "1  60746948000112     10000.00                        G1  SP  \n",
       "2  60746948000112     11409.08      2025-05-22        G1  PB  \n",
       "3  60746948000112     11256.04                        G1  SP  \n",
       "4  60746948000112     15215.42                        G1  TO  \n",
       "5           vazio     15000.00                        G1      \n",
       "6  60746948000112      5159.84      2025-06-02        G1  PI  \n",
       "7  33055146004776         0.00      2017-02-21        G1  PI  \n",
       "8           vazio         0.00      2025-05-19        G1      \n",
       "9  60746948000112     16804.00                        G1  AM  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultado = criar_colunas(df)\n",
    "display(resultado.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36608f51",
   "metadata": {},
   "source": [
    "## Análise de Erros e Melhorias\n",
    "\n",
    "Vamos analisar o arquivo de correção para identificar padrões de erro e propor melhorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb481246",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'plano-ensino/grupo_3-correcao.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Carrega e analisa o arquivo de correção\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m correcao \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplano-ensino/grupo_3-correcao.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRESUMO GERAL DE ACERTOS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/7o-semestre/direito/clinicas-2/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/7o-semestre/direito/clinicas-2/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Desktop/7o-semestre/direito/clinicas-2/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/7o-semestre/direito/clinicas-2/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Desktop/7o-semestre/direito/clinicas-2/venv/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'plano-ensino/grupo_3-correcao.csv'"
     ]
    }
   ],
   "source": [
    "# Carrega e analisa o arquivo de correção\n",
    "correcao = pd.read_csv(\"plano-ensino/grupo_3-correcao.csv\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RESUMO GERAL DE ACERTOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calcula taxa de acerto por campo\n",
    "campos = ['cnpj', 'valor_causa', 'dt_distribuicao', 'tipo_vara', 'uf']\n",
    "for campo in campos:\n",
    "    col_acerto = f\"{campo}_acertou\"\n",
    "    if col_acerto in correcao.columns:\n",
    "        # Conta apenas os não-vazios\n",
    "        validos = correcao[col_acerto].notna()\n",
    "        acertos = (correcao[col_acerto] == \"VERDADEIRO\").sum()\n",
    "        erros = (correcao[col_acerto] == \"FALSO\").sum()\n",
    "        total = acertos + erros\n",
    "        \n",
    "        if total > 0:\n",
    "            taxa = (acertos / total) * 100\n",
    "            print(f\"\\n{campo.upper():20s}: {acertos:2d}/{total:2d} ({taxa:5.1f}%) ✓  |  {erros:2d} erros ✗\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CASOS COM ERRO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Mostra casos com erro em cada campo\n",
    "for campo in campos:\n",
    "    col_acerto = f\"{campo}_acertou\"\n",
    "    if col_acerto in correcao.columns:\n",
    "        erros_campo = correcao[correcao[col_acerto] == \"FALSO\"]\n",
    "        if len(erros_campo) > 0:\n",
    "            print(f\"\\n--- ERROS EM {campo.upper()} ({len(erros_campo)} casos) ---\")\n",
    "            for _, row in erros_campo.iterrows():\n",
    "                resposta = row[f\"{campo}_resposta\"]\n",
    "                gabarito = row[f\"{campo}_gabarito\"]\n",
    "                cd = row['cd_atendimento']\n",
    "                print(f\"  {cd}: '{resposta}' ≠ '{gabarito}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d127a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos investigar os casos problemáticos no dataset original\n",
    "casos_problema = [\n",
    "    '0001977-19.2025.8.17.2001',  # CNPJ não encontrado (retornou 'vazio')\n",
    "    '1015310-63.2025.8.26.0451',  # CNPJ não encontrado (retornou 'vazio')\n",
    "    '1000512-48.2025.8.26.0629',  # Faltou CNPJ e valor errado (2 bilhões!)\n",
    "    '5005789-05.2025.8.13.0672',  # Faltou um CNPJ\n",
    "    '5000199-56.2025.8.21.0015',  # Faltou CNPJ e valor errado\n",
    "]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"INVESTIGANDO CASOS COM ERRO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for cd in casos_problema:\n",
    "    caso = df[df['cd_atendimento'] == cd]\n",
    "    if len(caso) > 0:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"CASO: {cd}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Mostra a qualificação (onde geralmente está o CNPJ)\n",
    "        qual = str(caso.iloc[0]['ds_Qualificacao'])\n",
    "        print(f\"\\n--- ds_Qualificacao ---\")\n",
    "        print(qual[:800] if len(qual) > 800 else qual)\n",
    "        \n",
    "        # Mostra fatos e pedidos (onde geralmente está o valor)\n",
    "        fatos = str(caso.iloc[0]['ds_fatos'])\n",
    "        print(f\"\\n--- ds_fatos (primeiros 500 chars) ---\")\n",
    "        print(fatos[:500] if len(fatos) > 500 else fatos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb348f99",
   "metadata": {},
   "source": [
    "## Problemas Identificados e Soluções\n",
    "\n",
    "Com base na análise, identifiquei os seguintes problemas:\n",
    "\n",
    "### 1. **CNPJ** (3 erros)\n",
    "- **Problema**: Alguns CNPJs não estão sendo encontrados\n",
    "- **Possíveis causas**:\n",
    "  - CNPJ pode estar em outras colunas além de `ds_Qualificacao`\n",
    "  - CNPJ pode estar muito distante do nome da empresa (> 200 chars)\n",
    "  - Pode haver múltiplos CNPJs e estamos pegando apenas os próximos ao primeiro nome\n",
    "  \n",
    "### 2. **Data de Distribuição** (6 erros)\n",
    "- **Problema**: Datas incorretas sendo extraídas\n",
    "- **Possíveis causas**:\n",
    "  - Múltiplas datas no texto (outras datas de eventos processuais)\n",
    "  - Data está em formato diferente (ex: \"28 de junho de 2025\")\n",
    "  - Estamos pegando a data errada quando há várias\n",
    "\n",
    "### 3. **Valor da Causa** (3 erros)\n",
    "- **Problema**: Valores muito errados (ex: R$ 2 bilhões)\n",
    "- **Possíveis causas**:\n",
    "  - Números grandes sem separadores sendo interpretados incorretamente\n",
    "  - Pegando valores de outros contextos (honorários, custas, etc.)\n",
    "\n",
    "### 4. **UF e Tipo de Vara** \n",
    "- ✅ **100% de acerto!** Essas funções estão funcionando bem.\n",
    "\n",
    "---\n",
    "\n",
    "## Melhorias Propostas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cca5a11",
   "metadata": {},
   "source": [
    "### Versão Melhorada 1: CNPJ - Busca em Todas as Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e83338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_company_and_cnpjs_v2(text: str, win_after=300, win_before=150) -> Tuple[str, List[str]]:\n",
    "    \"\"\"\n",
    "    VERSÃO MELHORADA:\n",
    "    - Janela de busca maior (300 chars depois, 150 antes)\n",
    "    - Se não encontrar CNPJ próximo, retorna TODOS os CNPJs válidos do texto\n",
    "    - Prioriza CNPJs próximos, mas não descarta os distantes\n",
    "    \"\"\"\n",
    "    T = clean_text(text)\n",
    "    companies = find_company_spans(T)\n",
    "    cnpjs_pos = find_cnpjs_pos(T)\n",
    "\n",
    "    # helper: cnpjs próximos a um span\n",
    "    def cnpjs_near(start, end):\n",
    "        near = []\n",
    "        for cnpj, pos in cnpjs_pos:\n",
    "            if (start - win_before) <= pos <= (end + win_after):\n",
    "                near.append(cnpj)\n",
    "        return sorted(set(near))\n",
    "\n",
    "    # 1) Tenta associar por proximidade\n",
    "    for name, s, e in companies:\n",
    "        near = cnpjs_near(s, e)\n",
    "        if near:\n",
    "            return name, near\n",
    "\n",
    "    # 2) Fallback melhorado: retorna TODOS os CNPJs válidos (não apenas o primeiro)\n",
    "    if cnpjs_pos:\n",
    "        all_cnpjs = sorted(set([cnpj for cnpj, _ in cnpjs_pos]))\n",
    "        # Se tem empresa mas sem CNPJ próximo, associa todos os CNPJs à primeira empresa\n",
    "        if companies:\n",
    "            return companies[0][0], all_cnpjs\n",
    "        return \"vazio\", all_cnpjs\n",
    "\n",
    "    return \"vazio\", []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0f061b",
   "metadata": {},
   "source": [
    "### Versão Melhorada 2: Data - Prioriza Label \"Distribuição\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913ed72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dt_distribuicao_v2(text: str) -> str:\n",
    "    \"\"\"\n",
    "    VERSÃO MELHORADA:\n",
    "    1. Procura data próxima a \"distribuição\", \"distribuído\", \"autuação\"\n",
    "    2. Aceita formatos: DD/MM/YYYY, DD-MM-YYYY, YYYY-MM-DD\n",
    "    3. Aceita datas por extenso: \"28 de junho de 2025\"\n",
    "    4. Se não achar próximo ao label, pega a PRIMEIRA data em formato 2025 (ano atual/futuro)\n",
    "    \"\"\"\n",
    "    t_original = clean_text(text)\n",
    "    t = strip_accents(t_original).lower()\n",
    "    \n",
    "    # 1) Procura próximo a labels específicos (janela de ±100 chars)\n",
    "    labels = [r\"distribui[cç][aã]o\", r\"distribuido\", r\"autuado\", r\"autua[cç][aã]o\"]\n",
    "    for label_pattern in labels:\n",
    "        for m in re.finditer(label_pattern, t):\n",
    "            a, b = max(0, m.start()-100), m.end()+100\n",
    "            trecho = t[a:b]\n",
    "            \n",
    "            # Tenta ISO primeiro\n",
    "            match = re.search(r\"\\b(20\\d{2})-(0[1-9]|1[0-2])-(0[1-9]|[12]\\d|3[01])\\b\", trecho)\n",
    "            if match:\n",
    "                return f\"{match.group(1)}-{match.group(2)}-{match.group(3)}\"\n",
    "            \n",
    "            # Tenta DD/MM/YYYY ou DD-MM-YYYY\n",
    "            match = re.search(r\"\\b(0?[1-9]|[12]\\d|3[01])[/\\-](0?[1-9]|1[0-2])[/\\-](20\\d{2})\\b\", trecho)\n",
    "            if match:\n",
    "                dd, mm, y = int(match.group(1)), int(match.group(2)), int(match.group(3))\n",
    "                return f\"{y:04d}-{mm:02d}-{dd:02d}\"\n",
    "    \n",
    "    # 2) Tenta data por extenso: \"DD de MMMM de YYYY\"\n",
    "    for mes_nome, mes_num in MESES_PT.items():\n",
    "        pattern = rf\"\\b(\\d{{1,2}})\\s+de\\s+{mes_nome}\\s+de\\s+(20\\d{{2}})\\b\"\n",
    "        match = re.search(pattern, t)\n",
    "        if match:\n",
    "            dd, y = int(match.group(1)), int(match.group(2))\n",
    "            if 1 <= dd <= 31:\n",
    "                return f\"{y:04d}-{mes_num:02d}-{dd:02d}\"\n",
    "    \n",
    "    # 3) Fallback: primeira data ISO encontrada\n",
    "    match = re.search(r\"\\b(20\\d{2})-(0[1-9]|1[0-2])-(0[1-9]|[12]\\d|3[01])\\b\", t)\n",
    "    if match:\n",
    "        return f\"{match.group(1)}-{match.group(2)}-{match.group(3)}\"\n",
    "    \n",
    "    # 4) Fallback final: primeira data DD/MM/YYYY\n",
    "    match = re.search(r\"\\b(0?[1-9]|[12]\\d|3[01])[/\\-](0?[1-9]|1[0-2])[/\\-](20\\d{2})\\b\", t)\n",
    "    if match:\n",
    "        dd, mm, y = int(match.group(1)), int(match.group(2)), int(match.group(3))\n",
    "        return f\"{y:04d}-{mm:02d}-{dd:02d}\"\n",
    "    \n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f60709",
   "metadata": {},
   "source": [
    "### Versão Melhorada 3: Valor da Causa - Validação de Razoabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af09ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_valor_causa_v2(text: str) -> float:\n",
    "    \"\"\"\n",
    "    VERSÃO MELHORADA:\n",
    "    1. Procura primeiro próximo a \"valor da causa\" (janela de ±100 chars)\n",
    "    2. Valida que valores fazem sentido (entre R$ 100 e R$ 10 milhões)\n",
    "    3. Ignora valores muito grandes (provavelmente erros de parsing)\n",
    "    4. Prioriza valores com separador de milhar correto\n",
    "    \"\"\"\n",
    "    T = clean_text(text)\n",
    "    t_lower = strip_accents(T).lower()\n",
    "    \n",
    "    # Limites razoáveis para valor da causa em ações de crédito consignado\n",
    "    MIN_VALOR = 100.0\n",
    "    MAX_VALOR = 10_000_000.0  # 10 milhões\n",
    "    \n",
    "    # 1) Procura próximo a \"valor da causa\" (janela de ±100 chars)\n",
    "    for m in re.finditer(r\"valor\\s+(?:da|de)\\s+causa\", t_lower):\n",
    "        a, b = max(0, m.start()-100), m.end()+100\n",
    "        trecho = T[a:b]\n",
    "        \n",
    "        # Encontra valores no trecho\n",
    "        nums = re.findall(r\"(?:R\\$\\s*)?(\\d{1,3}(?:\\.\\d{3})*,\\d{2})\", trecho)\n",
    "        if nums:\n",
    "            vals = []\n",
    "            for v in nums:\n",
    "                valor = float(v.replace(\".\", \"\").replace(\",\", \".\"))\n",
    "                # Valida se está em range razoável\n",
    "                if MIN_VALOR <= valor <= MAX_VALOR:\n",
    "                    vals.append(valor)\n",
    "            if vals:\n",
    "                return max(vals)  # Retorna o maior valor razoável encontrado\n",
    "    \n",
    "    # 2) Fallback: procura em todo o texto, mas com validação\n",
    "    # Padrão mais rigoroso: exige separador de milhar OU valores pequenos\n",
    "    nums_formatados = re.findall(r\"(?:R\\$\\s*)?(\\d{1,3}(?:\\.\\d{3})+,\\d{2})\", T)  # Com separador\n",
    "    nums_simples = re.findall(r\"(?:R\\$\\s*)?(\\d{1,5},\\d{2})\\b\", T)  # Sem separador (até 99.999)\n",
    "    \n",
    "    todos_nums = nums_formatados + nums_simples\n",
    "    vals_validos = []\n",
    "    \n",
    "    for v in todos_nums:\n",
    "        valor = float(v.replace(\".\", \"\").replace(\",\", \".\"))\n",
    "        if MIN_VALOR <= valor <= MAX_VALOR:\n",
    "            vals_validos.append(valor)\n",
    "    \n",
    "    if vals_validos:\n",
    "        return max(vals_validos)\n",
    "    \n",
    "    # 3) Último recurso: aceita qualquer valor, mas limita\n",
    "    nums_all = re.findall(r\"(?:R\\$\\s*)?(\\d+,\\d{2})\", T)\n",
    "    if nums_all:\n",
    "        vals = []\n",
    "        for v in nums_all:\n",
    "            valor = float(v.replace(\".\", \"\").replace(\",\", \".\"))\n",
    "            # Limita ao máximo permitido\n",
    "            if valor <= MAX_VALOR:\n",
    "                vals.append(valor)\n",
    "        if vals:\n",
    "            return max(vals)\n",
    "    \n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ad604b",
   "metadata": {},
   "source": [
    "### Função Principal Melhorada - criar_colunas_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f38e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_colunas_v2(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    VERSÃO MELHORADA que usa todas as funções v2.\n",
    "    \n",
    "    Melhorias principais:\n",
    "    - Busca CNPJs em TODAS as colunas de texto (não só ds_Qualificacao)\n",
    "    - Janela maior para proximidade (300 chars)\n",
    "    - Validação de valores razoáveis\n",
    "    - Priorização de labels específicos para data e valor\n",
    "    \"\"\"\n",
    "    qual = df.get(\"ds_Qualificacao\", \"\").astype(str)\n",
    "    fatos = df.get(\"ds_fatos\", \"\").astype(str)\n",
    "    pedidos = df.get(\"ds_Pedidos\", \"\").astype(str)\n",
    "    acao = df.get(\"ds_Acao_Judicial\", \"\").astype(str)\n",
    "    \n",
    "    # Concatena TODAS as colunas para buscar CNPJ (aumenta chance de encontrar)\n",
    "    texto_completo = (qual + \" \" + fatos + \" \" + pedidos + \" \" + acao).astype(str)\n",
    "    \n",
    "    # nome + cnpjs amarrados por proximidade (usando versão melhorada)\n",
    "    pares = texto_completo.map(lambda t: pick_company_and_cnpjs_v2(t))\n",
    "    nome_empresa = pares.map(lambda x: x[0])\n",
    "    cnpjs = pares.map(lambda x: \",\".join(x[1]) if x[1] else \"vazio\")\n",
    "\n",
    "    # Usa versões melhoradas das funções\n",
    "    texto_valor = (fatos + \" \" + pedidos).astype(str)\n",
    "    texto_data  = (pedidos + \" \" + qual + \" \" + acao).astype(str)\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"cd_atendimento\": df[\"cd_atendimento\"].astype(str),\n",
    "        \"nome_empresa\": nome_empresa,\n",
    "        \"cnpj\": cnpjs,\n",
    "        \"valor_causa\": texto_valor.map(extract_valor_causa_v2),\n",
    "        \"dt_distribuicao\": texto_data.map(extract_dt_distribuicao_v2),\n",
    "        \"tipo_vara\": qual.map(classify_tipo_vara),\n",
    "        \"uf\": qual.map(extract_uf),\n",
    "    })\n",
    "\n",
    "    out.to_excel(\"output_colunas_v2.xlsx\", index=False)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd495a80",
   "metadata": {},
   "source": [
    "### Teste e Comparação - Versão Original vs Melhorada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dee808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executa a versão melhorada\n",
    "print(\"Executando versão MELHORADA...\")\n",
    "resultado_v2 = criar_colunas_v2(df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARAÇÃO: Casos Problemáticos\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Testa nos casos que tinham erro\n",
    "casos_teste = correcao['cd_atendimento'].tolist()\n",
    "\n",
    "for cd in casos_teste[:5]:  # Mostra os primeiros 5 como exemplo\n",
    "    # Versão original\n",
    "    v1 = resultado[resultado['cd_atendimento'] == cd]\n",
    "    # Versão melhorada\n",
    "    v2 = resultado_v2[resultado_v2['cd_atendimento'] == cd]\n",
    "    # Gabarito\n",
    "    gab = correcao[correcao['cd_atendimento'] == cd]\n",
    "    \n",
    "    if len(v1) > 0 and len(v2) > 0 and len(gab) > 0:\n",
    "        print(f\"\\n{cd}:\")\n",
    "        print(f\"  CNPJ:\")\n",
    "        print(f\"    Original:  {v1.iloc[0]['cnpj']}\")\n",
    "        print(f\"    Melhorado: {v2.iloc[0]['cnpj']}\")\n",
    "        print(f\"    Gabarito:  {gab.iloc[0]['cnpj_gabarito']}\")\n",
    "        \n",
    "        print(f\"  Valor:\")\n",
    "        print(f\"    Original:  R$ {v1.iloc[0]['valor_causa']:,.2f}\")\n",
    "        print(f\"    Melhorado: R$ {v2.iloc[0]['valor_causa']:,.2f}\")\n",
    "        print(f\"    Gabarito:  R$ {float(gab.iloc[0]['valor_causa_gabarito']):,.2f}\")\n",
    "        \n",
    "        print(f\"  Data:\")\n",
    "        print(f\"    Original:  {v1.iloc[0]['dt_distribuicao']}\")\n",
    "        print(f\"    Melhorado: {v2.iloc[0]['dt_distribuicao']}\")\n",
    "        print(f\"    Gabarito:  {gab.iloc[0]['dt_distribuicao_gabarito']}\")\n",
    "\n",
    "print(\"\\n\\n✅ Arquivo 'output_colunas_v2.xlsx' criado com as melhorias!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941db94a",
   "metadata": {},
   "source": [
    "### Validação Automática - Calcula Taxa de Acerto da Versão Melhorada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278483c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valida a versão melhorada contra o gabarito\n",
    "def validar_resultados(resultado_df, gabarito_df):\n",
    "    \"\"\"Compara resultados com gabarito e calcula acertos.\"\"\"\n",
    "    stats = {\n",
    "        'cnpj': {'acertos': 0, 'erros': 0},\n",
    "        'valor_causa': {'acertos': 0, 'erros': 0},\n",
    "        'dt_distribuicao': {'acertos': 0, 'erros': 0},\n",
    "        'tipo_vara': {'acertos': 0, 'erros': 0},\n",
    "        'uf': {'acertos': 0, 'erros': 0},\n",
    "    }\n",
    "    \n",
    "    for _, gab_row in gabarito_df.iterrows():\n",
    "        cd = gab_row['cd_atendimento']\n",
    "        res_row = resultado_df[resultado_df['cd_atendimento'] == cd]\n",
    "        \n",
    "        if len(res_row) == 0:\n",
    "            continue\n",
    "        res_row = res_row.iloc[0]\n",
    "        \n",
    "        # CNPJ\n",
    "        if pd.notna(gab_row['cnpj_gabarito']) and gab_row['cnpj_gabarito'] != '':\n",
    "            if str(res_row['cnpj']) == str(gab_row['cnpj_gabarito']):\n",
    "                stats['cnpj']['acertos'] += 1\n",
    "            else:\n",
    "                stats['cnpj']['erros'] += 1\n",
    "        \n",
    "        # Valor (com tolerância de 1%)\n",
    "        if pd.notna(gab_row['valor_causa_gabarito']):\n",
    "            diff = abs(res_row['valor_causa'] - float(gab_row['valor_causa_gabarito']))\n",
    "            if diff < float(gab_row['valor_causa_gabarito']) * 0.01:  # tolerância 1%\n",
    "                stats['valor_causa']['acertos'] += 1\n",
    "            else:\n",
    "                stats['valor_causa']['erros'] += 1\n",
    "        \n",
    "        # Data\n",
    "        if pd.notna(gab_row['dt_distribuicao_gabarito']) and gab_row['dt_distribuicao_gabarito'] != '':\n",
    "            # Normaliza formato de data do gabarito\n",
    "            gab_data = str(gab_row['dt_distribuicao_gabarito'])\n",
    "            if '/' in gab_data:\n",
    "                parts = gab_data.split('/')\n",
    "                if len(parts) == 3:\n",
    "                    gab_data = f\"{parts[2]}-{parts[0].zfill(2)}-{parts[1].zfill(2)}\"\n",
    "            \n",
    "            if str(res_row['dt_distribuicao']) == gab_data:\n",
    "                stats['dt_distribuicao']['acertos'] += 1\n",
    "            else:\n",
    "                stats['dt_distribuicao']['erros'] += 1\n",
    "        \n",
    "        # Tipo Vara\n",
    "        if pd.notna(gab_row['tipo_vara_gabarito']):\n",
    "            if str(res_row['tipo_vara']) == str(gab_row['tipo_vara_gabarito']):\n",
    "                stats['tipo_vara']['acertos'] += 1\n",
    "            else:\n",
    "                stats['tipo_vara']['erros'] += 1\n",
    "        \n",
    "        # UF\n",
    "        if pd.notna(gab_row['uf_gabarito']):\n",
    "            if str(res_row['uf']) == str(gab_row['uf_gabarito']):\n",
    "                stats['uf']['acertos'] += 1\n",
    "            else:\n",
    "                stats['uf']['erros'] += 1\n",
    "    \n",
    "    return stats\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMPARAÇÃO FINAL: VERSÃO ORIGINAL vs MELHORADA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "stats_v1 = validar_resultados(resultado, correcao)\n",
    "stats_v2 = validar_resultados(resultado_v2, correcao)\n",
    "\n",
    "for campo in ['cnpj', 'valor_causa', 'dt_distribuicao', 'tipo_vara', 'uf']:\n",
    "    total_v1 = stats_v1[campo]['acertos'] + stats_v1[campo]['erros']\n",
    "    total_v2 = stats_v2[campo]['acertos'] + stats_v2[campo]['erros']\n",
    "    \n",
    "    if total_v1 > 0:\n",
    "        taxa_v1 = (stats_v1[campo]['acertos'] / total_v1) * 100\n",
    "        taxa_v2 = (stats_v2[campo]['acertos'] / total_v2) * 100\n",
    "        melhoria = taxa_v2 - taxa_v1\n",
    "        \n",
    "        print(f\"\\n{campo.upper()}:\")\n",
    "        print(f\"  Original:  {stats_v1[campo]['acertos']:2d}/{total_v1:2d} ({taxa_v1:5.1f}%)\")\n",
    "        print(f\"  Melhorado: {stats_v2[campo]['acertos']:2d}/{total_v2:2d} ({taxa_v2:5.1f}%)\")\n",
    "        \n",
    "        if melhoria > 0:\n",
    "            print(f\"  ⬆️  Melhoria: +{melhoria:.1f}%\")\n",
    "        elif melhoria < 0:\n",
    "            print(f\"  ⬇️  Piora: {melhoria:.1f}%\")\n",
    "        else:\n",
    "            print(f\"  ➡️  Sem mudança\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659c76f4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📊 Resumo das Melhorias Implementadas\n",
    "\n",
    "### ✅ Principais Mudanças:\n",
    "\n",
    "#### 1. **CNPJ** (3 erros → esperamos 0-1 erros)\n",
    "- ✨ **Janela de proximidade maior**: 100→150 chars antes, 200→300 chars depois\n",
    "- ✨ **Busca em todas as colunas**: não apenas `ds_Qualificacao`, mas também `ds_fatos`, `ds_Pedidos`, `ds_Acao_Judicial`\n",
    "- ✨ **Fallback inteligente**: se não encontrar CNPJ próximo ao nome, retorna TODOS os CNPJs válidos do texto\n",
    "\n",
    "#### 2. **Data de Distribuição** (6 erros → esperamos 1-2 erros)\n",
    "- ✨ **Prioriza labels específicos**: busca primeiro próximo a \"distribuição\", \"distribuído\", \"autuação\"\n",
    "- ✨ **Suporte a datas por extenso**: \"28 de junho de 2025\"\n",
    "- ✨ **Múltiplos formatos**: DD/MM/YYYY, DD-MM-YYYY, YYYY-MM-DD\n",
    "- ✨ **Janela contextual**: ±100 chars ao redor do label\n",
    "\n",
    "#### 3. **Valor da Causa** (3 erros → esperamos 0 erros)\n",
    "- ✨ **Validação de razoabilidade**: valores entre R$ 100 e R$ 10 milhões\n",
    "- ✨ **Prioriza label \"valor da causa\"**: busca primeiro próximo ao termo específico\n",
    "- ✨ **Evita valores absurdos**: filtra valores mal formatados (ex: R$ 2 bilhões)\n",
    "- ✨ **Validação de formato**: prioriza valores com separador de milhar correto\n",
    "\n",
    "#### 4. **UF e Tipo de Vara**\n",
    "- ✅ **Já estavam perfeitos**: 100% de acerto, sem alterações necessárias\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 Meta de Melhoria:\n",
    "- **Antes**: ~85% de acerto geral\n",
    "- **Depois**: **~95-100%** de acerto geral (esperado)\n",
    "\n",
    "Execute as células acima para ver os resultados!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
