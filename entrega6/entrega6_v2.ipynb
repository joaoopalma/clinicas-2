{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfd3319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, site, platform\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Exe   :\", sys.executable)   # <-- este é o Python do seu kernel\n",
    "print(\"Site  :\", site.getsitepackages())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a44d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -U pip setuptools wheel\n",
    "!{sys.executable} -m pip install -U statsmodels\n",
    "!{sys.executable} -m pip install -U scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02d2535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels, statsmodels.api as sm\n",
    "import sklearn\n",
    "print(\"statsmodels:\", statsmodels.__version__)\n",
    "print(\"sklearn    :\", sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187676bf",
   "metadata": {},
   "source": [
    "# Entrega 6 - Extração de Dados Estruturados\n",
    "## Ciência de Dados Aplicada ao Direito II\n",
    "\n",
    "**Objetivo:** Extrair informações estruturadas dos casos de crédito consignado (já filtrados pela Entrega 5)\n",
    "\n",
    "### Fluxo de Trabalho:\n",
    "1. **Entrega 5** → Filtra casos de crédito consignado do dataset completo\n",
    "2. **Entrega 6** → Extrai informações detalhadas APENAS dos casos filtrados\n",
    "\n",
    "### Campos Extraídos:\n",
    "- `cd_atendimento`: ID do caso\n",
    "- `nome_empresa`: Nome da empresa no polo passivo\n",
    "- `cnpj`: CNPJ válido (14 dígitos)\n",
    "- `valor_causa`: Valor da causa em reais\n",
    "- `dt_distribuicao`: Data de distribuição (YYYY-MM-DD)\n",
    "- `tipo_vara`: JE (Juizado Especial) ou G1 (Vara Comum)\n",
    "- `uf`: Unidade Federativa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff33330",
   "metadata": {},
   "source": [
    "## Sumário Executivo\n",
    "\n",
    "### Como Usar Este Notebook\n",
    "\n",
    "1. **Instale as dependências** (célula 2 - opcional se já tiver instalado)\n",
    "2. **Execute todas as células em ordem** \n",
    "3. **Resultado:** Arquivo `output.xlsx` com 7 colunas (requisito do roteiro)\n",
    "4. **Opcional:** Execute seção 10.1 para gerar `output_expandido.xlsx` com análise de danos morais/materiais\n",
    "\n",
    "### Entrada de Dados\n",
    "\n",
    "O notebook carrega automaticamente `./dataset_filtrado.xlsx` (casos de crédito consignado já filtrados).\n",
    "Se não existir, tenta fallbacks alternativos.\n",
    "\n",
    "### Saídas\n",
    "\n",
    "- `output.xlsx`: 7 colunas do roteiro oficial\n",
    "- `output_expandido.xlsx`: 13 colunas incluindo danos morais/materiais (opcional)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e6e27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict\n",
    "from unidecode import unidecode\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import statsmodels.api as sm\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19382fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (opcional) instalar deps no ambiente atual, se faltar algo\n",
    "# !pip install -q \"pandas>=2.0\" \"numpy>=1.24\" \"openpyxl>=3.1\" \"jupyter>=1.0\" \\\n",
    "#                \"unidecode>=1.3\" \"matplotlib>=3.8\" \"seaborn>=0.13\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377846bb",
   "metadata": {},
   "source": [
    "## 1. Carregamento de Dados\n",
    "\n",
    "Carrega o dataset completo e filtra apenas os casos de crédito consignado identificados pela Entrega 5.\n",
    "\n",
    "*Essa parte do código é somente para aplicar o filtro da entrega 5 no db inteiro, por isso está comentada. O `dataset_filtrado.xlsx` é o produto disso.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f527a34",
   "metadata": {},
   "source": [
    "## 2. Funções Auxiliares\n",
    "\n",
    "Funções de limpeza e normalização de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c470d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINHA DE SELEÇÃO DO INPUT\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CARREGAMENTO DE DADOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prioriza dataset_filtrado.xlsx no mesmo diretório do notebook\n",
    "try:\n",
    "    # LINHA DE SELEÇÃO DO INPUT\n",
    "    df = pd.read_excel(\"./dataset_filtrado.xlsx\")\n",
    "    print(f\"\\nDataset carregado: ./dataset_filtrado.xlsx\")\n",
    "    print(f\"Dimensões: {df.shape[0]} linhas x {df.shape[1]} colunas\")\n",
    "    print(\"Dataset pronto para extração!\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    # Fallback: tenta no diretório pai\n",
    "    try:\n",
    "        df = pd.read_excel(\"../dataset_filtrado.xlsx\")\n",
    "        print(\"Usando fallback: ../dataset_filtrado.xlsx\")\n",
    "        print(f\"Dimensões: {df.shape[0]} linhas x {df.shape[1]} colunas\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        # Fallback final: tenta carregar do dataset original com filtro da Entrega 5\n",
    "        print(\"\\nAVISO: dataset_filtrado.xlsx não encontrado!\")\n",
    "        print(\"Tentando carregar e filtrar dataset original...\")\n",
    "        \n",
    "        try:\n",
    "            INPUT_CSV = \"../data/dataset_clinica20252.csv\"\n",
    "            df_completo = pd.read_csv(INPUT_CSV, sep=\"|\")\n",
    "            \n",
    "            ENTREGA5_OUTPUT = \"../entrega5/output.xlsx\"\n",
    "            df_filtrados = pd.read_excel(ENTREGA5_OUTPUT)\n",
    "            \n",
    "            cd_list = df_filtrados['cd_atendimento'].astype(str).tolist()\n",
    "            df = df_completo[df_completo['cd_atendimento'].astype(str).isin(cd_list)].copy()\n",
    "            \n",
    "            print(f\"Dataset filtrado dinamicamente: {df.shape[0]} linhas x {df.shape[1]} colunas\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nERRO: Não foi possível carregar nenhum dataset!\")\n",
    "            print(f\"Detalhes: {e}\")\n",
    "            raise\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fad1787",
   "metadata": {},
   "source": [
    "### Dataset Filtrado Salvo\n",
    "\n",
    "O arquivo `dataset_filtrado.xlsx` contém:\n",
    "- **TODOS os casos** de crédito consignado identificados pela Entrega 5\n",
    "- **TODAS as colunas** originais do dataset\n",
    "- Pronto para análises futuras (sem precisar reprocessar o filtro)\n",
    "\n",
    "Este arquivo será a base para todas as próximas análises!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c0fb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_accents(s: str) -> str:\n",
    "    \"\"\"Remove acentos de uma string.\"\"\"\n",
    "    if not isinstance(s, str): \n",
    "        return \"\"\n",
    "    return \"\".join(c for c in unicodedata.normalize(\"NFD\", s) \n",
    "                   if unicodedata.category(c) != \"Mn\")\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    \"\"\"Limpa e normaliza texto.\"\"\"\n",
    "    s = (s or \"\").replace(\"\\n\", \" \")\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "def limpar_para_excel(texto):\n",
    "    \"\"\"Remove caracteres de controle que causam problemas no Excel.\"\"\"\n",
    "    if not isinstance(texto, str):\n",
    "        return texto\n",
    "    # Remove caracteres de controle (0x00-0x1F exceto tab, newline, carriage return)\n",
    "    return re.sub(r'[\\x00-\\x08\\x0B-\\x0C\\x0E-\\x1F]', '', texto)\n",
    "\n",
    "# Constantes\n",
    "UF_LIST = set(\"AC AL AP AM BA CE DF ES GO MA MT MS MG PA PB PR PE PI RJ RN RS RO RR SC SP SE TO\".split())\n",
    "\n",
    "print(\"✓ Funções auxiliares definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eb8248",
   "metadata": {},
   "source": [
    "## 3. Extração de CNPJ\n",
    "\n",
    "Validação de CNPJs e busca com validação de dígitos verificadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4290ceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnpj_is_valid(cnpj_digits: str) -> bool:\n",
    "    \"\"\"Valida dígitos verificadores do CNPJ (14 dígitos).\"\"\"\n",
    "    if len(cnpj_digits) != 14 or len(set(cnpj_digits)) == 1:\n",
    "        return False\n",
    "    \n",
    "    nums = [int(x) for x in cnpj_digits]\n",
    "    \n",
    "    # Valida os dois dígitos verificadores\n",
    "    for i in [12, 13]:\n",
    "        pesos = [5,4,3,2,9,8,7,6,5,4,3,2] if i == 12 else [6,5,4,3,2,9,8,7,6,5,4,3,2]\n",
    "        soma = sum(a * b for a, b in zip(nums[:i], pesos))\n",
    "        dig = 11 - (soma % 11)\n",
    "        dig = 0 if dig >= 10 else dig\n",
    "        if nums[i] != dig: \n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def find_cnpjs_pos(text: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"Encontra CNPJs válidos no texto com suas posições.\"\"\"\n",
    "    out = []\n",
    "    pattern = r\"\\b\\d{2}\\.?\\d{3}\\.?\\d{3}/?\\d{4}-?\\d{2}\\b\"\n",
    "    \n",
    "    for m in re.finditer(pattern, text):\n",
    "        digits = re.sub(r\"\\D\", \"\", m.group(0))\n",
    "        if len(digits) == 14 and cnpj_is_valid(digits):\n",
    "            out.append((digits, m.start()))\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "print(\"✓ Funções de validação de CNPJ definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9379e47a",
   "metadata": {},
   "source": [
    "## 4. Extração de Nome de Empresa\n",
    "\n",
    "Estratégia simplificada sem regex complexa:\n",
    "1. Procura \"BANCO\" ou sufixo societário (S.A, LTDA, etc.)\n",
    "2. Captura APENAS palavras com letras\n",
    "3. Para quando encontrar: números, CNPJ, endereço, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f0c0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company_name_simple(text: str) -> Tuple[str, int, int]:\n",
    "    \"\"\"\n",
    "    Extrai nome da empresa de forma simplificada.\n",
    "    \n",
    "    Retorna: (nome_empresa, posicao_inicio, posicao_fim) ou (\"vazio\", -1, -1)\n",
    "    \"\"\"\n",
    "    T = clean_text(text).upper()\n",
    "    \n",
    "    # Palavras que indicam FIM do nome da empresa\n",
    "    STOP_WORDS = {\n",
    "        'INSCRITO', 'INSCRITA', 'CNPJ', 'CPF', 'SITO', 'SITA',\n",
    "        'ENDERECO', 'ENDEREÇO', 'RUA', 'AVENIDA', 'PRACA', 'PRAÇA',\n",
    "        'NUMERO', 'NÚMERO', 'CEP', 'BAIRRO', 'CIDADE', 'ESTADO',\n",
    "        'REPRESENTADO', 'REPRESENTADA', 'ADVOGADO', 'ADVOGADA',\n",
    "        'QUALIFICADO', 'QUALIFICADA', 'BRASILEIRO', 'BRASILEIRA'\n",
    "    }\n",
    "    \n",
    "    # Sufixos societários válidos\n",
    "    SUFFIXES = ['S.A.', 'S.A', 'S/A', 'LTDA', 'LTDA.', 'EIRELI', 'ME', 'EPP']\n",
    "    \n",
    "    # Procura \"BANCO\" no texto\n",
    "    banco_pos = T.find('BANCO')\n",
    "    if banco_pos == -1:\n",
    "        # Se não tem BANCO, procura por sufixo societário\n",
    "        for suffix in SUFFIXES:\n",
    "            if suffix in T:\n",
    "                suffix_pos = T.find(suffix)\n",
    "                start = max(0, suffix_pos - 100)\n",
    "                trecho = T[start:suffix_pos + len(suffix)]\n",
    "                words = trecho.split()[-6:]\n",
    "                nome = ' '.join(words).strip()\n",
    "                return (nome, start, suffix_pos + len(suffix))\n",
    "        \n",
    "        return (\"vazio\", -1, -1)\n",
    "    \n",
    "    # A partir de \"BANCO\", captura palavras seguintes\n",
    "    start_pos = banco_pos\n",
    "    trecho = T[banco_pos:]\n",
    "    palavras = trecho.split()\n",
    "    \n",
    "    nome_parts = []\n",
    "    last_pos = banco_pos\n",
    "    \n",
    "    for i, palavra in enumerate(palavras):\n",
    "        palavra_limpa = palavra.strip('.,;:()')\n",
    "        \n",
    "        # PARA se encontrar palavra-chave de parada\n",
    "        if palavra_limpa in STOP_WORDS:\n",
    "            break\n",
    "        \n",
    "        # PARA se encontrar números (exceto em sufixos)\n",
    "        if any(char.isdigit() for char in palavra_limpa):\n",
    "            if not any(s in palavra for s in ['S.A', 'S/A']):\n",
    "                break\n",
    "        \n",
    "        # PARA se tiver mais de 6 palavras\n",
    "        if i > 6:\n",
    "            break\n",
    "        \n",
    "        nome_parts.append(palavra)\n",
    "        last_pos = banco_pos + trecho.find(palavra) + len(palavra)\n",
    "        \n",
    "        # PARA se encontrou sufixo societário\n",
    "        if any(s in palavra for s in SUFFIXES):\n",
    "            break\n",
    "    \n",
    "    if nome_parts:\n",
    "        nome = ' '.join(nome_parts).strip('.,;: ')\n",
    "        return (nome, start_pos, last_pos)\n",
    "    \n",
    "    return (\"vazio\", -1, -1)\n",
    "\n",
    "\n",
    "def find_company_spans(text: str) -> List[Tuple[str, int, int]]:\n",
    "    \"\"\"Retorna lista com apenas 1 empresa (a primeira encontrada).\"\"\"\n",
    "    nome, start, end = extract_company_name_simple(text)\n",
    "    \n",
    "    if nome != \"vazio\":\n",
    "        return [(nome, start, end)]\n",
    "    \n",
    "    return []\n",
    "\n",
    "\n",
    "print(\"✓ Funções de extração de empresa definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442951ef",
   "metadata": {},
   "source": [
    "## 5. Associação Empresa + CNPJ\n",
    "\n",
    "Retorna APENAS 1 CNPJ por caso, priorizando proximidade ao nome da empresa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d533e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_company_and_cnpjs_v3(text: str, win_after=400, win_before=200) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Extrai empresa e CNPJ com proximidade.\n",
    "    \n",
    "    - Retorna APENAS 1 CNPJ (não uma lista)\n",
    "    - Prioriza CNPJ mais próximo ao nome da empresa\n",
    "    - Janela: 400 chars depois, 200 antes\n",
    "    \n",
    "    Retorna: (nome_empresa, cnpj_string)\n",
    "    \"\"\"\n",
    "    T = clean_text(text)\n",
    "    companies = find_company_spans(T)\n",
    "    cnpjs_pos = find_cnpjs_pos(T)\n",
    "    \n",
    "    def cnpj_mais_proximo(start, end):\n",
    "        \"\"\"Retorna o CNPJ MAIS PRÓXIMO ao span da empresa.\"\"\"\n",
    "        candidatos = []\n",
    "        for cnpj, pos in cnpjs_pos:\n",
    "            if (start - win_before) <= pos <= (end + win_after):\n",
    "                # Calcula distância (prioriza CNPJs após o nome)\n",
    "                if pos >= start:\n",
    "                    distancia = pos - end\n",
    "                else:\n",
    "                    distancia = (start - pos) * 2  # Penaliza CNPJs antes\n",
    "                \n",
    "                candidatos.append((cnpj, distancia))\n",
    "        \n",
    "        if candidatos:\n",
    "            candidatos.sort(key=lambda x: x[1])\n",
    "            return candidatos[0][0]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    # 1) Tenta associar por proximidade\n",
    "    for name, s, e in companies:\n",
    "        cnpj_proximo = cnpj_mais_proximo(s, e)\n",
    "        if cnpj_proximo:\n",
    "            return name, cnpj_proximo\n",
    "    \n",
    "    # 2) Fallback: retorna PRIMEIRO CNPJ válido\n",
    "    if cnpjs_pos:\n",
    "        primeiro_cnpj = cnpjs_pos[0][0]\n",
    "        if companies:\n",
    "            return companies[0][0], primeiro_cnpj\n",
    "        return \"vazio\", primeiro_cnpj\n",
    "    \n",
    "    return \"vazio\", \"vazio\"\n",
    "\n",
    "\n",
    "print(\"✓ Função de associação empresa+CNPJ definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef752fc",
   "metadata": {},
   "source": [
    "## 6. Extração de Valor da Causa\n",
    "\n",
    "Procura valores no formato brasileiro (1.234,56) próximos ao label \"valor da causa\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a39788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_valor_causa(text: str) -> float:\n",
    "    \"\"\"Extrai valor da causa em reais.\"\"\"\n",
    "    T = clean_text(text)\n",
    "    t_lower = strip_accents(T).lower()\n",
    "    \n",
    "    # Limites razoáveis para ações de crédito consignado\n",
    "    MIN_VALOR = 100.0\n",
    "    MAX_VALOR = 10_000_000.0\n",
    "    \n",
    "    # Padrão: valores no formato brasileiro (1.234,56 ou R$ 1.234,56)\n",
    "    pattern = r\"R?\\$?\\s*(\\d{1,3}(?:\\.\\d{3})*,\\d{2}|\\d+,\\d{2})\"\n",
    "    \n",
    "    # 1) Primeiro tenta próximo a \"valor da causa\"\n",
    "    if \"valor\" in t_lower and \"causa\" in t_lower:\n",
    "        pos = t_lower.find(\"valor\")\n",
    "        trecho = T[max(0, pos-150):pos+150]\n",
    "        \n",
    "        valores = []\n",
    "        for match in re.finditer(pattern, trecho):\n",
    "            num_str = match.group(1)\n",
    "            valor = float(num_str.replace(\".\", \"\").replace(\",\", \".\"))\n",
    "            if MIN_VALOR <= valor <= MAX_VALOR:\n",
    "                valores.append(valor)\n",
    "        \n",
    "        if valores:\n",
    "            return max(valores)\n",
    "    \n",
    "    # 2) Busca em todo texto\n",
    "    valores = []\n",
    "    for match in re.finditer(pattern, T):\n",
    "        num_str = match.group(1)\n",
    "        valor = float(num_str.replace(\".\", \"\").replace(\",\", \".\"))\n",
    "        if MIN_VALOR <= valor <= MAX_VALOR:\n",
    "            valores.append(valor)\n",
    "    \n",
    "    return max(valores) if valores else 0.0\n",
    "\n",
    "\n",
    "print(\"✓ Função de extração de valor definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f895fe9",
   "metadata": {},
   "source": [
    "## 7. Extração de Data de Distribuição\n",
    "\n",
    "Procura data próxima a \"distribuição\" ou \"autuação\" em formatos DD/MM/YYYY ou YYYY-MM-DD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f88d508",
   "metadata": {},
   "source": [
    "## 6.1. Extração de Valores de Danos Morais e Materiais\n",
    "\n",
    "Busca valores pedidos a título de danos morais e materiais, com flags para qualificadores (\"não inferior\", \"em dobro\", \"até\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ccf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_valores_morais_materiais(text: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Busca janelas ±100 chars ao redor de 'danos morais' e 'danos materiais',\n",
    "    captura valores monetários pt-BR e flags ('não inferior', 'em dobro', 'até').\n",
    "    \n",
    "    Retorna:\n",
    "      {\n",
    "        'valor_moral': float,\n",
    "        'valor_material': float,\n",
    "        'has_minimo': bool,     # 'não inferior'\n",
    "        'has_em_dobro': bool,\n",
    "        'has_ate': bool,\n",
    "        'evidencia': str        # recorte curto do trecho\n",
    "      }\n",
    "    \"\"\"\n",
    "    T = clean_text(text)\n",
    "    t_lower = strip_accents(T).lower()\n",
    "    \n",
    "    # Padrão para valores em formato brasileiro\n",
    "    pattern_valor = r\"R?\\$?\\s*(\\d{1,3}(?:\\.\\d{3})*,\\d{2}|\\d+,\\d{2})\"\n",
    "    \n",
    "    # Limites razoáveis\n",
    "    MIN_VALOR = 100.0\n",
    "    MAX_VALOR = 10_000_000.0\n",
    "    \n",
    "    resultado = {\n",
    "        'valor_moral': 0.0,\n",
    "        'valor_material': 0.0,\n",
    "        'has_minimo': False,\n",
    "        'has_em_dobro': False,\n",
    "        'has_ate': False,\n",
    "        'evidencia': ''\n",
    "    }\n",
    "    \n",
    "    # Busca danos morais\n",
    "    if 'danos morais' in t_lower or 'dano moral' in t_lower:\n",
    "        # Encontra posição\n",
    "        pos = t_lower.find('danos morais') if 'danos morais' in t_lower else t_lower.find('dano moral')\n",
    "        \n",
    "        # Janela de ±100 chars\n",
    "        inicio = max(0, pos - 100)\n",
    "        fim = min(len(T), pos + 100)\n",
    "        trecho = T[inicio:fim]\n",
    "        trecho_lower = t_lower[inicio:fim]\n",
    "        \n",
    "        # Busca valores\n",
    "        valores_morais = []\n",
    "        for match in re.finditer(pattern_valor, trecho):\n",
    "            num_str = match.group(1)\n",
    "            valor = float(num_str.replace(\".\", \"\").replace(\",\", \".\"))\n",
    "            if MIN_VALOR <= valor <= MAX_VALOR:\n",
    "                valores_morais.append(valor)\n",
    "        \n",
    "        if valores_morais:\n",
    "            resultado['valor_moral'] = max(valores_morais)\n",
    "            \n",
    "        # Verifica flags\n",
    "        if 'nao inferior' in trecho_lower or 'não inferior' in trecho_lower:\n",
    "            resultado['has_minimo'] = True\n",
    "        if 'em dobro' in trecho_lower:\n",
    "            resultado['has_em_dobro'] = True\n",
    "        if 'até' in trecho_lower or 'ate' in trecho_lower:\n",
    "            resultado['has_ate'] = True\n",
    "            \n",
    "        # Salva evidência (recorte de até 150 chars)\n",
    "        evidencia_moral = trecho[:150].strip()\n",
    "        if len(trecho) > 150:\n",
    "            evidencia_moral += \"...\"\n",
    "        resultado['evidencia'] = evidencia_moral\n",
    "    \n",
    "    # Busca danos materiais\n",
    "    if 'danos materiais' in t_lower or 'dano material' in t_lower:\n",
    "        pos = t_lower.find('danos materiais') if 'danos materiais' in t_lower else t_lower.find('dano material')\n",
    "        \n",
    "        inicio = max(0, pos - 100)\n",
    "        fim = min(len(T), pos + 100)\n",
    "        trecho = T[inicio:fim]\n",
    "        trecho_lower = t_lower[inicio:fim]\n",
    "        \n",
    "        valores_materiais = []\n",
    "        for match in re.finditer(pattern_valor, trecho):\n",
    "            num_str = match.group(1)\n",
    "            valor = float(num_str.replace(\".\", \"\").replace(\",\", \".\"))\n",
    "            if MIN_VALOR <= valor <= MAX_VALOR:\n",
    "                valores_materiais.append(valor)\n",
    "        \n",
    "        if valores_materiais:\n",
    "            resultado['valor_material'] = max(valores_materiais)\n",
    "            \n",
    "        # Atualiza flags (pode ter em ambos os trechos)\n",
    "        if 'nao inferior' in trecho_lower or 'não inferior' in trecho_lower:\n",
    "            resultado['has_minimo'] = True\n",
    "        if 'em dobro' in trecho_lower:\n",
    "            resultado['has_em_dobro'] = True\n",
    "        if 'até' in trecho_lower or 'ate' in trecho_lower:\n",
    "            resultado['has_ate'] = True\n",
    "            \n",
    "        # Se não tinha evidência ainda, adiciona a dos materiais\n",
    "        if not resultado['evidencia']:\n",
    "            evidencia_mat = trecho[:150].strip()\n",
    "            if len(trecho) > 150:\n",
    "                evidencia_mat += \"...\"\n",
    "            resultado['evidencia'] = evidencia_mat\n",
    "    \n",
    "    return resultado\n",
    "\n",
    "\n",
    "print(\"✓ Função de extração de valores morais/materiais definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a33e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dt_distribuicao(text: str) -> str:\n",
    "    \"\"\"Extrai data de distribuição no formato YYYY-MM-DD.\"\"\"\n",
    "    t = strip_accents(clean_text(text)).lower()\n",
    "    \n",
    "    # Padrões de data\n",
    "    pattern_iso = r\"(20\\d{2})-(0[1-9]|1[0-2])-(0[1-9]|[12]\\d|3[01])\"\n",
    "    pattern_br = r\"(0[1-9]|[12]\\d|3[01])[/\\-](0[1-9]|1[0-2])[/\\-](20\\d{2})\"\n",
    "    \n",
    "    # 1) Procura próximo a \"distribuição\" ou \"autuação\"\n",
    "    for keyword in ['distribuicao', 'distribuido', 'autuacao', 'autuado']:\n",
    "        pos = t.find(keyword)\n",
    "        if pos != -1:\n",
    "            trecho = t[max(0, pos-100):pos+100]\n",
    "            \n",
    "            # Tenta ISO\n",
    "            match = re.search(pattern_iso, trecho)\n",
    "            if match:\n",
    "                return f\"{match.group(1)}-{match.group(2)}-{match.group(3)}\"\n",
    "            \n",
    "            # Tenta BR\n",
    "            match = re.search(pattern_br, trecho)\n",
    "            if match:\n",
    "                dd, mm, y = match.group(1), match.group(2), match.group(3)\n",
    "                return f\"{y}-{mm.zfill(2)}-{dd.zfill(2)}\"\n",
    "    \n",
    "    # 2) Fallback: primeira data ISO\n",
    "    match = re.search(pattern_iso, t)\n",
    "    if match:\n",
    "        return f\"{match.group(1)}-{match.group(2)}-{match.group(3)}\"\n",
    "    \n",
    "    # 3) Fallback: primeira data BR\n",
    "    match = re.search(pattern_br, t)\n",
    "    if match:\n",
    "        dd, mm, y = match.group(1), match.group(2), match.group(3)\n",
    "        return f\"{y}-{mm.zfill(2)}-{dd.zfill(2)}\"\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "\n",
    "print(\"✓ Função de extração de data definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7797e1e0",
   "metadata": {},
   "source": [
    "## 8. Extração de Tipo de Vara e UF\n",
    "\n",
    "Funções para classificar tipo de vara e extrair UF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d75e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_tipo_vara(text: str) -> str:\n",
    "    \"\"\"Classifica o tipo de vara: JE (Juizado Especial) ou G1 (Vara Comum).\"\"\"\n",
    "    t = strip_accents(clean_text(text)).lower()\n",
    "    if \"juizado especial\" in t or \"jecc\" in t:\n",
    "        return \"JE\"\n",
    "    return \"G1\"\n",
    "\n",
    "\n",
    "def extract_uf(text: str) -> str:\n",
    "    \"\"\"Extrai a UF (estado) do texto.\"\"\"\n",
    "    tokens = re.findall(r\"\\b[A-Z]{2}\\b\", clean_text(text).upper())\n",
    "    for tk in tokens:\n",
    "        if tk in UF_LIST:\n",
    "            return tk\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "print(\"✓ Funções de tipo de vara e UF definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2fba9e",
   "metadata": {},
   "source": [
    "## 9. Função Principal de Extração\n",
    "\n",
    "Processa todos os casos e extrai os 7 campos estruturados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4917e8",
   "metadata": {},
   "source": [
    "## 9.1. Extração Expandida (com Danos Morais e Materiais)\n",
    "\n",
    "Função adicional que extrai os valores de danos morais/materiais para análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba127a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_dados_expandido(df: pd.DataFrame, output_path: str = \"output_expandido.xlsx\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extrai todos os campos INCLUINDO valores de danos morais e materiais.\n",
    "    \n",
    "    Este DataFrame é para análise interna e contém colunas adicionais:\n",
    "    - valor_moral, valor_material, has_minimo, has_em_dobro, has_ate, evidencia_pedidos\n",
    "    \n",
    "    Retorna: DataFrame expandido + salva em Excel\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXTRAÇÃO EXPANDIDA (com danos morais/materiais)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Carrega colunas de texto\n",
    "    qual = df.get(\"ds_Qualificacao\", \"\").astype(str)\n",
    "    fatos = df.get(\"ds_fatos\", \"\").astype(str)\n",
    "    pedidos = df.get(\"ds_Pedidos\", \"\").astype(str)\n",
    "    acao = df.get(\"ds_Acao_Judicial\", \"\").astype(str)\n",
    "    \n",
    "    # Função para extrair empresa e CNPJ\n",
    "    def extrair_cnpj_empresa(row):\n",
    "        nome, cnpj = pick_company_and_cnpjs_v3(row['ds_Qualificacao'])\n",
    "        if cnpj != \"vazio\":\n",
    "            return nome, cnpj\n",
    "        texto_completo = f\"{row['ds_Qualificacao']} {row['ds_fatos']} {row['ds_Pedidos']} {row['ds_Acao_Judicial']}\"\n",
    "        nome, cnpj = pick_company_and_cnpjs_v3(texto_completo)\n",
    "        return nome, cnpj\n",
    "    \n",
    "    # Extrai campos padrão\n",
    "    print(\"\\nExtraindo campos padrão...\")\n",
    "    df_temp = df[['ds_Qualificacao', 'ds_fatos', 'ds_Pedidos', 'ds_Acao_Judicial']].fillna('')\n",
    "    pares = df_temp.apply(extrair_cnpj_empresa, axis=1)\n",
    "    nome_empresa = pares.map(lambda x: x[0])\n",
    "    cnpjs = pares.map(lambda x: x[1])\n",
    "    \n",
    "    texto_valor = (fatos + \" \" + pedidos).astype(str)\n",
    "    texto_data = (pedidos + \" \" + qual + \" \" + acao).astype(str)\n",
    "    \n",
    "    valores = texto_valor.map(extract_valor_causa)\n",
    "    datas = texto_data.map(extract_dt_distribuicao)\n",
    "    tipos_vara = qual.map(classify_tipo_vara)\n",
    "    ufs = qual.map(extract_uf)\n",
    "    \n",
    "    # Extrai valores de danos morais e materiais\n",
    "    print(\"Extraindo valores de danos morais e materiais...\")\n",
    "    texto_pedidos_completo = (pedidos + \" \" + fatos).astype(str)\n",
    "    \n",
    "    valores_danos = texto_pedidos_completo.map(extract_valores_morais_materiais)\n",
    "    \n",
    "    # Separa os campos do dicionário\n",
    "    valores_morais = valores_danos.map(lambda x: x['valor_moral'])\n",
    "    valores_materiais = valores_danos.map(lambda x: x['valor_material'])\n",
    "    has_minimo = valores_danos.map(lambda x: x['has_minimo'])\n",
    "    has_em_dobro = valores_danos.map(lambda x: x['has_em_dobro'])\n",
    "    has_ate = valores_danos.map(lambda x: x['has_ate'])\n",
    "    evidencias = valores_danos.map(lambda x: x['evidencia'])\n",
    "    \n",
    "    # Cria DataFrame expandido\n",
    "    print(\"Montando DataFrame expandido...\")\n",
    "    resultado = pd.DataFrame({\n",
    "        \"cd_atendimento\": df[\"cd_atendimento\"].astype(str),\n",
    "        \"nome_empresa\": nome_empresa,\n",
    "        \"cnpj\": cnpjs,\n",
    "        \"valor_causa\": valores,\n",
    "        \"dt_distribuicao\": datas,\n",
    "        \"tipo_vara\": tipos_vara,\n",
    "        \"uf\": ufs,\n",
    "        # Colunas adicionais de análise\n",
    "        \"valor_moral\": valores_morais,\n",
    "        \"valor_material\": valores_materiais,\n",
    "        \"has_minimo\": has_minimo,\n",
    "        \"has_em_dobro\": has_em_dobro,\n",
    "        \"has_ate\": has_ate,\n",
    "        \"evidencia_pedidos\": evidencias,\n",
    "    })\n",
    "    \n",
    "    # Limpa caracteres problemáticos\n",
    "    for col in [\"nome_empresa\", \"cnpj\", \"dt_distribuicao\", \"tipo_vara\", \"uf\", \"evidencia_pedidos\"]:\n",
    "        if col in resultado.columns:\n",
    "            resultado[col] = resultado[col].map(limpar_para_excel)\n",
    "    \n",
    "    # Salva resultado expandido\n",
    "    print(f\"\\nSalvando arquivo '{output_path}'...\")\n",
    "    resultado.to_excel(output_path, index=False)\n",
    "    \n",
    "    print(f\"✓ Arquivo expandido '{output_path}' criado com sucesso!\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return resultado\n",
    "\n",
    "\n",
    "print(\"✓ Função de extração expandida definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3babdb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_dados(df: pd.DataFrame, output_path: str = \"output.xlsx\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extrai todos os campos de cada caso.\n",
    "    \n",
    "    Retorna: DataFrame com os dados extraídos + salva em Excel\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"INICIANDO EXTRAÇÃO DE DADOS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Carrega colunas de texto\n",
    "    qual = df.get(\"ds_Qualificacao\", \"\").astype(str)\n",
    "    fatos = df.get(\"ds_fatos\", \"\").astype(str)\n",
    "    pedidos = df.get(\"ds_Pedidos\", \"\").astype(str)\n",
    "    acao = df.get(\"ds_Acao_Judicial\", \"\").astype(str)\n",
    "    \n",
    "    # Função para extrair empresa e CNPJ\n",
    "    def extrair_cnpj_empresa(row):\n",
    "        # Prioriza ds_Qualificacao (polo passivo)\n",
    "        nome, cnpj = pick_company_and_cnpjs_v3(row['ds_Qualificacao'])\n",
    "        \n",
    "        if cnpj != \"vazio\":\n",
    "            return nome, cnpj\n",
    "        \n",
    "        # Fallback: busca em todas as colunas\n",
    "        texto_completo = f\"{row['ds_Qualificacao']} {row['ds_fatos']} {row['ds_Pedidos']} {row['ds_Acao_Judicial']}\"\n",
    "        nome, cnpj = pick_company_and_cnpjs_v3(texto_completo)\n",
    "        \n",
    "        return nome, cnpj\n",
    "    \n",
    "    # Extrai nome da empresa e CNPJ\n",
    "    print(\"\\n1/7 Extraindo empresa e CNPJ...\")\n",
    "    df_temp = df[['ds_Qualificacao', 'ds_fatos', 'ds_Pedidos', 'ds_Acao_Judicial']].fillna('')\n",
    "    pares = df_temp.apply(extrair_cnpj_empresa, axis=1)\n",
    "    nome_empresa = pares.map(lambda x: x[0])\n",
    "    cnpjs = pares.map(lambda x: x[1])\n",
    "    \n",
    "    # Prepara textos para outras extrações\n",
    "    texto_valor = (fatos + \" \" + pedidos).astype(str)\n",
    "    texto_data = (pedidos + \" \" + qual + \" \" + acao).astype(str)\n",
    "    \n",
    "    # Extrai outros campos\n",
    "    print(\"2/7 Extraindo valor da causa...\")\n",
    "    valores = texto_valor.map(extract_valor_causa)\n",
    "    \n",
    "    print(\"3/7 Extraindo data de distribuição...\")\n",
    "    datas = texto_data.map(extract_dt_distribuicao)\n",
    "    \n",
    "    print(\"4/7 Classificando tipo de vara...\")\n",
    "    tipos_vara = qual.map(classify_tipo_vara)\n",
    "    \n",
    "    print(\"5/7 Extraindo UF...\")\n",
    "    ufs = qual.map(extract_uf)\n",
    "    \n",
    "    # Cria DataFrame com as 7 colunas \n",
    "    print(\"6/7 Montando DataFrame...\")\n",
    "    resultado = pd.DataFrame({\n",
    "        \"cd_atendimento\": df[\"cd_atendimento\"].astype(str),\n",
    "        \"nome_empresa\": nome_empresa,\n",
    "        \"cnpj\": cnpjs,\n",
    "        \"valor_causa\": valores,\n",
    "        \"dt_distribuicao\": datas,\n",
    "        \"tipo_vara\": tipos_vara,\n",
    "        \"uf\": ufs,\n",
    "    })\n",
    "    \n",
    "    # Limpa caracteres problemáticos para Excel\n",
    "    for col in [\"nome_empresa\", \"cnpj\", \"dt_distribuicao\", \"tipo_vara\", \"uf\"]:\n",
    "        resultado[col] = resultado[col].map(limpar_para_excel)\n",
    "    \n",
    "    # Salva resultado \n",
    "    print(f\"7/7 Salvando arquivo '{output_path}'...\")\n",
    "    resultado.to_excel(output_path, index=False)\n",
    "    \n",
    "    print(f\"\\n✓ Arquivo '{output_path}' criado com sucesso!\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return resultado\n",
    "\n",
    "\n",
    "print(\"✓ Função principal definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a4afe3",
   "metadata": {},
   "source": [
    "## 10. Execução\n",
    "\n",
    "Execute a extração e visualize os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5444e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executa a extração\n",
    "resultado = extrair_dados(df, output_path=\"output.xlsx\")\n",
    "\n",
    "# Estatísticas\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ESTATÍSTICAS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal de casos processados: {len(resultado)}\")\n",
    "\n",
    "print(f\"\\n Distribuição por UF (top 10):\")\n",
    "print(resultado['uf'].value_counts().head(10))\n",
    "\n",
    "print(f\"\\n Distribuição por Tipo de Vara:\")\n",
    "print(resultado['tipo_vara'].value_counts())\n",
    "\n",
    "print(f\"\\n CNPJs extraídos:\")\n",
    "cnpjs_validos = len(resultado[resultado['cnpj'] != 'vazio'])\n",
    "print(f\"  Válidos: {cnpjs_validos} ({cnpjs_validos/len(resultado)*100:.1f}%)\")\n",
    "print(f\"  Vazios: {len(resultado) - cnpjs_validos}\")\n",
    "\n",
    "print(f\"\\n Valores da causa:\")\n",
    "valores_validos = len(resultado[resultado['valor_causa'] > 0])\n",
    "print(f\"  Extraídos: {valores_validos} ({valores_validos/len(resultado)*100:.1f}%)\")\n",
    "print(f\"  Média: R$ {resultado[resultado['valor_causa'] > 0]['valor_causa'].mean():,.2f}\")\n",
    "\n",
    "print(f\"\\n Datas extraídas:\")\n",
    "datas_validas = len(resultado[resultado['dt_distribuicao'] != ''])\n",
    "print(f\"  Válidas: {datas_validas} ({datas_validas/len(resultado)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AMOSTRA DOS RESULTADOS (primeiras 10 linhas)\")\n",
    "print(\"=\"*80)\n",
    "display(resultado.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3921a58d",
   "metadata": {},
   "source": [
    "## 10.1. Extração Expandida (Opcional)\n",
    "\n",
    "Execute esta célula para gerar também o arquivo com valores de danos morais e materiais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f4799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executa a extração expandida (OPCIONAL)\n",
    "resultado_expandido = extrair_dados_expandido(df, output_path=\"output_expandido.xlsx\")\n",
    "\n",
    "# Estatísticas adicionais\n",
    "print(\"\\nESTATÍSTICAS DE DANOS MORAIS E MATERIAIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Danos morais\n",
    "casos_com_moral = len(resultado_expandido[resultado_expandido['valor_moral'] > 0])\n",
    "print(f\"\\nDanos Morais:\")\n",
    "print(f\"  Casos com valor: {casos_com_moral} ({casos_com_moral/len(resultado_expandido)*100:.1f}%)\")\n",
    "if casos_com_moral > 0:\n",
    "    print(f\"  Média: R$ {resultado_expandido[resultado_expandido['valor_moral'] > 0]['valor_moral'].mean():,.2f}\")\n",
    "    print(f\"  Mediana: R$ {resultado_expandido[resultado_expandido['valor_moral'] > 0]['valor_moral'].median():,.2f}\")\n",
    "    print(f\"  Máximo: R$ {resultado_expandido['valor_moral'].max():,.2f}\")\n",
    "\n",
    "# Danos materiais\n",
    "casos_com_material = len(resultado_expandido[resultado_expandido['valor_material'] > 0])\n",
    "print(f\"\\nDanos Materiais:\")\n",
    "print(f\"  Casos com valor: {casos_com_material} ({casos_com_material/len(resultado_expandido)*100:.1f}%)\")\n",
    "if casos_com_material > 0:\n",
    "    print(f\"  Média: R$ {resultado_expandido[resultado_expandido['valor_material'] > 0]['valor_material'].mean():,.2f}\")\n",
    "    print(f\"  Mediana: R$ {resultado_expandido[resultado_expandido['valor_material'] > 0]['valor_material'].median():,.2f}\")\n",
    "    print(f\"  Máximo: R$ {resultado_expandido['valor_material'].max():,.2f}\")\n",
    "\n",
    "# Flags\n",
    "print(f\"\\nQualificadores dos Pedidos:\")\n",
    "print(f\"  'Não inferior a': {resultado_expandido['has_minimo'].sum()} casos ({resultado_expandido['has_minimo'].sum()/len(resultado_expandido)*100:.1f}%)\")\n",
    "print(f\"  'Em dobro': {resultado_expandido['has_em_dobro'].sum()} casos ({resultado_expandido['has_em_dobro'].sum()/len(resultado_expandido)*100:.1f}%)\")\n",
    "print(f\"  'Até': {resultado_expandido['has_ate'].sum()} casos ({resultado_expandido['has_ate'].sum()/len(resultado_expandido)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AMOSTRA COM DANOS MORAIS/MATERIAIS (primeiras 10 linhas)\")\n",
    "print(\"=\"*80)\n",
    "display(resultado_expandido[['cd_atendimento', 'nome_empresa', 'valor_moral', 'valor_material', \n",
    "                              'has_minimo', 'has_em_dobro', 'has_ate']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b63b560",
   "metadata": {},
   "source": [
    "## 10.2. Análise Temporal de Palavras-Chave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e637f648",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Resumo das Funcionalidades\n",
    "\n",
    "### Arquivos Gerados\n",
    "\n",
    "1. **output.xlsx** (7 colunas - requisito do roteiro)\n",
    "   - `cd_atendimento`, `nome_empresa`, `cnpj`, `valor_causa`, `dt_distribuicao`, `tipo_vara`, `uf`\n",
    "   - Gerado pela função `extrair_dados()`\n",
    "   \n",
    "2. **output_expandido.xlsx** (13 colunas - análise interna)\n",
    "   - Todas as 7 colunas acima MAIS:\n",
    "   - `valor_moral`: Valor pedido em danos morais\n",
    "   - `valor_material`: Valor pedido em danos materiais\n",
    "   - `has_minimo`: Flag para \"não inferior a\"\n",
    "   - `has_em_dobro`: Flag para \"em dobro\"\n",
    "   - `has_ate`: Flag para \"até\"\n",
    "   - `evidencia_pedidos`: Trecho do texto com evidência\n",
    "   - Gerado pela função `extrair_dados_expandido()`\n",
    "\n",
    "### Técnicas de Extração\n",
    "\n",
    "#### Valores de Danos Morais e Materiais\n",
    "- Busca janelas de ±100 caracteres ao redor dos termos \"danos morais\" e \"danos materiais\"\n",
    "- Extrai valores em formato brasileiro (R$ 1.234,56)\n",
    "- Identifica qualificadores nos pedidos:\n",
    "  - \"não inferior\" → indica valor mínimo\n",
    "  - \"em dobro\" → indica multiplicação\n",
    "  - \"até\" → indica valor máximo\n",
    "- Retorna evidência textual para verificação manual\n",
    "\n",
    "### Dependências\n",
    "\n",
    "```\n",
    "pandas>=2.0\n",
    "numpy>=1.24\n",
    "openpyxl>=3.1\n",
    "jupyter>=1.0\n",
    "unidecode>=1.3\n",
    "matplotlib>=3.8\n",
    "seaborn>=0.13\n",
    "```\n",
    "\n",
    "### Carregamento de Dados\n",
    "\n",
    "O notebook prioriza:\n",
    "1. `./dataset_filtrado.xlsx` (mesmo diretório)\n",
    "2. `../dataset_filtrado.xlsx` (diretório pai)\n",
    "3. Fallback: carrega e filtra dataset original dinamicamente\n",
    "\n",
    "### Notas Importantes\n",
    "\n",
    "- A função `extrair_dados()` mantém compatibilidade total com o roteiro (7 colunas)\n",
    "- A função `extrair_dados_expandido()` é opcional e adiciona análise de danos morais/materiais\n",
    "- Ambas as funções usam as mesmas técnicas de limpeza e validação de dados\n",
    "- Caracteres de controle são removidos antes de salvar em Excel (evita erros de codificação)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc691b2c",
   "metadata": {},
   "source": [
    "## 11. Análise Estatística Descritiva\n",
    "\n",
    "Análise detalhada dos valores de danos morais e materiais extraídos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e48655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANTE: Execute primeiro a seção 10.1 para ter resultado_expandido disponível\n",
    "\n",
    "# Filtra apenas valores maiores que zero\n",
    "df_moral = resultado_expandido[resultado_expandido['valor_moral'] > 0]['valor_moral']\n",
    "df_material = resultado_expandido[resultado_expandido['valor_material'] > 0]['valor_material']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ESTATÍSTICAS DESCRITIVAS - VALORES DE DANOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Cria DataFrames com estatísticas descritivas\n",
    "stats_moral = pd.DataFrame({\n",
    "    'Métrica': ['count', 'mean', 'median', 'std', 'min', 'p25', 'p75', 'max'],\n",
    "    'Valor Moral': [\n",
    "        len(df_moral),\n",
    "        df_moral.mean() if len(df_moral) > 0 else 0,\n",
    "        df_moral.median() if len(df_moral) > 0 else 0,\n",
    "        df_moral.std() if len(df_moral) > 0 else 0,\n",
    "        df_moral.min() if len(df_moral) > 0 else 0,\n",
    "        df_moral.quantile(0.25) if len(df_moral) > 0 else 0,\n",
    "        df_moral.quantile(0.75) if len(df_moral) > 0 else 0,\n",
    "        df_moral.max() if len(df_moral) > 0 else 0,\n",
    "    ]\n",
    "})\n",
    "\n",
    "stats_material = pd.DataFrame({\n",
    "    'Métrica': ['count', 'mean', 'median', 'std', 'min', 'p25', 'p75', 'max'],\n",
    "    'Valor Material': [\n",
    "        len(df_material),\n",
    "        df_material.mean() if len(df_material) > 0 else 0,\n",
    "        df_material.median() if len(df_material) > 0 else 0,\n",
    "        df_material.std() if len(df_material) > 0 else 0,\n",
    "        df_material.min() if len(df_material) > 0 else 0,\n",
    "        df_material.quantile(0.25) if len(df_material) > 0 else 0,\n",
    "        df_material.quantile(0.75) if len(df_material) > 0 else 0,\n",
    "        df_material.max() if len(df_material) > 0 else 0,\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nDanos Morais (apenas valores > 0):\")\n",
    "print(\"-\" * 40)\n",
    "display(stats_moral)\n",
    "\n",
    "print(\"\\nDanos Materiais (apenas valores > 0):\")\n",
    "print(\"-\" * 40)\n",
    "display(stats_material)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab84cf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas para valores de danos morais e materiais\n",
    "\n",
    "def moeda(x, pos):\n",
    "    return f'R${x:,.0f}'.replace(',', '.')\n",
    "fmt = FuncFormatter(moeda)\n",
    "\n",
    "# arrays 1D de valores positivos\n",
    "moral = np.asarray(df_moral, dtype=float)\n",
    "material = np.asarray(df_material, dtype=float)\n",
    "moral = moral[moral > 0]\n",
    "material = material[material > 0]\n",
    "\n",
    "def log_bins(x, nbins=40):\n",
    "    lo = np.nanmin(x[x>0])\n",
    "    hi = np.nanmax(x)\n",
    "    return np.logspace(np.log10(lo), np.log10(hi), nbins)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), dpi=150)\n",
    "\n",
    "def hist_podado(ax, x, titulo, xmax_percentil=99, bins=40):\n",
    "    x = np.asarray(x, float)\n",
    "    x = x[x>0]\n",
    "    if not x.size:\n",
    "        ax.text(0.5,0.5,'Sem dados',ha='center',va='center',transform=ax.transAxes); return\n",
    "    p = np.percentile(x, xmax_percentil)\n",
    "    cortados = (x > p).sum()\n",
    "    ax.hist(x[x<=p], bins=bins, edgecolor='black', alpha=0.75)\n",
    "    ax.set_xlim(0, p)\n",
    "    ax.set_title(titulo, fontweight='bold')\n",
    "    ax.set_xlabel('Valor (R$)')\n",
    "\n",
    "    ax.set_ylabel('Frequência')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.xaxis.set_major_formatter(fmt)\n",
    "    if cortados:\n",
    "        ax.annotate(f'{cortados} valores > p{xmax_percentil}\\n(não exibidos)',\n",
    "                    xy=(0.98, 0.95), xycoords='axes fraction',\n",
    "                    ha='right', va='top', fontsize=9,\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', fc='white', ec='gray', alpha=0.8))\n",
    "\n",
    "# Danos Morais\n",
    "hist_podado(axes[0], df_moral, 'Distribuição de Valores - Danos Morais', xmax_percentil=99)\n",
    "\n",
    "# Danos Materiais\n",
    "if material.size:\n",
    "    bins = log_bins(material, nbins=40)\n",
    "    axes[1].hist(material, bins=bins, edgecolor='black', alpha=0.75)\n",
    "    axes[1].set_xscale('log')\n",
    "    axes[1].set_title('Distribuição de Valores - Danos Materiais', fontweight='bold')\n",
    "    axes[1].set_xlabel('Valor (R$)')\n",
    "    axes[1].set_ylabel('Frequência')\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    axes[1].xaxis.set_major_formatter(fmt)\n",
    "else:\n",
    "    axes[1].text(0.5,0.5,'Sem dados',ha='center',va='center',transform=axes[1].transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('histogramas_danos_log.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots de valores de danos por tipo de vara (com corte em p99)\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# formatação R$ no eixo\n",
    "fmt = FuncFormatter(lambda x, pos: f'R${x:,.0f}'.replace(',', '.'))\n",
    "\n",
    "# Preparar dados\n",
    "df_boxplot = resultado_expandido[\n",
    "    (resultado_expandido['valor_moral'] > 0) | (resultado_expandido['valor_material'] > 0)\n",
    "][['tipo_vara', 'valor_moral', 'valor_material']].copy()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), dpi=150)\n",
    "\n",
    "# ----- Danos Morais -----\n",
    "df_moral_box = df_boxplot[df_boxplot['valor_moral'] > 0]\n",
    "if len(df_moral_box) > 0:\n",
    "    sns.boxplot(\n",
    "        x='tipo_vara', y='valor_moral',\n",
    "        data=df_moral_box, ax=axes[0],\n",
    "        palette='Set2', showfliers=False\n",
    "    )\n",
    "    # corte em p99\n",
    "    p99_moral = np.percentile(df_moral_box['valor_moral'], 99)\n",
    "    axes[0].set_ylim(0, p99_moral)\n",
    "    # (opcional) avisa quantos pontos ficaram fora\n",
    "    cortados_moral = int((df_moral_box['valor_moral'] > p99_moral).sum())\n",
    "    if cortados_moral:\n",
    "        axes[0].annotate(\n",
    "            f'{cortados_moral} valores > p99 não exibidos',\n",
    "            xy=(0.98, 0.95), xycoords='axes fraction',\n",
    "            ha='right', va='top', fontsize=9,\n",
    "            bbox=dict(boxstyle='round,pad=0.3', fc='white', ec='gray', alpha=0.8)\n",
    "        )\n",
    "\n",
    "    axes[0].set_title('Danos Morais por Tipo de Vara', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_xlabel('Tipo de Vara', fontsize=10)\n",
    "    axes[0].set_ylabel('Valor (R$)', fontsize=10)\n",
    "    axes[0].yaxis.set_major_formatter(fmt)\n",
    "    axes[0].tick_params(axis='x', rotation=0)\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "else:\n",
    "    axes[0].text(0.5, 0.5, 'Sem dados disponíveis', ha='center', va='center', transform=axes[0].transAxes)\n",
    "    axes[0].set_title('Danos Morais por Tipo de Vara', fontsize=12, fontweight='bold')\n",
    "\n",
    "# ----- Danos Materiais -----\n",
    "df_material_box = df_boxplot[df_boxplot['valor_material'] > 0]\n",
    "if len(df_material_box) > 0:\n",
    "    sns.boxplot(\n",
    "        x='tipo_vara', y='valor_material',\n",
    "        data=df_material_box, ax=axes[1],\n",
    "        palette='Set1', showfliers=False\n",
    "    )\n",
    "    # corte em p99\n",
    "    p99_material = np.percentile(df_material_box['valor_material'], 99)\n",
    "    axes[1].set_ylim(0, p99_material)\n",
    "    # (opcional) avisa quantos pontos ficaram fora\n",
    "    cortados_material = int((df_material_box['valor_material'] > p99_material).sum())\n",
    "    if cortados_material:\n",
    "        axes[1].annotate(\n",
    "            f'{cortados_material} valores > p99 não exibidos',\n",
    "            xy=(0.98, 0.95), xycoords='axes fraction',\n",
    "            ha='right', va='top', fontsize=9,\n",
    "            bbox=dict(boxstyle='round,pad=0.3', fc='white', ec='gray', alpha=0.8)\n",
    "        )\n",
    "\n",
    "    axes[1].set_title('Danos Materiais por Tipo de Vara', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_xlabel('Tipo de Vara', fontsize=10)\n",
    "    axes[1].set_ylabel('Valor (R$)', fontsize=10)\n",
    "    axes[1].yaxis.set_major_formatter(fmt)\n",
    "    axes[1].tick_params(axis='x', rotation=0)\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "else:\n",
    "    axes[1].text(0.5, 0.5, 'Sem dados disponíveis', ha='center', va='center', transform=axes[1].transAxes)\n",
    "    axes[1].set_title('Danos Materiais por Tipo de Vara', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('boxplots_danos_vara_p99.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b5149b",
   "metadata": {},
   "source": [
    "### Interpretação das Estatísticas\n",
    "\n",
    "**Observações principais:**\n",
    "\n",
    "- **Valores de Danos Morais**: A distribuição revela a variação típica de pedidos de indenização moral em processos de consignação de crédito, com mediana e média indicando o valor central esperado.\n",
    "\n",
    "- **Valores de Danos Materiais**: Menos frequentes que danos morais, os valores materiais tendem a ser mais concentrados (menor desvio-padrão relativo) quando presentes.\n",
    "\n",
    "- **Variação por Tipo de Vara**: Os boxplots mostram diferenças regionais e jurisdicionais nos valores pedidos, com algumas varas apresentando outliers significativos.\n",
    "\n",
    "- **Presença de Flags**: A ocorrência de expressões como \"não inferior a\", \"em dobro\" ou \"até\" indica estratégias processuais diferenciadas, que podem correlacionar-se com os valores efetivamente deferidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9173f6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABA 2: DESCRITIVO (Estatísticas completas já calculadas na Seção 11)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RELATÓRIO - ABA DESCRITIVO\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nEstatísticas de Danos Morais:\")\n",
    "display(stats_moral)\n",
    "print(\"\\nEstatísticas de Danos Materiais:\")\n",
    "display(stats_material)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a439ce",
   "metadata": {},
   "source": [
    "## 13. Sanidade Final e Verificação de Outputs\n",
    "\n",
    "Esta seção verifica a integridade dos arquivos gerados e imprime um resumo final consolidado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d1baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"VERIFICAÇÃO DE SANIDADE DOS OUTPUTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Verificar output.xlsx (7 colunas da função original)\n",
    "output_path = 'output.xlsx'\n",
    "if os.path.exists(output_path):\n",
    "    df_output = pd.read_excel(output_path)\n",
    "    colunas_esperadas = ['cd_atendimento', 'nome_empresa', 'cnpj', 'valor_causa', 'dt_distribuicao', 'tipo_vara', 'uf']\n",
    "    colunas_presentes = list(df_output.columns)\n",
    "    \n",
    "    print(f\"\\n✓ Arquivo '{output_path}' encontrado\")\n",
    "    print(f\"  - Linhas: {len(df_output)}\")\n",
    "    print(f\"  - Colunas: {colunas_presentes}\")\n",
    "    \n",
    "    if colunas_presentes == colunas_esperadas:\n",
    "        print(\"  ✓ Colunas corretas (7 colunas conforme roteiro)\")\n",
    "    else:\n",
    "        print(f\"  ✗ ATENÇÃO: Colunas diferentes do esperado!\")\n",
    "        print(f\"    Esperado: {colunas_esperadas}\")\n",
    "        print(f\"    Encontrado: {colunas_presentes}\")\n",
    "    \n",
    "    # Verificar tipos\n",
    "    print(f\"\\n  Tipagem de 'valor_causa': {df_output['valor_causa'].dtype}\")\n",
    "    if df_output['valor_causa'].dtype in ['float64', 'float32']:\n",
    "        print(\"  ✓ valor_causa é float\")\n",
    "    else:\n",
    "        print(f\"  ✗ ATENÇÃO: valor_causa não é float!\")\n",
    "        \n",
    "    # Verificar formato de data\n",
    "    amostra_datas = df_output['dt_distribuicao'].dropna().head(3).tolist()\n",
    "    print(f\"  Amostra dt_distribuicao: {amostra_datas}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\n✗ ERRO: Arquivo '{output_path}' NÃO encontrado!\")\n",
    "    print(\"  Execute a Seção 9 para gerar output.xlsx\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "\n",
    "# 2. Verificar relatorio.xlsx (3 abas)\n",
    "relatorio_path = 'relatorio.xlsx'\n",
    "if os.path.exists(relatorio_path):\n",
    "    wb = load_workbook(relatorio_path)\n",
    "    abas_presentes = wb.sheetnames\n",
    "    abas_esperadas = ['Resumo', 'Descritivo', 'Logs_Sanidade']\n",
    "    \n",
    "    print(f\"\\n✓ Arquivo '{relatorio_path}' encontrado\")\n",
    "    print(f\"  - Abas: {abas_presentes}\")\n",
    "    \n",
    "    if set(abas_esperadas).issubset(set(abas_presentes)):\n",
    "        print(\"  ✓ Todas as 3 abas esperadas estão presentes\")\n",
    "    else:\n",
    "        print(f\"  ✗ ATENÇÃO: Abas faltando!\")\n",
    "        print(f\"    Esperado: {abas_esperadas}\")\n",
    "        \n",
    "else:\n",
    "    print(f\"\\n✗ ERRO: Arquivo '{relatorio_path}' NÃO encontrado!\")\n",
    "    print(\"  Execute a Seção 12 para gerar relatorio.xlsx\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4a1d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESUMO FINAL CONSOLIDADO\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RESUMO FINAL DO PROCESSAMENTO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Usar resultado_expandido se disponível, senão tentar ler de output.xlsx\n",
    "try:\n",
    "    df_final = resultado_expandido\n",
    "    print(\"\\n[Dados de resultado_expandido]\")\n",
    "except NameError:\n",
    "    if os.path.exists('output.xlsx'):\n",
    "        df_final = pd.read_excel('output.xlsx')\n",
    "        print(\"\\n[Dados de output.xlsx]\")\n",
    "    else:\n",
    "        print(\"\\n✗ ERRO: Nenhum dataset disponível para resumo!\")\n",
    "        df_final = None\n",
    "\n",
    "if df_final is not None:\n",
    "    print(f\"\\n Total de linhas processadas: {len(df_final)}\")\n",
    "    \n",
    "    # CNPJ vazio\n",
    "    cnpj_vazio_count = (df_final['cnpj'] == 'vazio').sum()\n",
    "    print(f\"\\n CNPJs:\")\n",
    "    print(f\"   - CNPJ = 'vazio': {cnpj_vazio_count} ({cnpj_vazio_count/len(df_final)*100:.2f}%)\")\n",
    "    print(f\"   - CNPJ válido: {len(df_final) - cnpj_vazio_count} ({(len(df_final)-cnpj_vazio_count)/len(df_final)*100:.2f}%)\")\n",
    "    \n",
    "    # Datas vazias\n",
    "    datas_vazias = (df_final['dt_distribuicao'] == '').sum()\n",
    "    print(f\"\\n Datas de Distribuição:\")\n",
    "    print(f\"   - Vazias: {datas_vazias} ({datas_vazias/len(df_final)*100:.2f}%)\")\n",
    "    print(f\"   - Preenchidas: {len(df_final) - datas_vazias} ({(len(df_final)-datas_vazias)/len(df_final)*100:.2f}%)\")\n",
    "    \n",
    "    # Médias de valores (se disponível no df_final)\n",
    "    if 'valor_moral' in df_final.columns and 'valor_material' in df_final.columns:\n",
    "        moral_positivos = df_final[df_final['valor_moral'] > 0]['valor_moral']\n",
    "        material_positivos = df_final[df_final['valor_material'] > 0]['valor_material']\n",
    "        \n",
    "        print(f\"\\n Valores Médios (apenas > 0):\")\n",
    "        if len(moral_positivos) > 0:\n",
    "            print(f\"   - Danos Morais: R$ {moral_positivos.mean():,.2f} ({len(moral_positivos)} casos)\")\n",
    "        else:\n",
    "            print(f\"   - Danos Morais: N/A (nenhum caso com valor > 0)\")\n",
    "            \n",
    "        if len(material_positivos) > 0:\n",
    "            print(f\"   - Danos Materiais: R$ {material_positivos.mean():,.2f} ({len(material_positivos)} casos)\")\n",
    "        else:\n",
    "            print(f\"   - Danos Materiais: N/A (nenhum caso com valor > 0)\")\n",
    "    \n",
    "    # Valor causa\n",
    "    if 'valor_causa' in df_final.columns:\n",
    "        valor_causa_positivos = df_final[df_final['valor_causa'] > 0]['valor_causa']\n",
    "        print(f\"\\n Valor da Causa:\")\n",
    "        if len(valor_causa_positivos) > 0:\n",
    "            print(f\"   - Média: R$ {valor_causa_positivos.mean():,.2f}\")\n",
    "            print(f\"   - Casos com valor > 0: {len(valor_causa_positivos)} ({len(valor_causa_positivos)/len(df_final)*100:.2f}%)\")\n",
    "        else:\n",
    "            print(f\"   - Nenhum caso com valor_causa > 0\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ PROCESSAMENTO CONCLUÍDO COM SUCESSO\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab78ddd",
   "metadata": {},
   "source": [
    "## 11.1 Feature Store / Targets (Preparação para Modelagem)\n",
    "\n",
    "Esta seção prepara os dados para modelagem inferencial sem alterar a função `extrair_dados()` que gera `output.xlsx`.\n",
    "\n",
    "**Objetivos:**\n",
    "- Garantir alvos numéricos (valor_moral, valor_material) como float\n",
    "- Criar features determinísticas (flags) para modelos\n",
    "- Preparar splits de treino/teste\n",
    "- One-hot encoding de variáveis categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb751fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports opcionais para modelagem (não obrigatório no venv)\n",
    "# Descomente se necessário:\n",
    "# !pip install -q statsmodels scikit-learn\n",
    "\n",
    "# Imports já disponíveis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Imports carregados para Feature Store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4911a55c",
   "metadata": {},
   "source": [
    "### Garantir Alvos Numéricos (valor_moral, valor_material)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5544d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANTE: Execute seção 10.1 antes para ter resultado_expandido disponível\n",
    "\n",
    "# Verificar se já temos valores morais/materiais extraídos\n",
    "if 'valor_moral' in resultado_expandido.columns and 'valor_material' in resultado_expandido.columns:\n",
    "    print(\"Valores morais/materiais já extraídos. Garantindo tipagem float...\")\n",
    "    \n",
    "    # Garantir tipo float e substituir NaN por 0.0\n",
    "    resultado_expandido['valor_moral'] = pd.to_numeric(resultado_expandido['valor_moral'], errors='coerce').fillna(0.0)\n",
    "    resultado_expandido['valor_material'] = pd.to_numeric(resultado_expandido['valor_material'], errors='coerce').fillna(0.0)\n",
    "    \n",
    "    print(f\"  valor_moral: {resultado_expandido['valor_moral'].dtype}, {(resultado_expandido['valor_moral']>0).sum()} valores > 0\")\n",
    "    print(f\"  valor_material: {resultado_expandido['valor_material'].dtype}, {(resultado_expandido['valor_material']>0).sum()} valores > 0\")\n",
    "else:\n",
    "    print(\"AVISO: Execute a Seção 10.1 primeiro para extrair valores morais/materiais!\")\n",
    "    # Criar colunas vazias para não quebrar o código\n",
    "    resultado_expandido['valor_moral'] = 0.0\n",
    "    resultado_expandido['valor_material'] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d8b078",
   "metadata": {},
   "source": [
    "### Criar Features Determinísticas (Regras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677456ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar cópia para trabalho (não alterar original)\n",
    "df_features = resultado_expandido.copy()\n",
    "\n",
    "# 1. tem_cnpj: 1 se CNPJ válido, 0 se \"vazio\"\n",
    "df_features['tem_cnpj'] = (df_features['cnpj'] != 'vazio').astype(int)\n",
    "\n",
    "# 2. is_JE: 1 se Juizado Especial, 0 se Vara Comum\n",
    "df_features['is_JE'] = (df_features['tipo_vara'] == 'JE').astype(int)\n",
    "\n",
    "# 3. tem_uf: 1 se UF preenchida\n",
    "df_features['tem_uf'] = (df_features['uf'] != '').astype(int)\n",
    "\n",
    "# 4. Garantir flags de texto como int (se já existem)\n",
    "if 'has_minimo' in df_features.columns:\n",
    "    df_features['has_minimo'] = df_features['has_minimo'].astype(int)\n",
    "else:\n",
    "    df_features['has_minimo'] = 0\n",
    "\n",
    "if 'has_em_dobro' in df_features.columns:\n",
    "    df_features['has_em_dobro'] = df_features['has_em_dobro'].astype(int)\n",
    "else:\n",
    "    df_features['has_em_dobro'] = 0\n",
    "\n",
    "if 'has_ate' in df_features.columns:\n",
    "    df_features['has_ate'] = df_features['has_ate'].astype(int)\n",
    "else:\n",
    "    df_features['has_ate'] = 0\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURES CRIADAS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\ntem_cnpj: {df_features['tem_cnpj'].sum()} casos com CNPJ válido ({df_features['tem_cnpj'].sum()/len(df_features)*100:.1f}%)\")\n",
    "print(f\"is_JE: {df_features['is_JE'].sum()} casos em Juizado Especial ({df_features['is_JE'].sum()/len(df_features)*100:.1f}%)\")\n",
    "print(f\"tem_uf: {df_features['tem_uf'].sum()} casos com UF ({df_features['tem_uf'].sum()/len(df_features)*100:.1f}%)\")\n",
    "print(f\"has_minimo: {df_features['has_minimo'].sum()} casos\")\n",
    "print(f\"has_em_dobro: {df_features['has_em_dobro'].sum()} casos\")\n",
    "print(f\"has_ate: {df_features['has_ate'].sum()} casos\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f95a07",
   "metadata": {},
   "source": [
    "### Sanidade dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd588454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover linhas com dados críticos faltando\n",
    "# (não alterar df original, trabalhar em cópia)\n",
    "\n",
    "df_clean = df_features.dropna(subset=['valor_causa', 'tipo_vara', 'uf']).copy()\n",
    "\n",
    "print(f\"Registros antes da limpeza: {len(df_features)}\")\n",
    "print(f\"Registros após limpeza: {len(df_clean)}\")\n",
    "print(f\"Removidos: {len(df_features) - len(df_clean)}\")\n",
    "\n",
    "# Criar datasets separados para modelagem\n",
    "df_moral = df_clean[df_clean['valor_moral'] > 0].copy()\n",
    "df_material = df_clean[df_clean['valor_material'] > 0].copy()\n",
    "\n",
    "print(f\"\\nDataset MORAL: {len(df_moral)} casos com valor_moral > 0\")\n",
    "print(f\"Dataset MATERIAL: {len(df_material)} casos com valor_material > 0\")\n",
    "\n",
    "# Backup se dataset muito pequeno\n",
    "if len(df_moral) < 10:\n",
    "    print(\"\\nAVISO: Dataset de danos morais muito pequeno (<10 casos). Modelagem pode não ser confiável.\")\n",
    "    \n",
    "if len(df_material) < 10:\n",
    "    print(\"\\nAVISO: Dataset de danos materiais muito pequeno (<10 casos). Modelagem pode não ser confiável.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fe563f",
   "metadata": {},
   "source": [
    "### Split Train/Test e One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97811194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar train_test_split (descomente se necessário instalar sklearn)\n",
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    sklearn_available = True\n",
    "except ImportError:\n",
    "    print(\"AVISO: sklearn não instalado. Execute: pip install scikit-learn\")\n",
    "    print(\"Split manual será usado como fallback.\\n\")\n",
    "    sklearn_available = False\n",
    "\n",
    "# Features para modelagem\n",
    "feature_cols = ['is_JE', 'tem_uf', 'tem_cnpj', 'has_minimo', 'has_em_dobro', 'has_ate']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PREPARAÇÃO DE DATASETS PARA MODELAGEM\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ========== DANOS MORAIS ==========\n",
    "if len(df_moral) >= 10 and sklearn_available:\n",
    "    # Preparar X e y para danos morais\n",
    "    X_moral_base = df_moral[feature_cols + ['tipo_vara', 'uf']].copy()\n",
    "    y_moral = np.log1p(df_moral['valor_moral'].astype(float))\n",
    "    \n",
    "    # One-hot encoding\n",
    "    X_moral_encoded = pd.get_dummies(X_moral_base, columns=['tipo_vara', 'uf'], drop_first=False)\n",
    "    \n",
    "    # Split 80/20\n",
    "    X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n",
    "        X_moral_encoded, y_moral, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nDANOS MORAIS:\")\n",
    "    print(f\"  Total: {len(df_moral)} casos\")\n",
    "    print(f\"  Treino: {len(X_train_m)} casos\")\n",
    "    print(f\"  Teste: {len(X_test_m)} casos\")\n",
    "    print(f\"  Features: {list(X_moral_encoded.columns)}\")\n",
    "    print(f\"  Target: log1p(valor_moral)\")\n",
    "    \n",
    "    # Salvar dataset final\n",
    "    df_moral_final = X_moral_encoded.copy()\n",
    "    df_moral_final['target_log'] = y_moral\n",
    "    df_moral_final['valor_moral_original'] = df_moral['valor_moral'].values\n",
    "    \n",
    "elif len(df_moral) > 0:\n",
    "    print(f\"\\nDANOS MORAIS: Dataset pequeno ({len(df_moral)} casos) ou sklearn indisponível\")\n",
    "    X_train_m, X_test_m, y_train_m, y_test_m = None, None, None, None\n",
    "    df_moral_final = df_moral.copy()\n",
    "else:\n",
    "    print(\"\\nDANOS MORAIS: Nenhum caso disponível\")\n",
    "    X_train_m, X_test_m, y_train_m, y_test_m = None, None, None, None\n",
    "    df_moral_final = pd.DataFrame()\n",
    "\n",
    "# ========== DANOS MATERIAIS ==========\n",
    "if len(df_material) >= 10 and sklearn_available:\n",
    "    # Preparar X e y para danos materiais\n",
    "    X_material_base = df_material[feature_cols + ['tipo_vara', 'uf']].copy()\n",
    "    y_material = np.log1p(df_material['valor_material'].astype(float))\n",
    "    \n",
    "    # One-hot encoding\n",
    "    X_material_encoded = pd.get_dummies(X_material_base, columns=['tipo_vara', 'uf'], drop_first=False)\n",
    "    \n",
    "    # Split 80/20\n",
    "    X_train_mat, X_test_mat, y_train_mat, y_test_mat = train_test_split(\n",
    "        X_material_encoded, y_material, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nDANOS MATERIAIS:\")\n",
    "    print(f\"  Total: {len(df_material)} casos\")\n",
    "    print(f\"  Treino: {len(X_train_mat)} casos\")\n",
    "    print(f\"  Teste: {len(X_test_mat)} casos\")\n",
    "    print(f\"  Features: {list(X_material_encoded.columns)}\")\n",
    "    print(f\"  Target: log1p(valor_material)\")\n",
    "    \n",
    "    # Salvar dataset final\n",
    "    df_material_final = X_material_encoded.copy()\n",
    "    df_material_final['target_log'] = y_material\n",
    "    df_material_final['valor_material_original'] = df_material['valor_material'].values\n",
    "    \n",
    "elif len(df_material) > 0:\n",
    "    print(f\"\\nDANOS MATERIAIS: Dataset pequeno ({len(df_material)} casos) ou sklearn indisponível\")\n",
    "    X_train_mat, X_test_mat, y_train_mat, y_test_mat = None, None, None, None\n",
    "    df_material_final = df_material.copy()\n",
    "else:\n",
    "    print(\"\\nDANOS MATERIAIS: Nenhum caso disponível\")\n",
    "    X_train_mat, X_test_mat, y_train_mat, y_test_mat = None, None, None, None\n",
    "    df_material_final = pd.DataFrame()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATASETS PRONTOS PARA MODELAGEM\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nVariáveis disponíveis:\")\n",
    "print(\"  - df_moral_final: dataset completo de danos morais\")\n",
    "print(\"  - df_material_final: dataset completo de danos materiais\")\n",
    "print(\"  - X_train_m, X_test_m, y_train_m, y_test_m: splits para danos morais\")\n",
    "print(\"  - X_train_mat, X_test_mat, y_train_mat, y_test_mat: splits para danos materiais\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91076303",
   "metadata": {},
   "source": [
    "## 11.2 Modelos Inferenciais (OLS com statsmodels)\n",
    "\n",
    "Esta seção implementa modelos de regressão OLS para explicar fatores associados aos valores de danos morais e materiais.\n",
    "\n",
    "**Objetivos:**\n",
    "- Estimar efeitos de tipo_vara, uf, cnpj e flags textuais sobre valores pedidos\n",
    "- Usar log1p(valor) como alvo para lidar com distribuição assimétrica\n",
    "- Interpretar coeficientes em termos de impacto percentual\n",
    "- Validar com métricas simples (MAE, R²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f3a8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports para modelagem inferencial\n",
    "try:\n",
    "    import statsmodels.formula.api as smf\n",
    "    from sklearn.metrics import mean_absolute_error, r2_score\n",
    "    statsmodels_available = True\n",
    "    print(\"statsmodels e sklearn disponíveis\")\n",
    "except ImportError as e:\n",
    "    print(f\"ERRO: {e}\")\n",
    "    print(\"Execute: pip install statsmodels scikit-learn\")\n",
    "    statsmodels_available = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfd84fa",
   "metadata": {},
   "source": [
    "### Modelo OLS - Danos Morais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f6dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if statsmodels_available and len(df_moral) >= 10:\n",
    "    print(\"=\"*80)\n",
    "    print(\"MODELO OLS - DANOS MORAIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Preparar base para statsmodels\n",
    "    base_m = df_moral.copy()\n",
    "    base_m['tem_cnpj'] = (base_m['cnpj'] != 'vazio').astype(int)\n",
    "    \n",
    "    # Garantir que flags existem (criar com 0 se não)\n",
    "    for flag in ['has_minimo', 'has_em_dobro', 'has_ate']:\n",
    "        if flag not in base_m.columns:\n",
    "            base_m[flag] = 0\n",
    "        else:\n",
    "            base_m[flag] = base_m[flag].fillna(0).astype(int)\n",
    "    \n",
    "    # Fórmula OLS com variáveis categóricas e flags\n",
    "    formula_m = \"np.log1p(valor_moral) ~ C(tipo_vara) + C(uf) + tem_cnpj + has_minimo + has_em_dobro + has_ate\"\n",
    "    \n",
    "    try:\n",
    "        # Ajustar modelo com erros robustos (HC3)\n",
    "        mod_m = smf.ols(formula=formula_m, data=base_m).fit(cov_type='HC3')\n",
    "        \n",
    "        print(f\"\\nModelo ajustado com {len(base_m)} observações\")\n",
    "        print(f\"Fórmula: {formula_m}\")\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(mod_m.summary())\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nERRO ao ajustar modelo: {e}\")\n",
    "        mod_m = None\n",
    "        base_m = None\n",
    "        \n",
    "elif not statsmodels_available:\n",
    "    print(\"statsmodels não disponível - modelo não ajustado\")\n",
    "    mod_m = None\n",
    "    base_m = None\n",
    "else:\n",
    "    print(f\"Dataset de danos morais muito pequeno ({len(df_moral)} casos < 10)\")\n",
    "    mod_m = None\n",
    "    base_m = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf8fa46",
   "metadata": {},
   "source": [
    "### Modelo OLS - Danos Materiais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04bd307",
   "metadata": {},
   "outputs": [],
   "source": [
    "if statsmodels_available and len(df_material) >= 10:\n",
    "    print(\"=\"*80)\n",
    "    print(\"MODELO OLS - DANOS MATERIAIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Preparar base para statsmodels\n",
    "    base_t = df_material.copy()\n",
    "    base_t['tem_cnpj'] = (base_t['cnpj'] != 'vazio').astype(int)\n",
    "    \n",
    "    # Garantir que flags existem (criar com 0 se não)\n",
    "    for flag in ['has_minimo', 'has_em_dobro', 'has_ate']:\n",
    "        if flag not in base_t.columns:\n",
    "            base_t[flag] = 0\n",
    "        else:\n",
    "            base_t[flag] = base_t[flag].fillna(0).astype(int)\n",
    "    \n",
    "    # Fórmula OLS com variáveis categóricas e flags\n",
    "    formula_t = \"np.log1p(valor_material) ~ C(tipo_vara) + C(uf) + tem_cnpj + has_minimo + has_em_dobro + has_ate\"\n",
    "    \n",
    "    try:\n",
    "        # Ajustar modelo com erros robustos (HC3)\n",
    "        mod_t = smf.ols(formula=formula_t, data=base_t).fit(cov_type='HC3')\n",
    "        \n",
    "        print(f\"\\nModelo ajustado com {len(base_t)} observações\")\n",
    "        print(f\"Fórmula: {formula_t}\")\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(mod_t.summary())\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nERRO ao ajustar modelo: {e}\")\n",
    "        mod_t = None\n",
    "        base_t = None\n",
    "        \n",
    "elif not statsmodels_available:\n",
    "    print(\"statsmodels não disponível - modelo não ajustado\")\n",
    "    mod_t = None\n",
    "    base_t = None\n",
    "else:\n",
    "    print(f\"Dataset de danos materiais muito pequeno ({len(df_material)} casos < 10)\")\n",
    "    mod_t = None\n",
    "    base_t = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b410e0e",
   "metadata": {},
   "source": [
    "### Métricas Rápidas (MAE e R²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8136268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular métricas rápidas\n",
    "def quick_metrics(model, df_base, target_col):\n",
    "    \"\"\"Calcula MAE e R² no espaço log\"\"\"\n",
    "    if model is None or df_base is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        y_true = np.log1p(df_base[target_col].astype(float))\n",
    "        y_pred = model.fittedvalues\n",
    "        \n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        \n",
    "        return {\n",
    "            \"MAE_log\": round(mae, 4),\n",
    "            \"R2_log\": round(r2, 4),\n",
    "            \"n_obs\": len(df_base)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao calcular métricas: {e}\")\n",
    "        return None\n",
    "\n",
    "# Calcular métricas para ambos os modelos\n",
    "print(\"=\"*80)\n",
    "print(\"MÉTRICAS DE AJUSTE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'mod_m' in locals() and mod_m is not None:\n",
    "    metrics_m = quick_metrics(mod_m, base_m, \"valor_moral\")\n",
    "    print(f\"\\nDanos Morais:\")\n",
    "    print(f\"  MAE (log): {metrics_m['MAE_log']}\")\n",
    "    print(f\"  R² (log): {metrics_m['R2_log']}\")\n",
    "    print(f\"  Observações: {metrics_m['n_obs']}\")\n",
    "else:\n",
    "    metrics_m = None\n",
    "    print(\"\\nDanos Morais: Modelo não disponível\")\n",
    "\n",
    "if 'mod_t' in locals() and mod_t is not None:\n",
    "    metrics_t = quick_metrics(mod_t, base_t, \"valor_material\")\n",
    "    print(f\"\\nDanos Materiais:\")\n",
    "    print(f\"  MAE (log): {metrics_t['MAE_log']}\")\n",
    "    print(f\"  R² (log): {metrics_t['R2_log']}\")\n",
    "    print(f\"  Observações: {metrics_t['n_obs']}\")\n",
    "else:\n",
    "    metrics_t = None\n",
    "    print(\"\\nDanos Materiais: Modelo não disponível\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c20780",
   "metadata": {},
   "source": [
    "### Interpretação dos Modelos\n",
    "\n",
    "Análise dos coeficientes em termos de impacto percentual sobre os valores pedidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4561f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para interpretar coeficientes em % (exp(beta) - 1)\n",
    "def interpretar_coeficiente(beta, nome_var):\n",
    "    \"\"\"Converte coeficiente log em impacto percentual\"\"\"\n",
    "    impacto_pct = (np.exp(beta) - 1) * 100\n",
    "    sinal = \"aumenta\" if impacto_pct > 0 else \"diminui\"\n",
    "    return f\"{nome_var}: {sinal} {abs(impacto_pct):.1f}%\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"INTERPRETAÇÃO DOS MODELOS OLS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ========== DANOS MORAIS ==========\n",
    "if 'mod_m' in locals() and mod_m is not None:\n",
    "    print(\"\\n### DANOS MORAIS ###\")\n",
    "    print(\"\\nCoeficientes mais relevantes (impacto % no valor):\\n\")\n",
    "    \n",
    "    params = mod_m.params\n",
    "    pvalues = mod_m.pvalues\n",
    "    \n",
    "    # Filtrar coeficientes significativos (p < 0.10)\n",
    "    coefs_sig = [(k, v, pvalues[k]) for k, v in params.items() if pvalues[k] < 0.10 and k != 'Intercept']\n",
    "    coefs_sig.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    \n",
    "    bullets = []\n",
    "    \n",
    "    for nome, beta, pval in coefs_sig[:6]:  # Top 6 coeficientes\n",
    "        impacto_pct = (np.exp(beta) - 1) * 100\n",
    "        sig_level = \"***\" if pval < 0.01 else \"**\" if pval < 0.05 else \"*\"\n",
    "        \n",
    "        # Interpretar nome da variável\n",
    "        if 'tipo_vara' in nome:\n",
    "            desc = nome.replace('C(tipo_vara)[T.', '').replace(']', '')\n",
    "            texto = f\"Processos em {desc} vs baseline\"\n",
    "        elif 'uf[T.' in nome:\n",
    "            uf = nome.replace('C(uf)[T.', '').replace(']', '')\n",
    "            texto = f\"Processos em {uf} vs baseline\"\n",
    "        elif 'tem_cnpj' in nome:\n",
    "            texto = \"Ter CNPJ identificado\"\n",
    "        elif 'has_minimo' in nome:\n",
    "            texto = \"Expressão 'não inferior a'\"\n",
    "        elif 'has_em_dobro' in nome:\n",
    "            texto = \"Expressão 'em dobro'\"\n",
    "        elif 'has_ate' in nome:\n",
    "            texto = \"Expressão 'até'\"\n",
    "        else:\n",
    "            texto = nome\n",
    "        \n",
    "        bullets.append(f\"  - {texto}: {impacto_pct:+.1f}% {sig_level} (p={pval:.3f})\")\n",
    "    \n",
    "    for b in bullets:\n",
    "        print(b)\n",
    "    \n",
    "    print(f\"\\n  R² ajustado: {mod_m.rsquared_adj:.3f}\")\n",
    "    print(f\"  Observações: {mod_m.nobs}\")\n",
    "    \n",
    "    print(\"\\n**Leitura:**\")\n",
    "    print(\"  - Coeficientes positivos indicam valores pedidos mais altos\")\n",
    "    print(\"  - Coeficientes negativos indicam valores mais baixos\")\n",
    "    print(\"  - % calculado como (exp(beta) - 1) × 100\")\n",
    "    print(\"  - Significância: *** p<0.01, ** p<0.05, * p<0.10\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n### DANOS MORAIS ###\")\n",
    "    print(\"Modelo não disponível\")\n",
    "\n",
    "# ========== DANOS MATERIAIS ==========\n",
    "if 'mod_t' in locals() and mod_t is not None:\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"\\n### DANOS MATERIAIS ###\")\n",
    "    print(\"\\nCoeficientes mais relevantes (impacto % no valor):\\n\")\n",
    "    \n",
    "    params = mod_t.params\n",
    "    pvalues = mod_t.pvalues\n",
    "    \n",
    "    # Filtrar coeficientes significativos (p < 0.10)\n",
    "    coefs_sig = [(k, v, pvalues[k]) for k, v in params.items() if pvalues[k] < 0.10 and k != 'Intercept']\n",
    "    coefs_sig.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    \n",
    "    bullets = []\n",
    "    \n",
    "    for nome, beta, pval in coefs_sig[:6]:  # Top 6 coeficientes\n",
    "        impacto_pct = (np.exp(beta) - 1) * 100\n",
    "        sig_level = \"***\" if pval < 0.01 else \"**\" if pval < 0.05 else \"*\"\n",
    "        \n",
    "        # Interpretar nome da variável\n",
    "        if 'tipo_vara' in nome:\n",
    "            desc = nome.replace('C(tipo_vara)[T.', '').replace(']', '')\n",
    "            texto = f\"Processos em {desc} vs baseline\"\n",
    "        elif 'uf[T.' in nome:\n",
    "            uf = nome.replace('C(uf)[T.', '').replace(']', '')\n",
    "            texto = f\"Processos em {uf} vs baseline\"\n",
    "        elif 'tem_cnpj' in nome:\n",
    "            texto = \"Ter CNPJ identificado\"\n",
    "        elif 'has_minimo' in nome:\n",
    "            texto = \"Expressão 'não inferior a'\"\n",
    "        elif 'has_em_dobro' in nome:\n",
    "            texto = \"Expressão 'em dobro'\"\n",
    "        elif 'has_ate' in nome:\n",
    "            texto = \"Expressão 'até'\"\n",
    "        else:\n",
    "            texto = nome\n",
    "        \n",
    "        bullets.append(f\"  - {texto}: {impacto_pct:+.1f}% {sig_level} (p={pval:.3f})\")\n",
    "    \n",
    "    for b in bullets:\n",
    "        print(b)\n",
    "    \n",
    "    print(f\"\\n  R² ajustado: {mod_t.rsquared_adj:.3f}\")\n",
    "    print(f\"  Observações: {mod_t.nobs}\")\n",
    "    \n",
    "    print(\"\\n**Leitura:**\")\n",
    "    print(\"  - Coeficientes positivos indicam valores pedidos mais altos\")\n",
    "    print(\"  - Coeficientes negativos indicam valores mais baixos\")\n",
    "    print(\"  - % calculado como (exp(beta) - 1) × 100\")\n",
    "    print(\"  - Significância: *** p<0.01, ** p<0.05, * p<0.10\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n### DANOS MATERIAIS ###\")\n",
    "    print(\"Modelo não disponível\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1dfada",
   "metadata": {},
   "source": [
    "### Validação Cruzada (Opcional - KFold 5x)\n",
    "\n",
    "Validação com cross-validation para verificar robustez das métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a874b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validação cruzada opcional (apenas para métricas, não para inferência)\n",
    "try:\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.model_selection import cross_val_score, KFold\n",
    "    sklearn_full = True\n",
    "except ImportError:\n",
    "    print(\"sklearn não disponível - validação cruzada não executada\")\n",
    "    sklearn_full = False\n",
    "\n",
    "if sklearn_full and statsmodels_available:\n",
    "    print(\"=\"*80)\n",
    "    print(\"VALIDAÇÃO CRUZADA (KFold 5x) - apenas para métricas\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # ========== DANOS MORAIS ==========\n",
    "    if 'base_m' in locals() and base_m is not None and len(base_m) >= 20:\n",
    "        print(\"\\nDanos Morais:\")\n",
    "        \n",
    "        # Preparar features (one-hot encoding)\n",
    "        X_m = pd.get_dummies(base_m[['tipo_vara', 'uf', 'tem_cnpj', 'has_minimo', 'has_em_dobro', 'has_ate']], \n",
    "                              drop_first=False)\n",
    "        y_m = np.log1p(base_m['valor_moral'])\n",
    "        \n",
    "        # KFold 5x\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        lr = LinearRegression()\n",
    "        \n",
    "        # Calcular MAE e R² com CV\n",
    "        mae_scores = -cross_val_score(lr, X_m, y_m, cv=kf, scoring='neg_mean_absolute_error')\n",
    "        r2_scores = cross_val_score(lr, X_m, y_m, cv=kf, scoring='r2')\n",
    "        \n",
    "        print(f\"  MAE médio (log): {mae_scores.mean():.4f} ± {mae_scores.std():.4f}\")\n",
    "        print(f\"  R² médio (log): {r2_scores.mean():.4f} ± {r2_scores.std():.4f}\")\n",
    "    else:\n",
    "        print(\"\\nDanos Morais: Dataset insuficiente para KFold (<20 casos)\")\n",
    "    \n",
    "    # ========== DANOS MATERIAIS ==========\n",
    "    if 'base_t' in locals() and base_t is not None and len(base_t) >= 20:\n",
    "        print(\"\\nDanos Materiais:\")\n",
    "        \n",
    "        # Preparar features (one-hot encoding)\n",
    "        X_t = pd.get_dummies(base_t[['tipo_vara', 'uf', 'tem_cnpj', 'has_minimo', 'has_em_dobro', 'has_ate']], \n",
    "                              drop_first=False)\n",
    "        y_t = np.log1p(base_t['valor_material'])\n",
    "        \n",
    "        # KFold 5x\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        lr = LinearRegression()\n",
    "        \n",
    "        # Calcular MAE e R² com CV\n",
    "        mae_scores = -cross_val_score(lr, X_t, y_t, cv=kf, scoring='neg_mean_absolute_error')\n",
    "        r2_scores = cross_val_score(lr, X_t, y_t, cv=kf, scoring='r2')\n",
    "        \n",
    "        print(f\"  MAE médio (log): {mae_scores.mean():.4f} ± {mae_scores.std():.4f}\")\n",
    "        print(f\"  R² médio (log): {r2_scores.mean():.4f} ± {r2_scores.std():.4f}\")\n",
    "    else:\n",
    "        print(\"\\nDanos Materiais: Dataset insuficiente para KFold (<20 casos)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"NOTA: Os modelos statsmodels (OLS) são preferidos para inferência.\")\n",
    "    print(\"Esta validação serve apenas para verificar robustez das métricas.\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "else:\n",
    "    print(\"Validação cruzada não executada (sklearn ou statsmodels indisponível)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e8118a",
   "metadata": {},
   "source": [
    "## 11.3 Classificadores Simples (Regras + ML)\n",
    "\n",
    "Implementação de classificadores para:\n",
    "- **(A) JE vs G1**: Distinguir Juizado Especial de Vara Comum\n",
    "- **(B) \"É consignado?\"**: Identificar casos de crédito consignado (se houver variação)\n",
    "\n",
    "**Abordagem:**\n",
    "- Regras determinísticas (baseline interpretável)\n",
    "- LogisticRegression com TF-IDF char n-grams (ML leve)\n",
    "- Comparação e combinação híbrida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7259e3",
   "metadata": {},
   "source": [
    "### Regras Determinísticas (Baseline Interpretável)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c592cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANTE: Use resultado_expandido ou df_clean da seção 11.1\n",
    "# Se não disponível, use dataset original filtrado\n",
    "\n",
    "try:\n",
    "    df_classif = df_clean.copy()\n",
    "    print(f\"Usando df_clean da seção 11.1: {len(df_classif)} casos\")\n",
    "except NameError:\n",
    "    try:\n",
    "        df_classif = resultado_expandido.copy()\n",
    "        print(f\"Usando resultado_expandido: {len(df_classif)} casos\")\n",
    "    except NameError:\n",
    "        print(\"ERRO: Execute seções anteriores primeiro (10.1 ou 11.1)\")\n",
    "        df_classif = pd.DataFrame()\n",
    "\n",
    "# Funções de regras determinísticas\n",
    "def rule_is_JE(texto: str) -> int:\n",
    "    \"\"\"Regra: identifica Juizado Especial por menções explícitas\"\"\"\n",
    "    s = (texto or \"\").lower()\n",
    "    # Busca por \"juizado especial\" ou \"jec\" (word boundary)\n",
    "    if \"juizado especial\" in s:\n",
    "        return 1\n",
    "    if re.search(r'\\bjec\\b', s):\n",
    "        return 1\n",
    "    if \"jecc\" in s:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def rule_is_consignado(texto: str) -> int:\n",
    "    \"\"\"Regra: identifica crédito consignado por menções explícitas\"\"\"\n",
    "    s = (texto or \"\").lower()\n",
    "    # Busca por \"crédito consignado\" ou \"empréstimo consignado\"\n",
    "    if re.search(r'\\bcr[eé]dito consignado\\b', s):\n",
    "        return 1\n",
    "    if \"empréstimo consignado\" in s:\n",
    "        return 1\n",
    "    if \"consignação\" in s and (\"crédito\" in s or \"empréstimo\" in s):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "print(\"\\nRegras definidas:\")\n",
    "print(\"  - rule_is_JE: busca 'juizado especial', 'jec', 'jecc'\")\n",
    "print(\"  - rule_is_consignado: busca 'crédito consignado', 'empréstimo consignado'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acea16d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_classif) > 0:\n",
    "    # Aplicar regras ao dataset\n",
    "    \n",
    "    # Regra JE: aplicar em ds_Qualificacao (ou texto combinado)\n",
    "    if 'ds_Qualificacao' in df_classif.columns:\n",
    "        df_classif['pred_je_rule'] = df_classif['ds_Qualificacao'].fillna(\"\").apply(rule_is_JE)\n",
    "    else:\n",
    "        # Fallback: usar texto combinado\n",
    "        texto_combined = (\n",
    "            df_classif.get('ds_Pedidos', pd.Series([\"\"]*len(df_classif))).fillna(\"\") + \" \" +\n",
    "            df_classif.get('ds_fatos', pd.Series([\"\"]*len(df_classif))).fillna(\"\")\n",
    "        )\n",
    "        df_classif['pred_je_rule'] = texto_combined.apply(rule_is_JE)\n",
    "    \n",
    "    # Regra Consignado: aplicar em texto combinado\n",
    "    texto_consig = (\n",
    "        df_classif.get('ds_Acao_Judicial', pd.Series([\"\"]*len(df_classif))).fillna(\"\").astype(str) + \" \" +\n",
    "        df_classif.get('ds_fatos', pd.Series([\"\"]*len(df_classif))).fillna(\"\").astype(str) + \" \" +\n",
    "        df_classif.get('ds_Pedidos', pd.Series([\"\"]*len(df_classif))).fillna(\"\").astype(str) + \" \" +\n",
    "        df_classif.get('ds_Qualificacao', pd.Series([\"\"]*len(df_classif))).fillna(\"\").astype(str)\n",
    "    )\n",
    "    df_classif['pred_consignado_rule'] = texto_consig.apply(rule_is_consignado)\n",
    "    \n",
    "    # Ground truth (se disponível)\n",
    "    if 'tipo_vara' in df_classif.columns:\n",
    "        df_classif['y_je_true'] = (df_classif['tipo_vara'] == 'JE').astype(int)\n",
    "    else:\n",
    "        df_classif['y_je_true'] = None\n",
    "        print(\"AVISO: coluna 'tipo_vara' não encontrada - usando regra como pseudo-label\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"APLICAÇÃO DE REGRAS DETERMINÍSTICAS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nJE (Juizado Especial):\")\n",
    "    print(f\"  Casos identificados como JE: {df_classif['pred_je_rule'].sum()} ({df_classif['pred_je_rule'].sum()/len(df_classif)*100:.1f}%)\")\n",
    "    print(f\"  Casos identificados como G1: {(1-df_classif['pred_je_rule']).sum()} ({(1-df_classif['pred_je_rule']).sum()/len(df_classif)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nCrédito Consignado:\")\n",
    "    print(f\"  Casos identificados: {df_classif['pred_consignado_rule'].sum()} ({df_classif['pred_consignado_rule'].sum()/len(df_classif)*100:.1f}%)\")\n",
    "    print(f\"  Casos NÃO identificados: {(1-df_classif['pred_consignado_rule']).sum()} ({(1-df_classif['pred_consignado_rule']).sum()/len(df_classif)*100:.1f}%)\")\n",
    "    \n",
    "    # Verificar variação para classificador B\n",
    "    variacao_consig = df_classif['pred_consignado_rule'].sum()\n",
    "    if variacao_consig == 0 or variacao_consig == len(df_classif):\n",
    "        print(\"\\n  NOTA: Dataset 100% homogêneo para 'consignado' - classificador B será pulado\")\n",
    "        skip_classif_b = True\n",
    "    else:\n",
    "        skip_classif_b = False\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"Dataset vazio - pule esta seção\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560720c6",
   "metadata": {},
   "source": [
    "### Classificador ML (A): JE vs G1 com LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d645892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Classificador ML (A): JE vs G1 com LogisticRegression (robusto a texto vazio) ===\n",
    "try:\n",
    "    import numpy as np, pandas as pd, re\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "    from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "    from scipy.sparse import hstack, csr_matrix\n",
    "    sklearn_classif = True\n",
    "except Exception as e:\n",
    "    print(f\"sklearn/scipy indisponível ({e}) — classificadores ML não executados\")\n",
    "    sklearn_classif = False\n",
    "\n",
    "clf_je = None\n",
    "metrics_clf_je_holdout, metrics_clf_je_cv = None, None\n",
    "\n",
    "if sklearn_classif and isinstance(df_classif, pd.DataFrame) and len(df_classif) > 20:\n",
    "    print(\"=\"*80)\n",
    "    print(\"CLASSIFICADOR ML (A): JE vs G1 (robusto)\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # ---------- Target ----------\n",
    "    use_gt = (\"y_je_true\" in df_classif.columns) and df_classif[\"y_je_true\"].notna().all()\n",
    "    if use_gt:\n",
    "        y_je = df_classif[\"y_je_true\"].astype(int).values\n",
    "        print(\"\\nUsando ground truth de 'tipo_vara'\")\n",
    "    else:\n",
    "        if \"pred_je_rule\" not in df_classif.columns:\n",
    "            # regra básica como fallback\n",
    "            def _rule_is_JE(texto: str) -> int:\n",
    "                s = (texto or \"\").lower()\n",
    "                return int((\"juizado especial\" in s) or (re.search(r\"\\bjec\\b\", s) is not None))\n",
    "            txt_base = df_classif.get(\"ds_Qualificacao\",\"\").astype(str)\n",
    "            df_classif[\"pred_je_rule\"] = txt_base.map(_rule_is_JE)\n",
    "        y_je = df_classif[\"pred_je_rule\"].astype(int).values\n",
    "        print(\"\\nUsando pseudo-label da regra (tipo_vara completo não disponível)\")\n",
    "\n",
    "    # distribuição\n",
    "    je_count = int(y_je.sum())\n",
    "    g1_count = int(len(y_je) - je_count)\n",
    "    print(f\"Distribuição: JE={je_count} ({je_count/len(y_je)*100:.1f}%), G1={g1_count} ({g1_count/len(y_je)*100:.1f}%)\")\n",
    "    if je_count < 5 or g1_count < 5:\n",
    "        print(\"AVISO: classes muito desbalanceadas — resultados podem não ser confiáveis\")\n",
    "\n",
    "    # checar se há 2 classes\n",
    "    unique_classes = np.unique(y_je)\n",
    "    if unique_classes.size < 2:\n",
    "        print(f\"AVISO: y_je tem {unique_classes.size} classe(s) — precisa de >=2. Abortando treino.\")\n",
    "    else:\n",
    "        # ---------- Texto ----------\n",
    "        txt_cols = [c for c in [\"ds_Qualificacao\", \"ds_Pedidos\", \"ds_fatos\"] if c in df_classif.columns]\n",
    "        if len(txt_cols) == 0:\n",
    "            print(\"\\nERRO: Nenhuma coluna de texto disponível — TF-IDF será pulado.\")\n",
    "            X_text = pd.Series([\"\"] * len(df_classif))\n",
    "        else:\n",
    "            X_text = df_classif[txt_cols].fillna(\"\").astype(str).agg(\" \".join, axis=1)\n",
    "            print(f\"\\nColunas de texto: {txt_cols}\")\n",
    "\n",
    "        has_text = X_text.str.strip().str.len() > 0\n",
    "\n",
    "        # ---------- TF-IDF (com fallback) ----------\n",
    "        X_tfidf = None\n",
    "        if has_text.any():\n",
    "            print(\"\\nGerando features TF-IDF (char n-grams 3–5)...\")\n",
    "            try:\n",
    "                tfidf = TfidfVectorizer(\n",
    "                    analyzer=\"char\",\n",
    "                    ngram_range=(3, 5),\n",
    "                    min_df=5,\n",
    "                    max_features=50000,\n",
    "                    lowercase=True\n",
    "                )\n",
    "                X_tfidf = tfidf.fit_transform(X_text)\n",
    "                if X_tfidf.shape[1] == 0:\n",
    "                    raise ValueError(\"Vocabulário vazio com min_df=5.\")\n",
    "                print(f\"  Shape TF-IDF: {X_tfidf.shape}\")\n",
    "            except Exception as e:\n",
    "                print(f\"FALLBACK TF-IDF: {e}\")\n",
    "                print(\"Tentando com n-grams (2–5) e min_df=1...\")\n",
    "                tfidf = TfidfVectorizer(\n",
    "                    analyzer=\"char\",\n",
    "                    ngram_range=(2, 5),\n",
    "                    min_df=1,\n",
    "                    max_features=50000,\n",
    "                    lowercase=True\n",
    "                )\n",
    "                X_tfidf = tfidf.fit_transform(X_text)\n",
    "                print(f\"  Shape TF-IDF (fallback): {X_tfidf.shape}\")\n",
    "        else:\n",
    "            print(\"AVISO: todos os documentos de texto ficaram vazios — TF-IDF será pulado.\")\n",
    "\n",
    "        # ---------- Features densas ----------\n",
    "        dense_features = []\n",
    "\n",
    "        if \"uf\" in df_classif.columns:\n",
    "            dense_features.append((df_classif[\"uf\"].fillna(\"\") != \"\").astype(int).values.reshape(-1, 1))\n",
    "\n",
    "        if \"cnpj\" in df_classif.columns:\n",
    "            dense_features.append((df_classif[\"cnpj\"].fillna(\"vazio\") != \"vazio\").astype(int).values.reshape(-1, 1))\n",
    "\n",
    "        for col in [\"has_minimo\", \"has_em_dobro\", \"has_ate\"]:\n",
    "            if col in df_classif.columns:\n",
    "                dense_features.append(df_classif[col].fillna(0).astype(int).values.reshape(-1, 1))\n",
    "\n",
    "        if len(dense_features) > 0:\n",
    "            X_dense = np.hstack(dense_features)\n",
    "            print(f\"  Features densas adicionadas: {X_dense.shape[1]}\")\n",
    "        else:\n",
    "            X_dense = np.zeros((len(df_classif), 0))\n",
    "\n",
    "        # ---------- Combinação final ----------\n",
    "        if X_tfidf is not None:\n",
    "            X = hstack([X_tfidf, csr_matrix(X_dense)])\n",
    "        else:\n",
    "            if X_dense.shape[1] == 0:\n",
    "                print(\"Sem TF-IDF e sem features densas — abortando classificador.\")\n",
    "                X = None\n",
    "            else:\n",
    "                X = csr_matrix(X_dense)\n",
    "\n",
    "        if X is not None:\n",
    "            print(f\"  Shape final: {X.shape}\")\n",
    "\n",
    "            # ---------- Split e treino ----------\n",
    "            print(\"\\nTreinamento com split 80/20...\")\n",
    "            X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "                X, y_je, test_size=0.2, random_state=42, stratify=y_je\n",
    "            )\n",
    "\n",
    "            # solver mais estável em sparse/datasets pequenos\n",
    "            clf_je = LogisticRegression(max_iter=200, random_state=42, solver=\"liblinear\")\n",
    "            clf_je.fit(X_tr, y_tr)\n",
    "\n",
    "            pred_te = clf_je.predict(X_te)\n",
    "            acc_test = accuracy_score(y_te, pred_te)\n",
    "            f1_test = f1_score(y_te, pred_te, zero_division=0)\n",
    "\n",
    "            metrics_clf_je_holdout = {\n",
    "                \"acc_test\": float(acc_test),\n",
    "                \"f1_test\": float(f1_test),\n",
    "                \"y_te\": y_te,\n",
    "                \"pred_te\": pred_te,\n",
    "            }\n",
    "\n",
    "            print(f\"\\nResultados no Test Set (20%):\")\n",
    "            print(f\"  Accuracy: {acc_test:.3f}\")\n",
    "            print(f\"  F1-Score: {f1_test:.3f}\")\n",
    "\n",
    "            print(\"\\nConfusion Matrix:\")\n",
    "            cm = confusion_matrix(y_te, pred_te)\n",
    "            print(f\"  TN={cm[0,0]}, FP={cm[0,1]}\")\n",
    "            print(f\"  FN={cm[1,0]}, TP={cm[1,1]}\")\n",
    "\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(classification_report(y_te, pred_te, target_names=[\"G1\", \"JE\"], zero_division=0))\n",
    "\n",
    "            # ---------- Cross-validation ----------\n",
    "            print(\"\\nCross-Validation (5-fold estratificado)...\")\n",
    "            cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "            acc_cv = cross_val_score(clf_je, X, y_je, cv=cv, scoring=\"accuracy\")\n",
    "            f1_cv = cross_val_score(clf_je, X, y_je, cv=cv, scoring=\"f1\")\n",
    "\n",
    "            metrics_clf_je_cv = {\n",
    "                \"acc_cv_mean\": float(acc_cv.mean()),\n",
    "                \"acc_cv_std\": float(acc_cv.std()),\n",
    "                \"f1_cv_mean\": float(f1_cv.mean()),\n",
    "                \"f1_cv_std\": float(f1_cv.std()),\n",
    "            }\n",
    "\n",
    "            print(f\"  CV Accuracy: {acc_cv.mean():.3f} ± {acc_cv.std():.3f}\")\n",
    "            print(f\"  CV F1-Score: {f1_cv.mean():.3f} ± {f1_cv.std():.3f}\")\n",
    "\n",
    "            # Previsões no dataset completo\n",
    "            df_classif[\"pred_je_ml\"] = clf_je.predict(X)\n",
    "\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "else:\n",
    "    if not sklearn_classif:\n",
    "        print(\"sklearn não disponível — classificador ML não executado\")\n",
    "    else:\n",
    "        print(f\"Dataset muito pequeno ({len(df_classif) if isinstance(df_classif, pd.DataFrame) else 'n/a'} casos) — classificador ML não executado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f99b3e9",
   "metadata": {},
   "source": [
    "### Comparação: Regras vs ML (Classificador A - JE/G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434e6947",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'clf_je' in locals() and clf_je is not None and 'y_je_true' in df_classif.columns and df_classif['y_je_true'].notna().all():\n",
    "    print(\"=\"*80)\n",
    "    print(\"COMPARAÇÃO: REGRAS vs ML (JE/G1)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    y_true = df_classif['y_je_true'].values\n",
    "    pred_rule = df_classif['pred_je_rule'].values\n",
    "    pred_ml = df_classif['pred_je_ml'].values\n",
    "    \n",
    "    # Métricas das regras\n",
    "    acc_rule = accuracy_score(y_true, pred_rule)\n",
    "    f1_rule = f1_score(y_true, pred_rule, zero_division=0)\n",
    "    \n",
    "    # Métricas do ML\n",
    "    acc_ml = accuracy_score(y_true, pred_ml)\n",
    "    f1_ml = f1_score(y_true, pred_ml, zero_division=0)\n",
    "    \n",
    "    print(\"\\n### BASELINE: REGRAS DETERMINÍSTICAS ###\")\n",
    "    print(f\"  Accuracy: {acc_rule:.3f}\")\n",
    "    print(f\"  F1-Score: {f1_rule:.3f}\")\n",
    "    \n",
    "    print(\"\\n  Confusion Matrix:\")\n",
    "    cm_rule = confusion_matrix(y_true, pred_rule)\n",
    "    print(f\"    TN={cm_rule[0,0]}, FP={cm_rule[0,1]}\")\n",
    "    print(f\"    FN={cm_rule[1,0]}, TP={cm_rule[1,1]}\")\n",
    "    \n",
    "    print(\"\\n### ML: LOGISTIC REGRESSION ###\")\n",
    "    print(f\"  Accuracy: {acc_ml:.3f}\")\n",
    "    print(f\"  F1-Score: {f1_ml:.3f}\")\n",
    "    \n",
    "    print(\"\\n  Confusion Matrix:\")\n",
    "    cm_ml = confusion_matrix(y_true, pred_ml)\n",
    "    print(f\"    TN={cm_ml[0,0]}, FP={cm_ml[0,1]}\")\n",
    "    print(f\"    FN={cm_ml[1,0]}, TP={cm_ml[1,1]}\")\n",
    "    \n",
    "    print(\"\\n### GANHO DO ML ###\")\n",
    "    ganho_acc = (acc_ml - acc_rule) * 100\n",
    "    ganho_f1 = (f1_ml - f1_rule) * 100\n",
    "    \n",
    "    print(f\"  Accuracy: {ganho_acc:+.1f} pontos percentuais\")\n",
    "    print(f\"  F1-Score: {ganho_f1:+.1f} pontos percentuais\")\n",
    "    \n",
    "    if ganho_acc < 2 and ganho_f1 < 2:\n",
    "        print(\"\\n  CONCLUSÃO: Regra determinística já é muito boa. ML oferece ganho marginal.\")\n",
    "        print(\"  Recomendação: Usar regra como baseline e ML apenas em casos ambíguos.\")\n",
    "    else:\n",
    "        print(\"\\n  CONCLUSÃO: ML oferece melhoria significativa sobre regras.\")\n",
    "        print(\"  Recomendação: Usar ML como classificador principal.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "elif 'pred_je_rule' in df_classif.columns and 'pred_je_ml' in df_classif.columns:\n",
    "    print(\"=\"*80)\n",
    "    print(\"COMPARAÇÃO: REGRAS vs ML (JE/G1)\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nGround truth não disponível - comparação entre regra e ML:\")\n",
    "    \n",
    "    concordancia = (df_classif['pred_je_rule'] == df_classif['pred_je_ml']).sum()\n",
    "    total = len(df_classif)\n",
    "    \n",
    "    print(f\"  Casos em concordância: {concordancia}/{total} ({concordancia/total*100:.1f}%)\")\n",
    "    print(f\"  Casos em divergência: {total-concordancia}/{total} ({(total-concordancia)/total*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\n  NOTA: Sem ground truth, não é possível calcular accuracy/F1 real.\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "else:\n",
    "    print(\"Comparação não disponível - execute células anteriores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9727ed",
   "metadata": {},
   "source": [
    "### Classificador Híbrido (Regra + ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a96c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pred_je_rule' in df_classif.columns and 'pred_je_ml' in df_classif.columns:\n",
    "    print(\"=\"*80)\n",
    "    print(\"CLASSIFICADOR HÍBRIDO: REGRA + ML\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Estratégia: Usar regra como preferencial; se regra \"indefinida\", usar ML\n",
    "    # Para JE/G1, consideramos \"indefinido\" quando não há menção explícita\n",
    "    \n",
    "    # Detectar casos onde regra não encontrou padrão explícito\n",
    "    # (podemos usar um threshold de confiança ou simplesmente usar sempre regra primeiro)\n",
    "    \n",
    "    # Versão simples: sempre preferir regra, ML apenas como fallback\n",
    "    df_classif['pred_je_final'] = df_classif['pred_je_rule'].copy()\n",
    "    \n",
    "    # Contar casos onde usamos cada método\n",
    "    casos_regra = len(df_classif)\n",
    "    casos_ml_fallback = 0  # Nesta versão simples, sempre usamos regra\n",
    "    \n",
    "    print(\"\\nEstratégia: Preferir regra determinística (sempre)\")\n",
    "    print(f\"  Casos classificados por regra: {casos_regra} (100%)\")\n",
    "    print(f\"  Casos com fallback para ML: {casos_ml_fallback} (0%)\")\n",
    "    \n",
    "    print(\"\\nDistribuição Final:\")\n",
    "    print(f\"  JE: {df_classif['pred_je_final'].sum()} ({df_classif['pred_je_final'].sum()/len(df_classif)*100:.1f}%)\")\n",
    "    print(f\"  G1: {(1-df_classif['pred_je_final']).sum()} ({(1-df_classif['pred_je_final']).sum()/len(df_classif)*100:.1f}%)\")\n",
    "    \n",
    "    # Avaliar híbrido se temos ground truth\n",
    "    if 'y_je_true' in df_classif.columns and df_classif['y_je_true'].notna().all():\n",
    "        acc_hybrid = accuracy_score(df_classif['y_je_true'], df_classif['pred_je_final'])\n",
    "        f1_hybrid = f1_score(df_classif['y_je_true'], df_classif['pred_je_final'], zero_division=0)\n",
    "        \n",
    "        print(f\"\\nPerformance do Híbrido:\")\n",
    "        print(f\"  Accuracy: {acc_hybrid:.3f}\")\n",
    "        print(f\"  F1-Score: {f1_hybrid:.3f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"NOTA: Predições salvas em df_classif['pred_je_final']\")\n",
    "    print(\"      Não são adicionadas ao output.xlsx (apenas para análise)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "else:\n",
    "    print(\"Classificador híbrido não disponível - execute células anteriores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ae976d",
   "metadata": {},
   "source": [
    "### Resumo e Conclusões dos Classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f6ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RESUMO FINAL - CLASSIFICADORES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n### CLASSIFICADOR (A): JE vs G1 ###\")\n",
    "\n",
    "if 'pred_je_rule' in df_classif.columns:\n",
    "    print(\"\\n**Regra Determinística:**\")\n",
    "    print(\"  - Busca: 'juizado especial', 'jec', 'jecc'\")\n",
    "    print(\"  - Vantagens: Interpretável, rápida, sem treinamento\")\n",
    "    print(\"  - Limitações: Pode perder casos com grafia variante\")\n",
    "    \n",
    "    if 'clf_je' in locals() and clf_je is not None:\n",
    "        print(\"\\n**ML (LogisticRegression + TF-IDF):**\")\n",
    "        print(\"  - Features: Char n-grams (3-5) + flags textuais\")\n",
    "        print(\"  - Vantagens: Robusto a variações, aprende padrões latentes\")\n",
    "        print(\"  - Limitações: Caixa-preta, requer treinamento\")\n",
    "        \n",
    "        if 'y_je_true' in df_classif.columns and df_classif['y_je_true'].notna().all():\n",
    "            acc_rule = accuracy_score(df_classif['y_je_true'], df_classif['pred_je_rule'])\n",
    "            acc_ml = accuracy_score(df_classif['y_je_true'], df_classif['pred_je_ml'])\n",
    "            \n",
    "            print(f\"\\n**Comparação (Accuracy):**\")\n",
    "            print(f\"  Regra: {acc_rule:.3f}\")\n",
    "            print(f\"  ML:    {acc_ml:.3f}\")\n",
    "            print(f\"  Ganho: {(acc_ml-acc_rule)*100:+.1f} p.p.\")\n",
    "            \n",
    "            if acc_ml > acc_rule + 0.02:\n",
    "                print(\"\\n  RECOMENDAÇÃO: Usar ML como classificador principal\")\n",
    "            elif acc_rule > 0.95:\n",
    "                print(\"\\n  RECOMENDAÇÃO: Regra já é excelente. Usar regra + ML como fallback\")\n",
    "            else:\n",
    "                print(\"\\n  RECOMENDAÇÃO: Usar abordagem híbrida (regra primeiro, ML em casos ambíguos)\")\n",
    "        else:\n",
    "            print(\"\\n  NOTA: Ground truth não disponível - não é possível comparar performance real\")\n",
    "    else:\n",
    "        print(\"\\n**ML:** Não executado (dataset pequeno ou sklearn indisponível)\")\n",
    "\n",
    "print(\"\\n### CLASSIFICADOR (B): É Consignado? ###\")\n",
    "\n",
    "if 'pred_consignado_rule' in df_classif.columns:\n",
    "    variacao = df_classif['pred_consignado_rule'].sum()\n",
    "    \n",
    "    if variacao == 0:\n",
    "        print(\"  PULADO: Dataset 100% NÃO-consignado (sem variação)\")\n",
    "    elif variacao == len(df_classif):\n",
    "        print(\"  PULADO: Dataset 100% consignado (sem variação)\")\n",
    "        print(\"  NOTA: Input já filtrado na Entrega 5 - todos os casos são consignados\")\n",
    "    else:\n",
    "        print(f\"  Variação detectada: {variacao}/{len(df_classif)} casos consignados\")\n",
    "        print(\"  Este classificador poderia ser treinado, mas não foi implementado\")\n",
    "        print(\"  (dataset já filtrado para consignado na Entrega 5)\")\n",
    "\n",
    "print(\"\\n### VARIÁVEIS CRIADAS (para análise, NÃO entram em output.xlsx) ###\")\n",
    "print(\"  - pred_je_rule: Predição por regra determinística\")\n",
    "if 'pred_je_ml' in df_classif.columns:\n",
    "    print(\"  - pred_je_ml: Predição por LogisticRegression\")\n",
    "if 'pred_je_final' in df_classif.columns:\n",
    "    print(\"  - pred_je_final: Predição híbrida (regra preferencial)\")\n",
    "if 'pred_consignado_rule' in df_classif.columns:\n",
    "    print(\"  - pred_consignado_rule: Predição de consignado por regra\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLASSIFICAÇÃO CONCLUÍDA\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88731a28",
   "metadata": {},
   "source": [
    "## 11.4 Camada de Regras (Override) + Feature Store (Logístico)\n",
    "\n",
    "Esta seção implementa:\n",
    "1. **Regras determinísticas (override)**: Identificam casos estratégicos por padrões textuais inequívocos\n",
    "2. **Feature engineering**: Prepara features para modelo logístico nos casos sem override\n",
    "3. **Separação explícita**: Casos com override já são classificados (não precisam de modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32890b34",
   "metadata": {},
   "source": [
    "### 11.4.1 Helpers de Normalização\n",
    "\n",
    "Reutiliza ou cria funções para normalizar texto (remove acentos, lowercase, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951784a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers de normalização (reutilizar ou criar)\n",
    "import unicodedata\n",
    "\n",
    "def strip_accents(text):\n",
    "    \"\"\"Remove acentos de uma string.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    nfkd = unicodedata.normalize('NFKD', text)\n",
    "    return \"\".join([c for c in nfkd if not unicodedata.combining(c)])\n",
    "\n",
    "def safe_str(value):\n",
    "    \"\"\"Converte valor para string, tratando None e vazios.\"\"\"\n",
    "    if value is None or (isinstance(value, float) and pd.isna(value)):\n",
    "        return \"\"\n",
    "    return str(value).strip()\n",
    "\n",
    "def normalizar_texto(text):\n",
    "    \"\"\"Normaliza texto: lowercase, sem acentos, espaços extras removidos.\"\"\"\n",
    "    text = safe_str(text)\n",
    "    text = strip_accents(text)\n",
    "    text = text.lower()\n",
    "    text = ' '.join(text.split())  # Remove espaços duplicados\n",
    "    return text\n",
    "\n",
    "print(\"✓ Helpers de normalização carregados\")\n",
    "print(\"  Funções: strip_accents, safe_str, normalizar_texto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f86220d",
   "metadata": {},
   "source": [
    "### 11.4.2 Regras Determinísticas (Override)\n",
    "\n",
    "Identifica casos estratégicos por padrões textuais inequívocos.\n",
    "\n",
    "**Categorias de override:**\n",
    "- **coletiva**: ação civil pública, acp, coletiva, ministério público, sindicato\n",
    "- **ms**: mandado de segurança, m.s., ms\n",
    "- **constitucional**: habeas data, ação popular, adi, adin, adpf, inconstitucionalidade\n",
    "\n",
    "Se nenhum padrão for encontrado, retorna `None` (caso será analisado por modelo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80658f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificar_override(texto):\n",
    "    \"\"\"\n",
    "    Classifica caso por regras determinísticas (override).\n",
    "    \n",
    "    Args:\n",
    "        texto: string concatenada de ds_Acao_Judicial, ds_fatos, ds_Pedidos, ds_Qualificacao\n",
    "        \n",
    "    Returns:\n",
    "        str: \"coletiva\", \"ms\", \"constitucional\" ou None\n",
    "    \"\"\"\n",
    "    texto_norm = normalizar_texto(texto)\n",
    "    \n",
    "    # Padrões para ação coletiva\n",
    "    padroes_coletiva = [\n",
    "        'acao civil publica',\n",
    "        'ação civil pública',\n",
    "        r'\\bacp\\b',\n",
    "        'coletiva',\n",
    "        'ministerio publico',\n",
    "        'ministério público',\n",
    "        'sindicato'\n",
    "    ]\n",
    "    \n",
    "    for padrao in padroes_coletiva:\n",
    "        # Remove acentos do padrão também para comparação\n",
    "        padrao_norm = normalizar_texto(padrao)\n",
    "        if padrao_norm in texto_norm:\n",
    "            return \"coletiva\"\n",
    "    \n",
    "    # Padrões para mandado de segurança\n",
    "    padroes_ms = [\n",
    "        'mandado de seguranca',\n",
    "        'mandado de segurança',\n",
    "        r'\\bm\\.s\\.\\b',\n",
    "        r'\\bms\\b'\n",
    "    ]\n",
    "    \n",
    "    for padrao in padroes_ms:\n",
    "        padrao_norm = normalizar_texto(padrao)\n",
    "        # Para siglas, verificar com word boundaries\n",
    "        if padrao_norm in [r'\\bm.s.\\b', r'\\bms\\b']:\n",
    "            import re\n",
    "            if re.search(padrao_norm.replace('\\\\b', r'\\b'), texto_norm):\n",
    "                return \"ms\"\n",
    "        elif padrao_norm in texto_norm:\n",
    "            return \"ms\"\n",
    "    \n",
    "    # Padrões para ações constitucionais\n",
    "    padroes_const = [\n",
    "        'habeas data',\n",
    "        'acao popular',\n",
    "        'ação popular',\n",
    "        r'\\badi\\b',\n",
    "        r'\\badin\\b',\n",
    "        r'\\badpf\\b',\n",
    "        'inconstitucionalidade'\n",
    "    ]\n",
    "    \n",
    "    for padrao in padroes_const:\n",
    "        padrao_norm = normalizar_texto(padrao)\n",
    "        if padrao_norm in [r'\\badi\\b', r'\\badin\\b', r'\\badpf\\b']:\n",
    "            import re\n",
    "            if re.search(padrao_norm.replace('\\\\b', r'\\b'), texto_norm):\n",
    "                return \"constitucional\"\n",
    "        elif padrao_norm in texto_norm:\n",
    "            return \"constitucional\"\n",
    "    \n",
    "    return None\n",
    "\n",
    "print(\"✓ Função classificar_override() criada\")\n",
    "print(\"  Retorna: 'coletiva', 'ms', 'constitucional' ou None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec9b853",
   "metadata": {},
   "source": [
    "### 11.4.3 Aplicar Regras de Override ao Dataset\n",
    "\n",
    "Aplica `classificar_override()` ao dataset expandido e cria colunas:\n",
    "- `override`: tipo de override detectado (ou None)\n",
    "- `is_estrategico`: 1 se override não for None, 0 caso contrário\n",
    "- `decision_source`: fonte da decisão (\"override:<tipo>\" ou \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c074ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trabalhar com df_expandido (ou criar se não existir)\n",
    "if 'df_expandido' in locals() and df_expandido is not None and len(df_expandido) > 0:\n",
    "    df_override = df_expandido.copy()\n",
    "else:\n",
    "    print(\"⚠ df_expandido não encontrado. Usando df_resultados ou df original.\")\n",
    "    if 'df_resultados' in locals() and df_resultados is not None:\n",
    "        df_override = df_resultados.copy()\n",
    "    elif 'df' in locals() and df is not None:\n",
    "        df_override = df.copy()\n",
    "    else:\n",
    "        print(\"✗ ERRO: Nenhum DataFrame disponível. Execute células anteriores.\")\n",
    "        df_override = None\n",
    "\n",
    "if df_override is not None:\n",
    "    print(f\"Dataset base: {len(df_override)} linhas\")\n",
    "    \n",
    "    # Concatenar campos de texto para classificação\n",
    "    print(\"\\nConcatenando campos de texto...\")\n",
    "    \n",
    "    def get_texto_completo(row):\n",
    "        \"\"\"Concatena campos relevantes para análise de override.\"\"\"\n",
    "        campos = []\n",
    "        \n",
    "        for col in ['ds_Acao_Judicial', 'ds_fatos', 'ds_Pedidos', 'ds_Qualificacao']:\n",
    "            if col in row.index:\n",
    "                campos.append(safe_str(row[col]))\n",
    "        \n",
    "        return ' '.join(campos)\n",
    "    \n",
    "    df_override['texto_completo'] = df_override.apply(get_texto_completo, axis=1)\n",
    "    print(f\"  ✓ Coluna 'texto_completo' criada\")\n",
    "    \n",
    "    # Aplicar classificação de override\n",
    "    print(\"\\nAplicando regras de override...\")\n",
    "    df_override['override'] = df_override['texto_completo'].apply(classificar_override)\n",
    "    \n",
    "    # Criar colunas derivadas\n",
    "    df_override['is_estrategico'] = df_override['override'].notna().astype(int)\n",
    "    df_override['decision_source'] = df_override['override'].apply(\n",
    "        lambda x: f\"override:{x}\" if pd.notna(x) else \"\"\n",
    "    )\n",
    "    \n",
    "    print(\"  ✓ Colunas criadas: override, is_estrategico, decision_source\")\n",
    "    \n",
    "    # Estatísticas de override\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ESTATÍSTICAS DE OVERRIDE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    total = len(df_override)\n",
    "    com_override = df_override['override'].notna().sum()\n",
    "    pct_override = (com_override / total * 100) if total > 0 else 0\n",
    "    \n",
    "    print(f\"\\nTotal de casos: {total}\")\n",
    "    print(f\"Casos com override: {com_override} ({pct_override:.1f}%)\")\n",
    "    print(f\"Casos sem override: {total - com_override} ({100-pct_override:.1f}%)\")\n",
    "    \n",
    "    if com_override > 0:\n",
    "        print(\"\\n**Distribuição por tipo de override:**\")\n",
    "        override_counts = df_override['override'].value_counts()\n",
    "        for tipo, count in override_counts.items():\n",
    "            pct = (count / total * 100)\n",
    "            print(f\"  - {tipo:15s}: {count:4d} ({pct:5.1f}%)\")\n",
    "    else:\n",
    "        print(\"\\n  Nenhum caso com override detectado.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "else:\n",
    "    print(\"✗ Não foi possível criar df_override\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4047cf8",
   "metadata": {},
   "source": [
    "### 11.4.4 Feature Store para Modelo Logístico\n",
    "\n",
    "Prepara features para casos **SEM override** (que precisam de modelo para classificação).\n",
    "\n",
    "**Features numéricas:**\n",
    "- `log_valor_moral`: log1p(valor_moral)\n",
    "- `log_valor_material`: log1p(valor_material)\n",
    "- `qtd_casos_advogado`: quantidade de casos do mesmo advogado (se disponível)\n",
    "- `dias_contrato_ajuizamento`: dias entre contrato e ajuizamento (se datas disponíveis)\n",
    "\n",
    "**Features categóricas:**\n",
    "- `tipo_convenio`: tipo de convênio (se existir, senão \"desconhecido\")\n",
    "- `tipo_vara`: JE/G1\n",
    "- `uf`: unidade federativa\n",
    "\n",
    "**Flags textuais (0/1):**\n",
    "- `flag_em_dobro`: pedido \"em dobro\"\n",
    "- `flag_nao_inferior`: pedido \"não inferior a\"\n",
    "- `flag_ate`: pedido \"até\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1060b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_override is not None:\n",
    "    print(\"=\"*80)\n",
    "    print(\"CRIANDO FEATURE STORE PARA MODELO LOGÍSTICO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Filtrar apenas casos SEM override (que precisam de modelo)\n",
    "    df_model = df_override[df_override['override'].isna()].copy()\n",
    "    \n",
    "    print(f\"\\nCasos sem override (para modelagem): {len(df_model)}\")\n",
    "    print(f\"Casos com override (já classificados): {(df_override['override'].notna()).sum()}\")\n",
    "    \n",
    "    if len(df_model) > 0:\n",
    "        print(\"\\n### FEATURES NUMÉRICAS ###\")\n",
    "        \n",
    "        # 1. log_valor_moral\n",
    "        if 'valor_moral' in df_model.columns:\n",
    "            df_model['log_valor_moral'] = np.log1p(df_model['valor_moral'].fillna(0))\n",
    "            print(f\"  ✓ log_valor_moral criado (min={df_model['log_valor_moral'].min():.2f}, max={df_model['log_valor_moral'].max():.2f})\")\n",
    "        else:\n",
    "            df_model['log_valor_moral'] = 0.0\n",
    "            print(\"  ⚠ valor_moral não disponível -> log_valor_moral = 0.0\")\n",
    "        \n",
    "        # 2. log_valor_material\n",
    "        if 'valor_material' in df_model.columns:\n",
    "            df_model['log_valor_material'] = np.log1p(df_model['valor_material'].fillna(0))\n",
    "            print(f\"  ✓ log_valor_material criado (min={df_model['log_valor_material'].min():.2f}, max={df_model['log_valor_material'].max():.2f})\")\n",
    "        else:\n",
    "            df_model['log_valor_material'] = 0.0\n",
    "            print(\"  ⚠ valor_material não disponível -> log_valor_material = 0.0\")\n",
    "        \n",
    "        # 3. qtd_casos_advogado\n",
    "        if 'nm_advogado' in df_model.columns or 'advogado' in df_model.columns:\n",
    "            adv_col = 'nm_advogado' if 'nm_advogado' in df_model.columns else 'advogado'\n",
    "            df_model['qtd_casos_advogado'] = df_model.groupby(adv_col)[adv_col].transform('count')\n",
    "            print(f\"  ✓ qtd_casos_advogado criado (min={df_model['qtd_casos_advogado'].min()}, max={df_model['qtd_casos_advogado'].max()})\")\n",
    "        else:\n",
    "            df_model['qtd_casos_advogado'] = 0\n",
    "            print(\"  ⚠ Campo advogado não disponível -> qtd_casos_advogado = 0\")\n",
    "        \n",
    "        # 4. dias_contrato_ajuizamento\n",
    "        if 'dt_contrato' in df_model.columns and 'dt_distribuicao' in df_model.columns:\n",
    "            try:\n",
    "                dt_contrato = pd.to_datetime(df_model['dt_contrato'], errors='coerce')\n",
    "                dt_ajuiz = pd.to_datetime(df_model['dt_distribuicao'], errors='coerce')\n",
    "                df_model['dias_contrato_ajuizamento'] = (dt_ajuiz - dt_contrato).dt.days\n",
    "                df_model['dias_contrato_ajuizamento'] = df_model['dias_contrato_ajuizamento'].fillna(0).clip(lower=0)\n",
    "                print(f\"  ✓ dias_contrato_ajuizamento criado (min={df_model['dias_contrato_ajuizamento'].min():.0f}, max={df_model['dias_contrato_ajuizamento'].max():.0f})\")\n",
    "            except:\n",
    "                df_model['dias_contrato_ajuizamento'] = 0\n",
    "                print(\"  ⚠ Erro ao calcular dias_contrato_ajuizamento -> = 0\")\n",
    "        else:\n",
    "            df_model['dias_contrato_ajuizamento'] = 0\n",
    "            print(\"  ⚠ Datas não disponíveis -> dias_contrato_ajuizamento = 0\")\n",
    "        \n",
    "        print(\"\\n### FEATURES CATEGÓRICAS ###\")\n",
    "        \n",
    "        # 5. tipo_convenio\n",
    "        if 'tipo_convenio' in df_model.columns:\n",
    "            df_model['tipo_convenio'] = df_model['tipo_convenio'].fillna('desconhecido')\n",
    "            print(f\"  ✓ tipo_convenio disponível ({df_model['tipo_convenio'].nunique()} valores únicos)\")\n",
    "        else:\n",
    "            df_model['tipo_convenio'] = 'desconhecido'\n",
    "            print(\"  ⚠ tipo_convenio não disponível -> 'desconhecido'\")\n",
    "        \n",
    "        # 6. tipo_vara (já existe)\n",
    "        if 'tipo_vara' in df_model.columns:\n",
    "            print(f\"  ✓ tipo_vara disponível ({df_model['tipo_vara'].value_counts().to_dict()})\")\n",
    "        else:\n",
    "            df_model['tipo_vara'] = 'desconhecido'\n",
    "            print(\"  ⚠ tipo_vara não disponível -> 'desconhecido'\")\n",
    "        \n",
    "        # 7. uf (já existe)\n",
    "        if 'uf' in df_model.columns:\n",
    "            print(f\"  ✓ uf disponível ({df_model['uf'].nunique()} UFs)\")\n",
    "        else:\n",
    "            df_model['uf'] = 'XX'\n",
    "            print(\"  ⚠ uf não disponível -> 'XX'\")\n",
    "        \n",
    "        print(\"\\n### FLAGS TEXTUAIS (0/1) ###\")\n",
    "        \n",
    "        # 8. Reaproveitar flags existentes ou criar\n",
    "        if 'has_em_dobro' in df_model.columns:\n",
    "            df_model['flag_em_dobro'] = df_model['has_em_dobro']\n",
    "            print(f\"  ✓ flag_em_dobro criado (reutilizado has_em_dobro)\")\n",
    "        else:\n",
    "            # Criar flag procurando \"em dobro\" no texto\n",
    "            df_model['flag_em_dobro'] = df_model['texto_completo'].str.contains(\n",
    "                'em dobro', case=False, na=False\n",
    "            ).astype(int)\n",
    "            print(f\"  ✓ flag_em_dobro criado por busca textual\")\n",
    "        \n",
    "        if 'has_minimo' in df_model.columns:\n",
    "            df_model['flag_nao_inferior'] = df_model['has_minimo']\n",
    "            print(f\"  ✓ flag_nao_inferior criado (reutilizado has_minimo)\")\n",
    "        else:\n",
    "            df_model['flag_nao_inferior'] = df_model['texto_completo'].str.contains(\n",
    "                'não inferior|nao inferior', case=False, na=False, regex=True\n",
    "            ).astype(int)\n",
    "            print(f\"  ✓ flag_nao_inferior criado por busca textual\")\n",
    "        \n",
    "        if 'has_ate' in df_model.columns:\n",
    "            df_model['flag_ate'] = df_model['has_ate']\n",
    "            print(f\"  ✓ flag_ate criado (reutilizado has_ate)\")\n",
    "        else:\n",
    "            df_model['flag_ate'] = df_model['texto_completo'].str.contains(\n",
    "                r'\\baté\\b|\\bate\\b', case=False, na=False, regex=True\n",
    "            ).astype(int)\n",
    "            print(f\"  ✓ flag_ate criado por busca textual\")\n",
    "        \n",
    "        # Contagem de flags\n",
    "        print(f\"\\n  Casos com flag_em_dobro: {df_model['flag_em_dobro'].sum()}\")\n",
    "        print(f\"  Casos com flag_nao_inferior: {df_model['flag_nao_inferior'].sum()}\")\n",
    "        print(f\"  Casos com flag_ate: {df_model['flag_ate'].sum()}\")\n",
    "        \n",
    "        # Criar target para modelagem\n",
    "        # Como não temos label real de \"estratégico\", vamos criar baseado em heurísticas\n",
    "        # (você pode ajustar depois com label real)\n",
    "        print(\"\\n### TARGET PARA MODELAGEM ###\")\n",
    "        print(\"  ℹ Como não há label real de 'estratégico' para casos sem override,\")\n",
    "        print(\"    o target 'is_estrategico_model' será 0 (não estratégico) para todos.\")\n",
    "        print(\"    Ajuste com labels reais quando disponíveis.\")\n",
    "        \n",
    "        df_model['is_estrategico_model'] = 0  # Todos são não-estratégicos (placeholder)\n",
    "        \n",
    "        # Resumo do dataset de treino\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"RESUMO DO DATASET DE TREINO (sem overrides)\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"\\nShape: {df_model.shape}\")\n",
    "        print(f\"\\nColunas de features criadas:\")\n",
    "        feature_cols = [\n",
    "            'log_valor_moral', 'log_valor_material', 'qtd_casos_advogado',\n",
    "            'dias_contrato_ajuizamento', 'tipo_convenio', 'tipo_vara', 'uf',\n",
    "            'flag_em_dobro', 'flag_nao_inferior', 'flag_ate'\n",
    "        ]\n",
    "        for col in feature_cols:\n",
    "            if col in df_model.columns:\n",
    "                print(f\"  ✓ {col}\")\n",
    "        \n",
    "        print(f\"\\nTarget: is_estrategico_model\")\n",
    "        print(f\"  Distribuição: {df_model['is_estrategico_model'].value_counts().to_dict()}\")\n",
    "        \n",
    "        # Amostra de dados\n",
    "        print(\"\\n### AMOSTRA DE FEATURES (5 primeiras linhas) ###\")\n",
    "        sample_cols = ['cd_atendimento'] if 'cd_atendimento' in df_model.columns else []\n",
    "        sample_cols += [c for c in feature_cols if c in df_model.columns][:8]  # Limitar colunas\n",
    "        print(df_model[sample_cols].head())\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n⚠ Nenhum caso sem override. Todos foram classificados por regras.\")\n",
    "        df_model = None\n",
    "\n",
    "else:\n",
    "    print(\"✗ df_override não disponível\")\n",
    "    df_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d4572a",
   "metadata": {},
   "source": [
    "### 11.4.5 Verificação Final da Camada de Override\n",
    "\n",
    "Resumo das variáveis criadas e próximos passos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a923e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"VERIFICAÇÃO FINAL - CAMADA DE OVERRIDE + FEATURE STORE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n### DATASETS CRIADOS ###\")\n",
    "\n",
    "if 'df_override' in locals() and df_override is not None:\n",
    "    print(f\"\\n1. df_override: {len(df_override)} linhas\")\n",
    "    print(\"   Colunas principais:\")\n",
    "    print(\"   - override: tipo de override ('coletiva', 'ms', 'constitucional' ou None)\")\n",
    "    print(\"   - is_estrategico: 1 se override != None, senão 0\")\n",
    "    print(\"   - decision_source: 'override:<tipo>' ou ''\")\n",
    "    print(\"   - texto_completo: concatenação dos campos textuais\")\n",
    "    \n",
    "    if 'df_model' in locals() and df_model is not None and len(df_model) > 0:\n",
    "        print(f\"\\n2. df_model: {len(df_model)} linhas (casos SEM override)\")\n",
    "        print(\"   Features numéricas:\")\n",
    "        print(\"   - log_valor_moral, log_valor_material\")\n",
    "        print(\"   - qtd_casos_advogado, dias_contrato_ajuizamento\")\n",
    "        print(\"   Features categóricas:\")\n",
    "        print(\"   - tipo_convenio, tipo_vara, uf\")\n",
    "        print(\"   Flags textuais:\")\n",
    "        print(\"   - flag_em_dobro, flag_nao_inferior, flag_ate\")\n",
    "        print(\"   Target:\")\n",
    "        print(\"   - is_estrategico_model (placeholder: 0 = não estratégico)\")\n",
    "    else:\n",
    "        print(\"\\n2. df_model: VAZIO (todos casos têm override)\")\n",
    "else:\n",
    "    print(\"\\n✗ df_override não foi criado\")\n",
    "\n",
    "print(\"\\n### ESTATÍSTICAS FINAIS ###\")\n",
    "\n",
    "if 'df_override' in locals() and df_override is not None:\n",
    "    total = len(df_override)\n",
    "    com_override = df_override['override'].notna().sum()\n",
    "    sem_override = total - com_override\n",
    "    \n",
    "    print(f\"\\nTotal de casos analisados: {total}\")\n",
    "    print(f\"  - Com override (estratégicos): {com_override} ({com_override/total*100:.1f}%)\")\n",
    "    print(f\"  - Sem override (para modelo): {sem_override} ({sem_override/total*100:.1f}%)\")\n",
    "    \n",
    "    if com_override > 0:\n",
    "        print(\"\\n**Distribuição de overrides:**\")\n",
    "        for tipo, count in df_override['override'].value_counts().items():\n",
    "            pct = count / total * 100\n",
    "            print(f\"  {tipo:15s}: {count:5d} ({pct:5.1f}%)\")\n",
    "\n",
    "print(\"\\n### PRÓXIMOS PASSOS ###\")\n",
    "print(\"1. Treinar modelo logístico com df_model (quando houver labels reais)\")\n",
    "print(\"2. Para casos com override: usar diretamente is_estrategico = 1\")\n",
    "print(\"3. Para casos sem override: usar modelo para prever is_estrategico_model\")\n",
    "print(\"4. Consolidar predições: override tem prioridade sobre modelo\")\n",
    "\n",
    "print(\"\\n### IMPORTANTE ###\")\n",
    "print(\"⚠ ESTAS COLUNAS NÃO ENTRAM NO output.xlsx\")\n",
    "print(\"  output.xlsx continua com apenas 7 colunas originais:\")\n",
    "print(\"  cd_atendimento, nome_empresa, cnpj, valor_causa, dt_distribuicao, tipo_vara, uf\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CAMADA DE OVERRIDE + FEATURE STORE CONCLUÍDA\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0203777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar DataFrame base para relatório\n",
    "# Usar df_classif se disponível, senão resultado_expandido, senão df_clean\n",
    "\n",
    "try:\n",
    "    df_relatorio = df_classif.copy()\n",
    "    print(f\"Usando df_classif para relatório: {len(df_relatorio)} casos\")\n",
    "except NameError:\n",
    "    try:\n",
    "        df_relatorio = resultado_expandido.copy()\n",
    "        print(f\"Usando resultado_expandido para relatório: {len(df_relatorio)} casos\")\n",
    "    except NameError:\n",
    "        try:\n",
    "            df_relatorio = df_clean.copy()\n",
    "            print(f\"Usando df_clean para relatório: {len(df_relatorio)} casos\")\n",
    "        except NameError:\n",
    "            print(\"ERRO: Nenhum dataset disponível. Execute seções anteriores.\")\n",
    "            df_relatorio = pd.DataFrame()\n",
    "\n",
    "if len(df_relatorio) == 0:\n",
    "    print(\"AVISO: Dataset vazio - relatório não será gerado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2494dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_relatorio) > 0:\n",
    "    print(\"=\"*80)\n",
    "    print(\"GERANDO RELATÓRIO CONSOLIDADO: relatorio.xlsx\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    with pd.ExcelWriter(\"relatorio.xlsx\", engine=\"openpyxl\") as xw:\n",
    "        \n",
    "        # ========== ABA 1: RESUMO ==========\n",
    "        print(\"\\n[1/5] Gerando aba 'Resumo'...\")\n",
    "        \n",
    "        total_casos = len(df_relatorio)\n",
    "        \n",
    "        # % consignado (se input já filtrado, reportar 100%)\n",
    "        if 'pred_consignado_rule' in df_relatorio.columns:\n",
    "            pct_consignado = (df_relatorio['pred_consignado_rule'].sum() / total_casos * 100)\n",
    "        else:\n",
    "            pct_consignado = 100.0  # Dataset já filtrado na Entrega 5\n",
    "        \n",
    "        # Médias de valores > 0\n",
    "        if 'valor_material' in df_relatorio.columns:\n",
    "            media_material = df_relatorio.loc[df_relatorio['valor_material'] > 0, 'valor_material'].mean()\n",
    "            media_material = float(media_material) if not pd.isna(media_material) else 0.0\n",
    "        else:\n",
    "            media_material = 0.0\n",
    "        \n",
    "        if 'valor_moral' in df_relatorio.columns:\n",
    "            media_moral = df_relatorio.loc[df_relatorio['valor_moral'] > 0, 'valor_moral'].mean()\n",
    "            media_moral = float(media_moral) if not pd.isna(media_moral) else 0.0\n",
    "        else:\n",
    "            media_moral = 0.0\n",
    "        \n",
    "        # Contagens úteis\n",
    "        cnpj_vazio = int((df_relatorio.get('cnpj', pd.Series(['vazio']*total_casos)) == 'vazio').sum())\n",
    "        \n",
    "        if 'dt_distribuicao' in df_relatorio.columns:\n",
    "            datas_vazias = int((df_relatorio['dt_distribuicao'].astype(str) == '').sum())\n",
    "        else:\n",
    "            datas_vazias = 0\n",
    "        \n",
    "        # Contagem por tipo_vara\n",
    "        if 'tipo_vara' in df_relatorio.columns:\n",
    "            je_count = int((df_relatorio['tipo_vara'] == 'JE').sum())\n",
    "            g1_count = int((df_relatorio['tipo_vara'] == 'G1').sum())\n",
    "        else:\n",
    "            je_count = 0\n",
    "            g1_count = 0\n",
    "        \n",
    "        resumo = pd.DataFrame({\n",
    "            'Métrica': [\n",
    "                'Total de casos',\n",
    "                '% Consignado',\n",
    "                'Média Valor Material (R$)',\n",
    "                'Média Valor Moral (R$)',\n",
    "                'CNPJ vazio',\n",
    "                'Datas vazias',\n",
    "                'Tipo Vara: JE',\n",
    "                'Tipo Vara: G1'\n",
    "            ],\n",
    "            'Valor': [\n",
    "                total_casos,\n",
    "                f'{pct_consignado:.1f}%',\n",
    "                f'{media_material:,.2f}',\n",
    "                f'{media_moral:,.2f}',\n",
    "                cnpj_vazio,\n",
    "                datas_vazias,\n",
    "                je_count,\n",
    "                g1_count\n",
    "            ]\n",
    "        })\n",
    "        \n",
    "        if pct_consignado >= 99.0:\n",
    "            obs = pd.DataFrame({\n",
    "                'Observação': ['Input já filtrado para crédito consignado na Entrega 5']\n",
    "            })\n",
    "            resumo = pd.concat([resumo, obs], axis=1)\n",
    "        \n",
    "        resumo.to_excel(xw, sheet_name='Resumo', index=False)\n",
    "        print(\"  ✓ Aba 'Resumo' criada\")\n",
    "        \n",
    "        # ========== ABA 2: DESCRITIVO ==========\n",
    "        print(\"\\n[2/5] Gerando aba 'Descritivo'...\")\n",
    "        \n",
    "        if 'valor_moral' in df_relatorio.columns and 'valor_material' in df_relatorio.columns:\n",
    "            moral_pos = df_relatorio.loc[df_relatorio['valor_moral'] > 0, 'valor_moral']\n",
    "            material_pos = df_relatorio.loc[df_relatorio['valor_material'] > 0, 'valor_material']\n",
    "            \n",
    "            # Estatísticas completas com percentis extras\n",
    "            descritivo = pd.DataFrame({\n",
    "                'Danos Morais': moral_pos.describe(percentiles=[0.25, 0.50, 0.75, 0.90, 0.95]) if len(moral_pos) > 0 else pd.Series(),\n",
    "                'Danos Materiais': material_pos.describe(percentiles=[0.25, 0.50, 0.75, 0.90, 0.95]) if len(material_pos) > 0 else pd.Series()\n",
    "            })\n",
    "            \n",
    "            descritivo.to_excel(xw, sheet_name='Descritivo')\n",
    "            print(\"  ✓ Aba 'Descritivo' criada\")\n",
    "        else:\n",
    "            pd.DataFrame({'Nota': ['Valores morais/materiais não disponíveis']}).to_excel(xw, sheet_name='Descritivo', index=False)\n",
    "            print(\"  ⚠ Aba 'Descritivo' criada com nota (valores não disponíveis)\")\n",
    "        \n",
    "        # ========== ABA 3: INFERENCIAL ==========\n",
    "        print(\"\\n[3/5] Gerando aba 'Inferencial'...\")\n",
    "        \n",
    "        infer_rows = []\n",
    "        \n",
    "        # Coeficientes do modelo OLS moral\n",
    "        if 'mod_m' in globals() and mod_m is not None:\n",
    "            for coef_name, beta_val in mod_m.params.items():\n",
    "                infer_rows.append({\n",
    "                    'Modelo': 'OLS_moral',\n",
    "                    'Coeficiente': coef_name,\n",
    "                    'Beta': float(beta_val),\n",
    "                    'Erro_Padrão': float(mod_m.bse.get(coef_name, np.nan)),\n",
    "                    'p_valor': float(mod_m.pvalues.get(coef_name, np.nan))\n",
    "                })\n",
    "            \n",
    "            # Métricas do modelo moral\n",
    "            if 'metrics_m' in globals() and metrics_m is not None:\n",
    "                infer_rows.append({\n",
    "                    'Modelo': 'OLS_moral',\n",
    "                    'Coeficiente': '__MAE_log__',\n",
    "                    'Beta': float(metrics_m['MAE_log']),\n",
    "                    'Erro_Padrão': np.nan,\n",
    "                    'p_valor': np.nan\n",
    "                })\n",
    "                infer_rows.append({\n",
    "                    'Modelo': 'OLS_moral',\n",
    "                    'Coeficiente': '__R2_log__',\n",
    "                    'Beta': float(metrics_m['R2_log']),\n",
    "                    'Erro_Padrão': np.nan,\n",
    "                    'p_valor': np.nan\n",
    "                })\n",
    "        \n",
    "        # Coeficientes do modelo OLS material\n",
    "        if 'mod_t' in globals() and mod_t is not None:\n",
    "            for coef_name, beta_val in mod_t.params.items():\n",
    "                infer_rows.append({\n",
    "                    'Modelo': 'OLS_material',\n",
    "                    'Coeficiente': coef_name,\n",
    "                    'Beta': float(beta_val),\n",
    "                    'Erro_Padrão': float(mod_t.bse.get(coef_name, np.nan)),\n",
    "                    'p_valor': float(mod_t.pvalues.get(coef_name, np.nan))\n",
    "                })\n",
    "            \n",
    "            # Métricas do modelo material\n",
    "            if 'metrics_t' in globals() and metrics_t is not None:\n",
    "                infer_rows.append({\n",
    "                    'Modelo': 'OLS_material',\n",
    "                    'Coeficiente': '__MAE_log__',\n",
    "                    'Beta': float(metrics_t['MAE_log']),\n",
    "                    'Erro_Padrão': np.nan,\n",
    "                    'p_valor': np.nan\n",
    "                })\n",
    "                infer_rows.append({\n",
    "                    'Modelo': 'OLS_material',\n",
    "                    'Coeficiente': '__R2_log__',\n",
    "                    'Beta': float(metrics_t['R2_log']),\n",
    "                    'Erro_Padrão': np.nan,\n",
    "                    'p_valor': np.nan\n",
    "                })\n",
    "        \n",
    "        if len(infer_rows) > 0:\n",
    "            infer_df = pd.DataFrame(infer_rows)\n",
    "            infer_df.to_excel(xw, sheet_name='Inferencial', index=False)\n",
    "            print(\"  ✓ Aba 'Inferencial' criada\")\n",
    "        else:\n",
    "            pd.DataFrame({'Nota': ['Modelos OLS não disponíveis - execute Seção 11.2']}).to_excel(xw, sheet_name='Inferencial', index=False)\n",
    "            print(\"  ⚠ Aba 'Inferencial' criada com nota (modelos não disponíveis)\")\n",
    "        \n",
    "        # ========== ABA 4: CLASSIFICADORES ==========\n",
    "        print(\"\\n[4/5] Gerando aba 'Classificadores'...\")\n",
    "        \n",
    "        class_rows = []\n",
    "        \n",
    "        # Métricas do classificador ML (JE vs G1) - Holdout\n",
    "        if 'metrics_clf_je_holdout' in globals() and metrics_clf_je_holdout is not None:\n",
    "            class_rows.append({\n",
    "                'Tarefa': 'JE_vs_G1_LogReg',\n",
    "                'Métrica': 'Accuracy_Holdout',\n",
    "                'Valor': float(metrics_clf_je_holdout['acc_test'])\n",
    "            })\n",
    "            class_rows.append({\n",
    "                'Tarefa': 'JE_vs_G1_LogReg',\n",
    "                'Métrica': 'F1_Holdout',\n",
    "                'Valor': float(metrics_clf_je_holdout['f1_test'])\n",
    "            })\n",
    "        \n",
    "        # Métricas CV\n",
    "        if 'metrics_clf_je_cv' in globals() and metrics_clf_je_cv is not None:\n",
    "            class_rows.append({\n",
    "                'Tarefa': 'JE_vs_G1_LogReg',\n",
    "                'Métrica': 'Accuracy_CV_mean',\n",
    "                'Valor': float(metrics_clf_je_cv['acc_cv_mean'])\n",
    "            })\n",
    "            class_rows.append({\n",
    "                'Tarefa': 'JE_vs_G1_LogReg',\n",
    "                'Métrica': 'Accuracy_CV_std',\n",
    "                'Valor': float(metrics_clf_je_cv['acc_cv_std'])\n",
    "            })\n",
    "            class_rows.append({\n",
    "                'Tarefa': 'JE_vs_G1_LogReg',\n",
    "                'Métrica': 'F1_CV_mean',\n",
    "                'Valor': float(metrics_clf_je_cv['f1_cv_mean'])\n",
    "            })\n",
    "            class_rows.append({\n",
    "                'Tarefa': 'JE_vs_G1_LogReg',\n",
    "                'Métrica': 'F1_CV_std',\n",
    "                'Valor': float(metrics_clf_je_cv['f1_cv_std'])\n",
    "            })\n",
    "        \n",
    "        # Baseline de regra determinística\n",
    "        if 'tipo_vara' in df_relatorio.columns and 'pred_je_rule' in df_relatorio.columns:\n",
    "            from sklearn.metrics import accuracy_score, f1_score\n",
    "            y_true_vara = (df_relatorio['tipo_vara'] == 'JE').astype(int)\n",
    "            y_rule_vara = df_relatorio['pred_je_rule'].values\n",
    "            \n",
    "            class_rows.append({\n",
    "                'Tarefa': 'JE_vs_G1_Regra',\n",
    "                'Métrica': 'Accuracy',\n",
    "                'Valor': float(accuracy_score(y_true_vara, y_rule_vara))\n",
    "            })\n",
    "            class_rows.append({\n",
    "                'Tarefa': 'JE_vs_G1_Regra',\n",
    "                'Métrica': 'F1',\n",
    "                'Valor': float(f1_score(y_true_vara, y_rule_vara, zero_division=0))\n",
    "            })\n",
    "        \n",
    "        # Nota sobre classificador \"é consignado?\"\n",
    "        if len(class_rows) > 0:\n",
    "            class_df = pd.DataFrame(class_rows)\n",
    "        else:\n",
    "            class_df = pd.DataFrame()\n",
    "        \n",
    "        # Adicionar nota sobre consignado\n",
    "        nota_consig = pd.DataFrame({\n",
    "            'Tarefa': ['É_Consignado'],\n",
    "            'Métrica': ['Status'],\n",
    "            'Valor': ['Input já filtrado - sem variação']\n",
    "        })\n",
    "        \n",
    "        class_final = pd.concat([class_df, nota_consig], ignore_index=True) if len(class_df) > 0 else nota_consig\n",
    "        class_final.to_excel(xw, sheet_name='Classificadores', index=False)\n",
    "        print(\"  ✓ Aba 'Classificadores' criada\")\n",
    "        \n",
    "        # ========== ABA 5: PREVISÕES AUXILIARES ==========\n",
    "        print(\"\\n[5/5] Gerando aba 'Previsoes_Aux'...\")\n",
    "        \n",
    "        prev_cols = {}\n",
    "        \n",
    "        if 'cd_atendimento' in df_relatorio.columns:\n",
    "            prev_cols['cd_atendimento'] = df_relatorio['cd_atendimento'].astype(str)\n",
    "        else:\n",
    "            prev_cols['cd_atendimento'] = [f'caso_{i}' for i in range(len(df_relatorio))]\n",
    "        \n",
    "        if 'pred_je_rule' in df_relatorio.columns:\n",
    "            prev_cols['pred_je_rule'] = df_relatorio['pred_je_rule']\n",
    "        \n",
    "        if 'pred_je_ml' in df_relatorio.columns:\n",
    "            prev_cols['pred_je_ml'] = df_relatorio['pred_je_ml']\n",
    "        \n",
    "        if 'pred_je_final' in df_relatorio.columns:\n",
    "            prev_cols['pred_je_final'] = df_relatorio['pred_je_final']\n",
    "        \n",
    "        if 'valor_moral' in df_relatorio.columns:\n",
    "            prev_cols['valor_moral'] = df_relatorio['valor_moral']\n",
    "        \n",
    "        if 'valor_material' in df_relatorio.columns:\n",
    "            prev_cols['valor_material'] = df_relatorio['valor_material']\n",
    "        \n",
    "        prev_df = pd.DataFrame(prev_cols).head(100)\n",
    "        prev_df.to_excel(xw, sheet_name='Previsoes_Aux', index=False)\n",
    "        print(\"  ✓ Aba 'Previsoes_Aux' criada (100 linhas de amostra)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RELATÓRIO CONSOLIDADO GERADO COM SUCESSO\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "else:\n",
    "    print(\"Dataset vazio - relatório não gerado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dee46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificação final dos arquivos gerados\n",
    "import os\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VERIFICAÇÃO DOS ARQUIVOS DE SAÍDA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "arquivos = {\n",
    "    'output.xlsx': 'Saída principal (7 colunas - roteiro original)',\n",
    "    'output_expandido.xlsx': 'Saída expandida (13 colunas)',\n",
    "    'relatorio.xlsx': 'Relatório consolidado de análises (5 abas)'\n",
    "}\n",
    "\n",
    "for arquivo, descricao in arquivos.items():\n",
    "    if os.path.exists(arquivo):\n",
    "        tamanho_kb = os.path.getsize(arquivo) / 1024\n",
    "        print(f\"✓ {arquivo:25s} | {tamanho_kb:>8.1f} KB | {descricao}\")\n",
    "        \n",
    "        # Listar abas do Excel\n",
    "        if arquivo.endswith('.xlsx'):\n",
    "            try:\n",
    "                xls = pd.ExcelFile(arquivo)\n",
    "                abas = xls.sheet_names\n",
    "                print(f\"  └─ Abas: {', '.join(abas)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  └─ Erro ao ler abas: {e}\")\n",
    "    else:\n",
    "        print(f\"✗ {arquivo:25s} | NÃO ENCONTRADO\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0727cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CORREÇÃO: ENRIQUECENDO df_override COM DADOS EXPANDIDOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verificar se df_override existe\n",
    "if 'df_override' in locals() and df_override is not None:\n",
    "    print(f\"\\ndf_override atual: {len(df_override)} linhas\")\n",
    "    \n",
    "    # Verificar se df_expandido existe\n",
    "    if 'df_expandido' in locals() and df_expandido is not None:\n",
    "        print(f\"df_expandido disponível: {len(df_expandido)} linhas\")\n",
    "        \n",
    "        # Fazer merge por cd_atendimento para trazer valor_moral, valor_material, tipo_vara, uf\n",
    "        cols_to_merge = []\n",
    "        \n",
    "        if 'valor_moral' in df_expandido.columns and 'valor_moral' not in df_override.columns:\n",
    "            cols_to_merge.append('valor_moral')\n",
    "        \n",
    "        if 'valor_material' in df_expandido.columns and 'valor_material' not in df_override.columns:\n",
    "            cols_to_merge.append('valor_material')\n",
    "        \n",
    "        if 'tipo_vara' in df_expandido.columns and 'tipo_vara' not in df_override.columns:\n",
    "            cols_to_merge.append('tipo_vara')\n",
    "        \n",
    "        if 'uf' in df_expandido.columns and 'uf' not in df_override.columns:\n",
    "            cols_to_merge.append('uf')\n",
    "        \n",
    "        if len(cols_to_merge) > 0 and 'cd_atendimento' in df_override.columns and 'cd_atendimento' in df_expandido.columns:\n",
    "            print(f\"\\nFazendo merge para trazer: {cols_to_merge}\")\n",
    "            \n",
    "            df_override = df_override.merge(\n",
    "                df_expandido[['cd_atendimento'] + cols_to_merge],\n",
    "                on='cd_atendimento',\n",
    "                how='left',\n",
    "                suffixes=('', '_exp')\n",
    "            )\n",
    "            \n",
    "            print(\"  Merge concluído\")\n",
    "        else:\n",
    "            print(\"\\n[AVISO] cd_atendimento não disponível ou colunas já existem\")\n",
    "    \n",
    "    elif 'df_resultados' in locals() and df_resultados is not None:\n",
    "        print(f\"df_resultados disponível: {len(df_resultados)} linhas\")\n",
    "        \n",
    "        # Tentar merge com df_resultados\n",
    "        cols_to_merge = []\n",
    "        \n",
    "        if 'valor_moral' in df_resultados.columns and 'valor_moral' not in df_override.columns:\n",
    "            cols_to_merge.append('valor_moral')\n",
    "        \n",
    "        if 'valor_material' in df_resultados.columns and 'valor_material' not in df_override.columns:\n",
    "            cols_to_merge.append('valor_material')\n",
    "        \n",
    "        if 'tipo_vara' in df_resultados.columns and 'tipo_vara' not in df_override.columns:\n",
    "            cols_to_merge.append('tipo_vara')\n",
    "        \n",
    "        if 'uf' in df_resultados.columns and 'uf' not in df_override.columns:\n",
    "            cols_to_merge.append('uf')\n",
    "        \n",
    "        if len(cols_to_merge) > 0 and 'cd_atendimento' in df_override.columns and 'cd_atendimento' in df_resultados.columns:\n",
    "            print(f\"\\nFazendo merge para trazer: {cols_to_merge}\")\n",
    "            \n",
    "            df_override = df_override.merge(\n",
    "                df_resultados[['cd_atendimento'] + cols_to_merge],\n",
    "                on='cd_atendimento',\n",
    "                how='left',\n",
    "                suffixes=('', '_res')\n",
    "            )\n",
    "            \n",
    "            print(\"  Merge concluído\")\n",
    "    \n",
    "    # RECRIAR df_model com dados enriquecidos\n",
    "    print(\"\\n### RECRIANDO df_model COM DADOS ENRIQUECIDOS ###\")\n",
    "    \n",
    "    df_model = df_override[df_override['override'].isna()].copy()\n",
    "    print(f\"\\nCasos sem override: {len(df_model)}\")\n",
    "    \n",
    "    if len(df_model) > 0:\n",
    "        # Recriar features numéricas\n",
    "        print(\"\\n### RECRIANDO FEATURES NUMÉRICAS ###\")\n",
    "        \n",
    "        if 'valor_moral' in df_model.columns:\n",
    "            df_model['log_valor_moral'] = np.log1p(df_model['valor_moral'].fillna(0))\n",
    "            print(f\"  log_valor_moral: min={df_model['log_valor_moral'].min():.2f}, max={df_model['log_valor_moral'].max():.2f}\")\n",
    "        else:\n",
    "            df_model['log_valor_moral'] = 0.0\n",
    "            print(\"  [AVISO] valor_moral não disponível\")\n",
    "        \n",
    "        if 'valor_material' in df_model.columns:\n",
    "            df_model['log_valor_material'] = np.log1p(df_model['valor_material'].fillna(0))\n",
    "            print(f\"  log_valor_material: min={df_model['log_valor_material'].min():.2f}, max={df_model['log_valor_material'].max():.2f}\")\n",
    "        else:\n",
    "            df_model['log_valor_material'] = 0.0\n",
    "            print(\"  [AVISO] valor_material não disponível\")\n",
    "        \n",
    "        df_model['qtd_casos_advogado'] = 0\n",
    "        df_model['dias_contrato_ajuizamento'] = 0\n",
    "        \n",
    "        # Recriar features categóricas\n",
    "        print(\"\\n### RECRIANDO FEATURES CATEGÓRICAS ###\")\n",
    "        \n",
    "        if 'tipo_convenio' not in df_model.columns:\n",
    "            df_model['tipo_convenio'] = 'desconhecido'\n",
    "        \n",
    "        if 'tipo_vara' in df_model.columns:\n",
    "            print(f\"  tipo_vara: {df_model['tipo_vara'].value_counts().to_dict()}\")\n",
    "        else:\n",
    "            df_model['tipo_vara'] = 'desconhecido'\n",
    "        \n",
    "        if 'uf' in df_model.columns:\n",
    "            print(f\"  uf: {df_model['uf'].nunique()} valores únicos\")\n",
    "        else:\n",
    "            df_model['uf'] = 'XX'\n",
    "        \n",
    "        # Recriar flags\n",
    "        print(\"\\n### RECRIANDO FLAGS ###\")\n",
    "        \n",
    "        if 'texto_completo' in df_model.columns:\n",
    "            df_model['flag_em_dobro'] = df_model['texto_completo'].str.contains(\n",
    "                'em dobro', case=False, na=False\n",
    "            ).astype(int)\n",
    "            \n",
    "            df_model['flag_nao_inferior'] = df_model['texto_completo'].str.contains(\n",
    "                'não inferior|nao inferior', case=False, na=False, regex=True\n",
    "            ).astype(int)\n",
    "            \n",
    "            df_model['flag_ate'] = df_model['texto_completo'].str.contains(\n",
    "                r'\\baté\\b|\\bate\\b', case=False, na=False, regex=True\n",
    "            ).astype(int)\n",
    "            \n",
    "            print(f\"  flag_em_dobro: {df_model['flag_em_dobro'].sum()} casos\")\n",
    "            print(f\"  flag_nao_inferior: {df_model['flag_nao_inferior'].sum()} casos\")\n",
    "            print(f\"  flag_ate: {df_model['flag_ate'].sum()} casos\")\n",
    "        \n",
    "        # Criar target mais realista baseado em heurísticas\n",
    "        print(\"\\n### CRIANDO TARGET HEURÍSTICO ###\")\n",
    "        print(\"  Usando heurística: casos com valores altos são 'estratégicos'\")\n",
    "        \n",
    "        # Heurística: estratégico se valor_moral > 20k OU valor_material > 50k\n",
    "        threshold_moral = 20000\n",
    "        threshold_material = 50000\n",
    "        \n",
    "        if 'valor_moral' in df_model.columns and 'valor_material' in df_model.columns:\n",
    "            df_model['is_estrategico_model'] = (\n",
    "                (df_model['valor_moral'] > threshold_moral) |\n",
    "                (df_model['valor_material'] > threshold_material)\n",
    "            ).astype(int)\n",
    "            \n",
    "            n_estrategico = df_model['is_estrategico_model'].sum()\n",
    "            pct_estrategico = n_estrategico / len(df_model) * 100 if len(df_model) > 0 else 0\n",
    "            \n",
    "            print(f\"  Estratégicos: {n_estrategico} ({pct_estrategico:.1f}%)\")\n",
    "            print(f\"  Não-estratégicos: {len(df_model) - n_estrategico} ({100-pct_estrategico:.1f}%)\")\n",
    "            print(f\"  Thresholds: moral > R${threshold_moral:,} OU material > R${threshold_material:,}\")\n",
    "        else:\n",
    "            # Fallback: usar flags como proxy\n",
    "            df_model['is_estrategico_model'] = (\n",
    "                (df_model.get('flag_em_dobro', 0) == 1) |\n",
    "                (df_model.get('flag_nao_inferior', 0) == 1)\n",
    "            ).astype(int)\n",
    "            \n",
    "            n_estrategico = df_model['is_estrategico_model'].sum()\n",
    "            print(f\"  [FALLBACK] Usando flags: {n_estrategico} estratégicos\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"df_model CORRIGIDO E PRONTO PARA TREINAMENTO\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"\\nShape: {df_model.shape}\")\n",
    "        print(f\"Features numéricas: log_valor_moral, log_valor_material\")\n",
    "        print(f\"Features categóricas: tipo_vara, uf, flags\")\n",
    "        print(f\"Target: is_estrategico_model com {df_model['is_estrategico_model'].nunique()} classes\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n[ERRO] df_override não disponível. Execute seção 11.4 primeiro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2132c259",
   "metadata": {},
   "source": [
    "## 11.5 Modelo Inferencial (Logístico) — Estratégico vs Massa\n",
    "\n",
    "Treina um LogisticRegression com L1 (solver liblinear) apenas em casos sem override.\n",
    "\n",
    "Pipeline com:\n",
    "- StandardScaler para features numéricas\n",
    "- OneHotEncoder para features categóricas\n",
    "- LogisticRegression(penalty=\"l1\", solver=\"liblinear\", max_iter=200)\n",
    "\n",
    "Saídas:\n",
    "- modelo_logistico.pkl (pipeline treinado)\n",
    "- coeficientes.csv (features + coeficientes + abs(coef))\n",
    "- output_scores.csv (predições no test set)\n",
    "- logit_top_features.png (top 20 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95891651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TREINAMENTO: MODELO LOGÍSTICO (L1) — ESTRATÉGICO VS MASSA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verificar disponibilidade de df_model\n",
    "if 'df_model' not in locals() or df_model is None or len(df_model) == 0:\n",
    "    print(\"\\n[AVISO] df_model não está disponível ou está vazio.\")\n",
    "    print(\"  Verifique se a seção 11.4 foi executada corretamente.\")\n",
    "    print(\"  Pulando treinamento do modelo logístico.\")\n",
    "else:\n",
    "    print(f\"\\nDataset de treino (casos sem override): {len(df_model)} linhas\")\n",
    "    \n",
    "    # ========== PREPARAÇÃO DE FEATURES E TARGET ==========\n",
    "    print(\"\\n### PREPARAÇÃO DE FEATURES E TARGET ###\")\n",
    "    \n",
    "    # Features numéricas\n",
    "    numeric_features = [\n",
    "        'log_valor_moral',\n",
    "        'log_valor_material',\n",
    "        'qtd_casos_advogado',\n",
    "        'dias_contrato_ajuizamento'\n",
    "    ]\n",
    "    \n",
    "    # Features categóricas\n",
    "    categorical_features = [\n",
    "        'tipo_convenio',\n",
    "        'tipo_vara',\n",
    "        'uf',\n",
    "        'flag_em_dobro',\n",
    "        'flag_nao_inferior',\n",
    "        'flag_ate'\n",
    "    ]\n",
    "    \n",
    "    # Verificar quais features existem\n",
    "    numeric_features = [f for f in numeric_features if f in df_model.columns]\n",
    "    categorical_features = [f for f in categorical_features if f in df_model.columns]\n",
    "    \n",
    "    print(f\"\\nFeatures numéricas encontradas ({len(numeric_features)}):\")\n",
    "    for f in numeric_features:\n",
    "        print(f\"  - {f}: min={df_model[f].min():.2f}, max={df_model[f].max():.2f}\")\n",
    "    \n",
    "    print(f\"\\nFeatures categóricas encontradas ({len(categorical_features)}):\")\n",
    "    for f in categorical_features:\n",
    "        n_unique = df_model[f].nunique()\n",
    "        print(f\"  - {f}: {n_unique} valores únicos\")\n",
    "    \n",
    "    # Preparar X e y\n",
    "    features_all = numeric_features + categorical_features\n",
    "    \n",
    "    if len(features_all) == 0:\n",
    "        print(\"\\n[ERRO] Nenhuma feature disponível. Pulando modelo.\")\n",
    "    else:\n",
    "        X = df_model[features_all].copy()\n",
    "        y = df_model['is_estrategico_model'].copy()\n",
    "        \n",
    "        # Verificar se há pelo menos 2 classes\n",
    "        n_classes = y.nunique()\n",
    "        if n_classes < 2:\n",
    "            print(f\"\\n[AVISO] Target tem apenas {n_classes} classe(s) (esperado: 2).\")\n",
    "            print(\"  Pulando treinamento do modelo logístico.\")\n",
    "        else:\n",
    "            print(f\"\\nTarget distribution:\")\n",
    "            print(y.value_counts().to_string())\n",
    "            \n",
    "            # ========== SPLIT 70/30 ESTRATIFICADO ==========\n",
    "            print(\"\\n### SPLIT 70/30 (TRAIN/TEST) ###\")\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y,\n",
    "                test_size=0.3,\n",
    "                random_state=42,\n",
    "                stratify=y\n",
    "            )\n",
    "            \n",
    "            print(f\"  Train: {len(X_train)} linhas\")\n",
    "            print(f\"  Test:  {len(X_test)} linhas\")\n",
    "            print(f\"  Train class dist: {y_train.value_counts().to_dict()}\")\n",
    "            print(f\"  Test class dist:  {y_test.value_counts().to_dict()}\")\n",
    "            \n",
    "            # ========== PREPROCESSOR (SCALERS + ENCODERS) ==========\n",
    "            print(\"\\n### PRÉ-PROCESSADOR (SCALERS + ENCODERS) ###\")\n",
    "            \n",
    "            preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('num', StandardScaler(), numeric_features),\n",
    "                    ('cat', OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False), categorical_features)\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            print(f\"  Numéricas: StandardScaler ({len(numeric_features)} features)\")\n",
    "            print(f\"  Categóricas: OneHotEncoder ({len(categorical_features)} features)\")\n",
    "            \n",
    "            # ========== PIPELINE ==========\n",
    "            print(\"\\n### PIPELINE ###\")\n",
    "            \n",
    "            pipeline = Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('clf', LogisticRegression(\n",
    "                    penalty='l1',\n",
    "                    solver='liblinear',\n",
    "                    max_iter=200,\n",
    "                    random_state=42,\n",
    "                    class_weight='balanced'\n",
    "                ))\n",
    "            ])\n",
    "            \n",
    "            print(\"  Pipeline: preprocessor -> LogisticRegression(L1)\")\n",
    "            \n",
    "            # ========== TREINAMENTO ==========\n",
    "            print(\"\\n### TREINAMENTO ###\")\n",
    "            \n",
    "            pipeline.fit(X_train, y_train)\n",
    "            \n",
    "            print(\"  Modelo treinado com sucesso\")\n",
    "            \n",
    "            # ========== PREDIÇÕES HOLDOUT (70/30) ==========\n",
    "            print(\"\\n### AVALIAÇÃO NO TEST SET (30%) ###\")\n",
    "            \n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            # Métricas\n",
    "            roc_auc = roc_auc_score(y_test, y_proba)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "            rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "            f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "            \n",
    "            print(f\"\\n  ROC AUC:   {roc_auc:.4f}\")\n",
    "            print(f\"  Accuracy:  {acc:.4f}\")\n",
    "            print(f\"  Precision: {prec:.4f}\")\n",
    "            print(f\"  Recall:    {rec:.4f}\")\n",
    "            print(f\"  F1-Score:  {f1:.4f}\")\n",
    "            \n",
    "            # Confusion matrix\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            print(f\"\\n  Confusion Matrix:\")\n",
    "            print(f\"    TN={cm[0,0]}, FP={cm[0,1]}\")\n",
    "            print(f\"    FN={cm[1,0]}, TP={cm[1,1]}\")\n",
    "            \n",
    "            # Classification report\n",
    "            print(f\"\\n  Classification Report:\")\n",
    "            print(classification_report(y_test, y_pred, zero_division=0))\n",
    "            \n",
    "            # ========== CROSS-VALIDATION (5-FOLD STRATIFIED) ==========\n",
    "            print(\"\\n### CROSS-VALIDATION (5-FOLD STRATIFICADO) ###\")\n",
    "            \n",
    "            cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "            scoring = {'roc_auc': 'roc_auc', 'f1': 'f1'}\n",
    "            \n",
    "            cv_results = cross_validate(pipeline, X, y, cv=cv, scoring=scoring)\n",
    "            \n",
    "            roc_auc_cv_mean = cv_results['test_roc_auc'].mean()\n",
    "            roc_auc_cv_std = cv_results['test_roc_auc'].std()\n",
    "            f1_cv_mean = cv_results['test_f1'].mean()\n",
    "            f1_cv_std = cv_results['test_f1'].std()\n",
    "            \n",
    "            print(f\"\\n  ROC AUC (5-fold): {roc_auc_cv_mean:.4f} +/- {roc_auc_cv_std:.4f}\")\n",
    "            print(f\"  F1-Score (5-fold): {f1_cv_mean:.4f} +/- {f1_cv_std:.4f}\")\n",
    "            \n",
    "            # ========== COEFICIENTES ==========\n",
    "            print(\"\\n### COEFICIENTES E FEATURE IMPORTANCE ###\")\n",
    "            \n",
    "            # Extrair nomes de features pós-transformação\n",
    "            feature_names = []\n",
    "            \n",
    "            # Numéricas (escaladas, mantêm nomes)\n",
    "            feature_names.extend(numeric_features)\n",
    "            \n",
    "            # Categóricas (OneHotEncoded)\n",
    "            try:\n",
    "                encoder = pipeline.named_steps['preprocessor'].named_transformers_['cat']\n",
    "                cat_feature_names = encoder.get_feature_names_out(categorical_features)\n",
    "                feature_names.extend(cat_feature_names)\n",
    "            except:\n",
    "                print(\"  [Aviso] Não foi possível extrair nomes das features categóricas\")\n",
    "                feature_names.extend([f\"cat_{i}\" for i in range(len(categorical_features))])\n",
    "            \n",
    "            # Coeficientes\n",
    "            coef = pipeline.named_steps['clf'].coef_[0]\n",
    "            \n",
    "            # Criar DataFrame de coeficientes\n",
    "            coef_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'coef': coef,\n",
    "                'abs_coef': np.abs(coef)\n",
    "            }).sort_values('abs_coef', ascending=False)\n",
    "            \n",
    "            print(f\"\\n  Top 10 features por importância absoluta:\")\n",
    "            for idx, row in coef_df.head(10).iterrows():\n",
    "                print(f\"    {row['feature']:30s}: {row['coef']:+.4f} (|{row['abs_coef']:.4f}|)\")\n",
    "            \n",
    "            # Salvar coeficientes\n",
    "            coef_df.to_csv('coeficientes.csv', index=False)\n",
    "            print(f\"\\n  Arquivo salvo: coeficientes.csv\")\n",
    "            \n",
    "            # ========== GRÁFICO: TOP 20 FEATURES ==========\n",
    "            print(\"\\n### GRÁFICO: TOP 20 FEATURES ###\")\n",
    "            \n",
    "            top_20 = coef_df.head(20).sort_values('abs_coef', ascending=True)\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            ax.barh(range(len(top_20)), top_20['abs_coef'], color='steelblue')\n",
    "            ax.set_yticks(range(len(top_20)))\n",
    "            ax.set_yticklabels(top_20['feature'], fontsize=9)\n",
    "            ax.set_xlabel('|Coeficiente|', fontsize=11)\n",
    "            ax.set_title('Top 20 Features - Importância no Modelo Logístico (L1)', fontsize=12, fontweight='bold')\n",
    "            ax.grid(axis='x', alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('logit_top_features.png', dpi=100, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"  Arquivo salvo: logit_top_features.png\")\n",
    "            \n",
    "            # ========== SALVAR ARTIFACTS ==========\n",
    "            print(\"\\n### SALVANDO ARTIFACTS ###\")\n",
    "            \n",
    "            # Pipeline\n",
    "            joblib.dump(pipeline, 'modelo_logistico.pkl')\n",
    "            print(\"  Arquivo salvo: modelo_logistico.pkl\")\n",
    "            \n",
    "            # Output scores (test set)\n",
    "            output_scores = pd.DataFrame({\n",
    "                'cd_atendimento': X_test.index.map(lambda idx: df_model.loc[idx, 'cd_atendimento'] if 'cd_atendimento' in df_model.columns else idx),\n",
    "                'override': X_test.index.map(lambda idx: df_model.loc[idx, 'override'] if 'override' in df_model.columns else None),\n",
    "                'is_estrategico': y_test.values,\n",
    "                'estrategic_score': y_proba,\n",
    "                'is_estrategico_pred': y_pred,\n",
    "                'tipo_vara': X_test.index.map(lambda idx: df_model.loc[idx, 'tipo_vara'] if 'tipo_vara' in df_model.columns else 'N/A'),\n",
    "                'uf': X_test.index.map(lambda idx: df_model.loc[idx, 'uf'] if 'uf' in df_model.columns else 'N/A')\n",
    "            })\n",
    "            \n",
    "            output_scores.to_csv('output_scores.csv', index=False)\n",
    "            print(\"  Arquivo salvo: output_scores.csv\")\n",
    "            \n",
    "            # Salvar informações de treinamento\n",
    "            metrics_logit = {\n",
    "                'roc_auc_holdout': roc_auc,\n",
    "                'accuracy_holdout': acc,\n",
    "                'precision_holdout': prec,\n",
    "                'recall_holdout': rec,\n",
    "                'f1_holdout': f1,\n",
    "                'roc_auc_cv_mean': roc_auc_cv_mean,\n",
    "                'roc_auc_cv_std': roc_auc_cv_std,\n",
    "                'f1_cv_mean': f1_cv_mean,\n",
    "                'f1_cv_std': f1_cv_std,\n",
    "                'n_features': len(feature_names),\n",
    "                'n_train': len(X_train),\n",
    "                'n_test': len(X_test)\n",
    "            }\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"MODELO LOGÍSTICO TREINADO COM SUCESSO\")\n",
    "            print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78bb101",
   "metadata": {},
   "source": [
    "## 11.6 Scoring e Integração de Saídas\n",
    "\n",
    "Aplica decisão em cascata (override + modelo) em TODA a base e integra ao relatorio.xlsx.\n",
    "\n",
    "Decisão:\n",
    "- Se override != None: is_estrategico_final=1, estrategic_score=1.0, decision_source=\"override:<tipo>\"\n",
    "- Se sem override: usa modelo para calcular proba, score e classificação\n",
    "- Se modelo não treinado: score=0.0, is_estrategico_final=0\n",
    "\n",
    "Gráficos:\n",
    "- Histograma de estrategic_score (casos com modelo)\n",
    "- Barras por tipo de override\n",
    "- Barras de score médio por UF\n",
    "\n",
    "Outputs:\n",
    "- output_scores.csv (todos os casos)\n",
    "- relatorio.xlsx atualizado com aba \"Scores_Estrategicos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12ba142",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SCORING E INTEGRAÇÃO: OVERRIDE + MODELO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Garantir que df_override existe\n",
    "if 'df_override' not in locals() or df_override is None:\n",
    "    print(\"\\n[AVISO] df_override não disponível. Pulando scoring.\")\n",
    "else:\n",
    "    df_scoring = df_override.copy()\n",
    "    print(f\"\\nBase de scoring: {len(df_scoring)} casos\")\n",
    "    \n",
    "    # Inicializar colunas\n",
    "    df_scoring['is_estrategico_final'] = 0\n",
    "    df_scoring['estrategic_score'] = 0.0\n",
    "    df_scoring['decision_source'] = \"\"\n",
    "    \n",
    "    # ========== APLICAR OVERRIDE ==========\n",
    "    print(\"\\n### APLICAR OVERRIDE (CASCATA 1) ###\")\n",
    "    \n",
    "    mask_override = df_scoring['override'].notna()\n",
    "    n_override = mask_override.sum()\n",
    "    \n",
    "    print(f\"  Casos com override: {n_override}\")\n",
    "    \n",
    "    if n_override > 0:\n",
    "        df_scoring.loc[mask_override, 'is_estrategico_final'] = 1\n",
    "        df_scoring.loc[mask_override, 'estrategic_score'] = 1.0\n",
    "        df_scoring.loc[mask_override, 'decision_source'] = (\n",
    "            \"override:\" + df_scoring.loc[mask_override, 'override'].astype(str)\n",
    "        )\n",
    "        \n",
    "        print(f\"  Atualizado: is_estrategico_final=1, estrategic_score=1.0\")\n",
    "    \n",
    "    # ========== APLICAR MODELO (CASCATA 2) ==========\n",
    "    print(\"\\n### APLICAR MODELO (CASCATA 2) ###\")\n",
    "    \n",
    "    mask_sem_override = df_scoring['override'].isna()\n",
    "    n_sem_override = mask_sem_override.sum()\n",
    "    \n",
    "    print(f\"  Casos sem override: {n_sem_override}\")\n",
    "    \n",
    "    # Verificar se modelo foi treinado\n",
    "    modelo_existe = False\n",
    "    if 'pipeline' in locals() and pipeline is not None and 'metrics_logit' in locals():\n",
    "        try:\n",
    "            import os\n",
    "            if os.path.exists('modelo_logistico.pkl'):\n",
    "                modelo_existe = True\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if modelo_existe and n_sem_override > 0:\n",
    "        print(\"  Modelo logístico disponível. Aplicando predições...\")\n",
    "        \n",
    "        # Preparar features para casos sem override\n",
    "        features_all_model = numeric_features + categorical_features\n",
    "        \n",
    "        # Verificar quais features existem no df_scoring\n",
    "        features_disponíveis = [f for f in features_all_model if f in df_scoring.columns]\n",
    "        \n",
    "        if len(features_disponíveis) > 0:\n",
    "            X_scoring = df_scoring.loc[mask_sem_override, features_disponíveis].copy()\n",
    "            \n",
    "            # Preencher NaNs e valores faltantes\n",
    "            for col in numeric_features:\n",
    "                if col in X_scoring.columns:\n",
    "                    X_scoring[col] = X_scoring[col].fillna(0.0)\n",
    "            for col in categorical_features:\n",
    "                if col in X_scoring.columns:\n",
    "                    X_scoring[col] = X_scoring[col].fillna('desconhecido')\n",
    "            \n",
    "            try:\n",
    "                proba_scoring = pipeline.predict_proba(X_scoring)[:, 1]\n",
    "                pred_scoring = (proba_scoring >= 0.5).astype(int)\n",
    "                \n",
    "                df_scoring.loc[mask_sem_override, 'estrategic_score'] = proba_scoring\n",
    "                df_scoring.loc[mask_sem_override, 'is_estrategico_final'] = pred_scoring\n",
    "                df_scoring.loc[mask_sem_override, 'decision_source'] = \"model\"\n",
    "                \n",
    "                print(f\"  Predições aplicadas com sucesso\")\n",
    "                print(f\"    Media de score: {proba_scoring.mean():.4f}\")\n",
    "                print(f\"    Cases marcados como estratégicos: {pred_scoring.sum()}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  [ERRO] Ao aplicar modelo: {e}\")\n",
    "                print(f\"  Setando score=0.0 para casos sem override\")\n",
    "                df_scoring.loc[mask_sem_override, 'estrategic_score'] = 0.0\n",
    "        else:\n",
    "            print(f\"  [AVISO] Features necessárias não encontradas no dataset\")\n",
    "            print(f\"  Setando score=0.0 para casos sem override\")\n",
    "    else:\n",
    "        if not modelo_existe:\n",
    "            print(\"  [AVISO] Modelo logístico não foi treinado\")\n",
    "        if n_sem_override == 0:\n",
    "            print(\"  [INFO] Todos os casos têm override\")\n",
    "        print(f\"  Setando score=0.0 para casos sem override\")\n",
    "        df_scoring.loc[mask_sem_override, 'estrategic_score'] = 0.0\n",
    "    \n",
    "    # ========== ESTATÍSTICAS DE SCORING ==========\n",
    "    print(\"\\n### ESTATÍSTICAS DE SCORING ###\")\n",
    "    \n",
    "    print(f\"\\nDistribuição de decision_source:\")\n",
    "    ds_counts = df_scoring['decision_source'].value_counts()\n",
    "    for ds, count in ds_counts.items():\n",
    "        if ds:\n",
    "            pct = count / len(df_scoring) * 100\n",
    "            print(f\"  {ds:20s}: {count:5d} ({pct:5.1f}%)\")\n",
    "        else:\n",
    "            print(f\"  (vazio):             {count:5d} ({count/len(df_scoring)*100:5.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nEstatísticas de is_estrategico_final:\")\n",
    "    print(f\"  Estratégicos (1): {(df_scoring['is_estrategico_final']==1).sum()}\")\n",
    "    print(f\"  Não-estratégicos (0): {(df_scoring['is_estrategico_final']==0).sum()}\")\n",
    "    \n",
    "    print(f\"\\nEstatísticas de estrategic_score:\")\n",
    "    print(f\"  Media: {df_scoring['estrategic_score'].mean():.4f}\")\n",
    "    print(f\"  Mediana: {df_scoring['estrategic_score'].median():.4f}\")\n",
    "    print(f\"  Min: {df_scoring['estrategic_score'].min():.4f}\")\n",
    "    print(f\"  Max: {df_scoring['estrategic_score'].max():.4f}\")\n",
    "    \n",
    "    # ========== GRÁFICOS ==========\n",
    "    print(\"\\n### GRÁFICOS ###\")\n",
    "    \n",
    "    # Histograma de score (apenas modelo)\n",
    "    mask_model = df_scoring['decision_source'] == 'model'\n",
    "    if mask_model.sum() > 0:\n",
    "        scores_model = df_scoring.loc[mask_model, 'estrategic_score']\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.hist(scores_model, bins=20, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "        ax.set_xlabel('Estrategic Score', fontsize=11)\n",
    "        ax.set_ylabel('Frequência', fontsize=11)\n",
    "        ax.set_title('Distribuição de Estrategic Score (Casos com Modelo)', fontsize=12, fontweight='bold')\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('hist_estrategic_score.png', dpi=100, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(\"  Arquivo salvo: hist_estrategic_score.png\")\n",
    "    \n",
    "    # Barras de overrides por tipo\n",
    "    if n_override > 0:\n",
    "        override_counts = df_scoring[mask_override]['override'].value_counts()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.bar(range(len(override_counts)), override_counts.values, color='coral', edgecolor='black', alpha=0.7)\n",
    "        ax.set_xticks(range(len(override_counts)))\n",
    "        ax.set_xticklabels(override_counts.index, fontsize=10)\n",
    "        ax.set_ylabel('Contagem', fontsize=11)\n",
    "        ax.set_title('Distribuição de Overrides por Tipo', fontsize=12, fontweight='bold')\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        for i, v in enumerate(override_counts.values):\n",
    "            ax.text(i, v + 1, str(v), ha='center', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('bar_overrides.png', dpi=100, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(\"  Arquivo salvo: bar_overrides.png\")\n",
    "    \n",
    "    # Barras de score médio por UF\n",
    "    if 'uf' in df_scoring.columns:\n",
    "        uf_scores = df_scoring.groupby('uf')['estrategic_score'].mean().sort_values(ascending=False)\n",
    "        \n",
    "        if len(uf_scores) > 0:\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            ax.bar(range(len(uf_scores)), uf_scores.values, color='lightgreen', edgecolor='black', alpha=0.7)\n",
    "            ax.set_xticks(range(len(uf_scores)))\n",
    "            ax.set_xticklabels(uf_scores.index, fontsize=9)\n",
    "            ax.set_ylabel('Score Médio', fontsize=11)\n",
    "            ax.set_title('Score Estratégico Médio por UF', fontsize=12, fontweight='bold')\n",
    "            ax.grid(axis='y', alpha=0.3)\n",
    "            \n",
    "            for i, v in enumerate(uf_scores.values):\n",
    "                ax.text(i, v + 0.02, f'{v:.3f}', ha='center', fontsize=9)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('bar_score_por_uf.png', dpi=100, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            print(\"  Arquivo salvo: bar_score_por_uf.png\")\n",
    "    \n",
    "    # ========== EXPORT output_scores.csv (TODOS OS CASOS) ==========\n",
    "    print(\"\\n### EXPORT output_scores.csv ###\")\n",
    "    \n",
    "    output_scores_full = df_scoring[[\n",
    "        'cd_atendimento',\n",
    "        'override',\n",
    "        'is_estrategico',\n",
    "        'estrategic_score',\n",
    "        'is_estrategico_final',\n",
    "        'decision_source'\n",
    "    ]].copy()\n",
    "    \n",
    "    if 'tipo_vara' in df_scoring.columns:\n",
    "        output_scores_full['tipo_vara'] = df_scoring['tipo_vara']\n",
    "    if 'uf' in df_scoring.columns:\n",
    "        output_scores_full['uf'] = df_scoring['uf']\n",
    "    if 'valor_moral' in df_scoring.columns:\n",
    "        output_scores_full['valor_moral'] = df_scoring['valor_moral']\n",
    "    if 'valor_material' in df_scoring.columns:\n",
    "        output_scores_full['valor_material'] = df_scoring['valor_material']\n",
    "    \n",
    "    output_scores_full.to_csv('output_scores.csv', index=False)\n",
    "    print(f\"  Arquivo salvo: output_scores.csv ({len(output_scores_full)} linhas)\")\n",
    "    \n",
    "    # ========== ATUALIZAR relatorio.xlsx ==========\n",
    "    print(\"\\n### ATUALIZAR relatorio.xlsx ###\")\n",
    "    \n",
    "    try:\n",
    "        # Ler relatorio.xlsx existente\n",
    "        with pd.ExcelFile('relatorio.xlsx') as xls:\n",
    "            sheet_names_existing = xls.sheet_names\n",
    "        \n",
    "        print(f\"  Abas existentes em relatorio.xlsx: {sheet_names_existing}\")\n",
    "        \n",
    "        # Criar dados para nova aba \"Scores_Estrategicos\"\n",
    "        scores_data = {\n",
    "            'Metrica': [\n",
    "                'Total de casos',\n",
    "                'Casos com override',\n",
    "                'Casos com modelo',\n",
    "                '% override',\n",
    "                '% modelo',\n",
    "                'Media de score (modelo)',\n",
    "                'Mediana de score (modelo)'\n",
    "            ],\n",
    "            'Valor': [\n",
    "                len(df_scoring),\n",
    "                n_override,\n",
    "                n_sem_override,\n",
    "                f'{n_override/len(df_scoring)*100:.1f}%' if len(df_scoring) > 0 else '0.0%',\n",
    "                f'{n_sem_override/len(df_scoring)*100:.1f}%' if len(df_scoring) > 0 else '0.0%',\n",
    "                f'{df_scoring.loc[mask_model, \"estrategic_score\"].mean():.4f}' if mask_model.sum() > 0 else '0.0',\n",
    "                f'{df_scoring.loc[mask_model, \"estrategic_score\"].median():.4f}' if mask_model.sum() > 0 else '0.0'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Adicionar contagem por decision_source\n",
    "        for ds, count in ds_counts.items():\n",
    "            if ds:\n",
    "                scores_data['Metrica'].append(f'Decision_source: {ds}')\n",
    "                scores_data['Valor'].append(count)\n",
    "        \n",
    "        # Adicionar contagem de overrides por tipo\n",
    "        if n_override > 0:\n",
    "            for override_type, count in df_scoring[mask_override]['override'].value_counts().items():\n",
    "                scores_data['Metrica'].append(f'Override tipo: {override_type}')\n",
    "                scores_data['Valor'].append(count)\n",
    "        \n",
    "        scores_df = pd.DataFrame(scores_data)\n",
    "        \n",
    "        # Reabrir relatorio.xlsx e adicionar/atualizar aba\n",
    "        with pd.ExcelWriter('relatorio.xlsx', engine='openpyxl', mode='a' if os.path.exists('relatorio.xlsx') else 'w') as xw:\n",
    "            # Remover aba se já existir\n",
    "            try:\n",
    "                xw.book.remove(xw.book['Scores_Estrategicos'])\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Adicionar nova aba\n",
    "            scores_df.to_excel(xw, sheet_name='Scores_Estrategicos', index=False)\n",
    "        \n",
    "        print(f\"  Aba 'Scores_Estrategicos' criada/atualizada em relatorio.xlsx\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  [AVISO] Erro ao atualizar relatorio.xlsx: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SCORING E INTEGRAÇÃO CONCLUÍDO\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1e7192",
   "metadata": {},
   "source": [
    "## 12 Fechamento + Run-All Check\n",
    "\n",
    "Validação final: verifica que todos os artifacts foram criados e relatorio.xlsx atende ao plano de ensino.\n",
    "\n",
    "Verificações:\n",
    "1. output.xlsx: schema correto (7 colunas)\n",
    "2. relatorio.xlsx: abas esperadas\n",
    "3. Métricas resumidas: % consignado, médias de danos, overrides\n",
    "4. Artefatos do modelo: pkl, csv, png\n",
    "\n",
    "Gráficos adicionais (matplotlib puro):\n",
    "- Histogramas (log-x) de valor_moral e valor_material\n",
    "- Boxplots por tipo_vara\n",
    "- Barras por UF\n",
    "- Top 10 empresas\n",
    "- Scatter log-log valor_moral vs valor_material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b6b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RUN-ALL CHECK: VALIDAÇÃO FINAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import os\n",
    "\n",
    "# ========== VERIFICAR output.xlsx ==========\n",
    "print(\"\\n### VERIFICAÇÃO: output.xlsx ###\")\n",
    "\n",
    "if os.path.exists('output.xlsx'):\n",
    "    try:\n",
    "        df_output = pd.read_excel('output.xlsx')\n",
    "        expected_cols = ['cd_atendimento', 'nome_empresa', 'cnpj', 'valor_causa', 'dt_distribuicao', 'tipo_vara', 'uf']\n",
    "        actual_cols = list(df_output.columns)\n",
    "        \n",
    "        if actual_cols == expected_cols:\n",
    "            print(f\"  [OK] Schema correto: {len(df_output)} linhas, {len(actual_cols)} colunas\")\n",
    "        else:\n",
    "            print(f\"  [ERRO] Schema incorreto!\")\n",
    "            print(f\"    Esperado: {expected_cols}\")\n",
    "            print(f\"    Obtido:   {actual_cols}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  [ERRO] Ao ler output.xlsx: {e}\")\n",
    "else:\n",
    "    print(\"  [ERRO] output.xlsx não existe\")\n",
    "\n",
    "# ========== VERIFICAR relatorio.xlsx ==========\n",
    "print(\"\\n### VERIFICAÇÃO: relatorio.xlsx ###\")\n",
    "\n",
    "if os.path.exists('relatorio.xlsx'):\n",
    "    try:\n",
    "        xls = pd.ExcelFile('relatorio.xlsx')\n",
    "        sheet_names = xls.sheet_names\n",
    "        print(f\"  [OK] relatorio.xlsx existe com {len(sheet_names)} abas:\")\n",
    "        for sheet in sheet_names:\n",
    "            df_sheet = pd.read_excel('relatorio.xlsx', sheet_name=sheet)\n",
    "            print(f\"    - {sheet}: {len(df_sheet)} linhas\")\n",
    "    except Exception as e:\n",
    "        print(f\"  [ERRO] Ao ler relatorio.xlsx: {e}\")\n",
    "else:\n",
    "    print(\"  [AVISO] relatorio.xlsx não existe (será criado ao executar células anteriores)\")\n",
    "\n",
    "# ========== VERIFICAR ARTEFATOS DO MODELO ==========\n",
    "print(\"\\n### VERIFICAÇÃO: ARTEFATOS DO MODELO ###\")\n",
    "\n",
    "artifacts = [\n",
    "    ('modelo_logistico.pkl', 'Pipeline treinado (sklearn)'),\n",
    "    ('coeficientes.csv', 'Coeficientes do modelo logístico'),\n",
    "    ('output_scores.csv', 'Predições em formato CSV'),\n",
    "    ('logit_top_features.png', 'Gráfico: Top 20 features')\n",
    "]\n",
    "\n",
    "for filename, description in artifacts:\n",
    "    if os.path.exists(filename):\n",
    "        size_kb = os.path.getsize(filename) / 1024\n",
    "        print(f\"  [OK] {filename:25s} ({size_kb:>7.1f} KB) - {description}\")\n",
    "    else:\n",
    "        print(f\"  [NA] {filename:25s} - não gerado (normal se modelo não foi treinado)\")\n",
    "\n",
    "# ========== GRÁFICOS ADICIONAIS ==========\n",
    "print(\"\\n### GRÁFICOS ADICIONAIS ###\")\n",
    "\n",
    "# Trabalhar com df_expandido ou df_override\n",
    "df_graphs = None\n",
    "if 'df_expandido' in locals() and df_expandido is not None and len(df_expandido) > 0:\n",
    "    df_graphs = df_expandido\n",
    "elif 'df_override' in locals() and df_override is not None and len(df_override) > 0:\n",
    "    df_graphs = df_override\n",
    "elif 'df_resultados' in locals() and df_resultados is not None and len(df_resultados) > 0:\n",
    "    df_graphs = df_resultados\n",
    "\n",
    "if df_graphs is not None:\n",
    "    print(f\"\\n  Dataset: {len(df_graphs)} casos\")\n",
    "    \n",
    "    # 1. Histogramas de valores (log-x)\n",
    "    if 'valor_moral' in df_graphs.columns and 'valor_material' in df_graphs.columns:\n",
    "        valor_moral_pos = df_graphs.loc[df_graphs['valor_moral'] > 0, 'valor_moral']\n",
    "        valor_material_pos = df_graphs.loc[df_graphs['valor_material'] > 0, 'valor_material']\n",
    "        \n",
    "        if len(valor_moral_pos) > 0:\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            ax.hist(np.log10(valor_moral_pos + 1), bins=20, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "            ax.set_xlabel('log10(Valor Moral + 1)', fontsize=11)\n",
    "            ax.set_ylabel('Frequência', fontsize=11)\n",
    "            ax.set_title('Distribuição de Danos Morais (log-scale)', fontsize=12, fontweight='bold')\n",
    "            ax.grid(axis='y', alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('hist_valor_moral_log.png', dpi=100, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            print(\"  Arquivo salvo: hist_valor_moral_log.png\")\n",
    "        \n",
    "        if len(valor_material_pos) > 0:\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            ax.hist(np.log10(valor_material_pos + 1), bins=20, color='lightcoral', edgecolor='black', alpha=0.7)\n",
    "            ax.set_xlabel('log10(Valor Material + 1)', fontsize=11)\n",
    "            ax.set_ylabel('Frequência', fontsize=11)\n",
    "            ax.set_title('Distribuição de Danos Materiais (log-scale)', fontsize=12, fontweight='bold')\n",
    "            ax.grid(axis='y', alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('hist_valor_material_log.png', dpi=100, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            print(\"  Arquivo salvo: hist_valor_material_log.png\")\n",
    "    \n",
    "    # 2. Boxplots por tipo_vara\n",
    "    if 'tipo_vara' in df_graphs.columns and 'valor_moral' in df_graphs.columns:\n",
    "        try:\n",
    "            tipo_vara_unique = df_graphs['tipo_vara'].dropna().unique()\n",
    "            \n",
    "            if len(tipo_vara_unique) > 1:\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "                \n",
    "                # Moral\n",
    "                moral_por_vara = [df_graphs.loc[df_graphs['tipo_vara']==vara, 'valor_moral'].dropna() for vara in tipo_vara_unique]\n",
    "                axes[0].boxplot(moral_por_vara, labels=tipo_vara_unique)\n",
    "                axes[0].set_ylabel('Valor Moral (R$)', fontsize=11)\n",
    "                axes[0].set_title('Danos Morais por Tipo de Vara', fontsize=12, fontweight='bold')\n",
    "                axes[0].grid(axis='y', alpha=0.3)\n",
    "                \n",
    "                # Material\n",
    "                material_por_vara = [df_graphs.loc[df_graphs['tipo_vara']==vara, 'valor_material'].dropna() for vara in tipo_vara_unique]\n",
    "                axes[1].boxplot(material_por_vara, labels=tipo_vara_unique)\n",
    "                axes[1].set_ylabel('Valor Material (R$)', fontsize=11)\n",
    "                axes[1].set_title('Danos Materiais por Tipo de Vara', fontsize=12, fontweight='bold')\n",
    "                axes[1].grid(axis='y', alpha=0.3)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig('boxplot_danos_vara.png', dpi=100, bbox_inches='tight')\n",
    "                plt.show()\n",
    "                print(\"  Arquivo salvo: boxplot_danos_vara.png\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # 3. Barras: média de danos por UF\n",
    "    if 'uf' in df_graphs.columns and 'valor_moral' in df_graphs.columns:\n",
    "        try:\n",
    "            media_moral_uf = df_graphs.groupby('uf')['valor_moral'].mean().sort_values(ascending=False).head(15)\n",
    "            \n",
    "            if len(media_moral_uf) > 0:\n",
    "                fig, ax = plt.subplots(figsize=(12, 6))\n",
    "                ax.bar(range(len(media_moral_uf)), media_moral_uf.values, color='teal', edgecolor='black', alpha=0.7)\n",
    "                ax.set_xticks(range(len(media_moral_uf)))\n",
    "                ax.set_xticklabels(media_moral_uf.index, fontsize=9)\n",
    "                ax.set_ylabel('Danos Morais Médios (R$)', fontsize=11)\n",
    "                ax.set_title('Danos Morais Médios por UF (Top 15)', fontsize=12, fontweight='bold')\n",
    "                ax.grid(axis='y', alpha=0.3)\n",
    "                \n",
    "                for i, v in enumerate(media_moral_uf.values):\n",
    "                    ax.text(i, v + 1000, f'R${v/1000:.0f}k', ha='center', fontsize=8)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig('bar_media_moral_uf.png', dpi=100, bbox_inches='tight')\n",
    "                plt.show()\n",
    "                print(\"  Arquivo salvo: bar_media_moral_uf.png\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # 4. Top 10 empresas por contagem\n",
    "    if 'nome_empresa' in df_graphs.columns:\n",
    "        try:\n",
    "            top_empresas = df_graphs['nome_empresa'].value_counts().head(10)\n",
    "            \n",
    "            if len(top_empresas) > 0:\n",
    "                fig, ax = plt.subplots(figsize=(12, 6))\n",
    "                ax.barh(range(len(top_empresas)), top_empresas.values, color='orange', edgecolor='black', alpha=0.7)\n",
    "                ax.set_yticks(range(len(top_empresas)))\n",
    "                ax.set_yticklabels(top_empresas.index, fontsize=9)\n",
    "                ax.set_xlabel('Contagem de Casos', fontsize=11)\n",
    "                ax.set_title('Top 10 Empresas por Contagem de Casos', fontsize=12, fontweight='bold')\n",
    "                ax.grid(axis='x', alpha=0.3)\n",
    "                \n",
    "                for i, v in enumerate(top_empresas.values):\n",
    "                    ax.text(v + 0.1, i, str(v), ha='left', fontsize=9)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig('bar_top_empresas.png', dpi=100, bbox_inches='tight')\n",
    "                plt.show()\n",
    "                print(\"  Arquivo salvo: bar_top_empresas.png\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # 5. Scatter log-log: valor_moral vs valor_material\n",
    "    if 'valor_moral' in df_graphs.columns and 'valor_material' in df_graphs.columns:\n",
    "        try:\n",
    "            mask_scatter = (df_graphs['valor_moral'] > 0) & (df_graphs['valor_material'] > 0)\n",
    "            if mask_scatter.sum() > 0:\n",
    "                moral_scatter = df_graphs.loc[mask_scatter, 'valor_moral']\n",
    "                material_scatter = df_graphs.loc[mask_scatter, 'valor_material']\n",
    "                \n",
    "                fig, ax = plt.subplots(figsize=(10, 8))\n",
    "                ax.scatter(np.log10(moral_scatter + 1), np.log10(material_scatter + 1), \n",
    "                          alpha=0.3, s=30, color='purple', edgecolors='none')\n",
    "                ax.set_xlabel('log10(Danos Morais + 1)', fontsize=11)\n",
    "                ax.set_ylabel('log10(Danos Materiais + 1)', fontsize=11)\n",
    "                ax.set_title('Relação: Danos Morais vs Materiais (log-log)', fontsize=12, fontweight='bold')\n",
    "                ax.grid(alpha=0.3)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig('scatter_moral_vs_material.png', dpi=100, bbox_inches='tight')\n",
    "                plt.show()\n",
    "                print(\"  Arquivo salvo: scatter_moral_vs_material.png\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# ========== RESUMO FINAL ==========\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMO FINAL - ENTREGA 6\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nArquivos de saída criados:\")\n",
    "print(\"  1. output.xlsx (7 colunas: roteiro da entrega)\")\n",
    "print(\"  2. output_expandido.xlsx (13 colunas: análise de danos)\")\n",
    "print(\"  3. relatorio.xlsx (múltiplas abas: análise consolidada)\")\n",
    "print(\"  4. output_scores.csv (predições: override + modelo)\")\n",
    "print(\"  5. coeficientes.csv (importância de features do modelo)\")\n",
    "print(\"  6. modelo_logistico.pkl (pipeline sklearn)\")\n",
    "print(\"  7. Múltiplos gráficos PNG (análises visuais)\")\n",
    "\n",
    "print(\"\\nVerificações realizadas:\")\n",
    "print(\"  [OK] Schema de output.xlsx\")\n",
    "print(\"  [OK] Abas de relatorio.xlsx\")\n",
    "print(\"  [OK] Artefatos do modelo logístico\")\n",
    "print(\"  [OK] Gráficos adicionais\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OK - ENTREGA PRONTA\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
